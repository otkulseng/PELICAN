#!/usr/bin/env python

import argparse
import yaml
import logging
from pathlib import Path
import os
import pickle
import numpy as np

from nanopelican.models import PelicanNano
from nanopelican.data import load_dataset
from nanopelican.schedulers import LinearWarmupCosineAnnealing

import tensorflow as tf
from tqdm.keras import TqdmCallback


import tensorflow as tf

logger = logging.getLogger('')

def load_arguments():
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("--config", required=True,  type=str)
    parser.add_argument("--gpu", type=str, default="0")
    args = parser.parse_args()

    os.environ["CUDA_VISIBLE_DEVICES"] = args.gpu

    with open(args.config, "r") as stream:
        config = yaml.load(stream, Loader=yaml.Loader)
    return config

def create_directory(args):

    root = args['folder']
    name = args['name']

    rootdir = Path.cwd() / root
    if not rootdir.exists():
        os.mkdir(rootdir)

    counter = 0
    while True:
        folder = rootdir / f'{name}-{counter}'
        if not folder.exists():
            break
        counter += 1

    os.mkdir(folder)
    return folder


def save_config_file(filename, data):
    with open(filename, 'w') as outfile:
        yaml.dump(data, outfile, default_flow_style=False)


def save_experiment(folder, model, history):
    model.save(folder / 'model.keras')

    with open(folder / 'history.pkl', 'wb') as file_pi:
        mydict = history
        pickle.dump(mydict, file_pi)



def add_default_values(conf):
    if 'seed' not in conf:
        conf['seed'] = np.random.randint(0, 2**31)

    if 'val_size' not in conf['hyperparams']:
        conf['hyperparams'].update({'val_size': -1})

    if 'patience' not in conf['hyperparams']:
        conf['hyperparams'].update({'patience': conf['hyperparams']['epochs']})

    if 'weight_decay' not in conf['hyperparams']:
        conf['hyperparams'].update({'weight_decay': 0.0})

    return conf


def run(conf):

    save_dir = create_directory(conf['save_dir'])
    # Save config to directory

    conf = add_default_values(conf)
    save_config_file(save_dir / 'config.yml', conf)

    tf.keras.utils.set_random_seed(conf['seed'])


    # Initialize logger
    logger.setLevel(logging.DEBUG)
    logfile = logging.FileHandler(save_dir / 'log.log')
    logging.basicConfig(level=logging.DEBUG, handlers=[logfile])
    train_log = tf.keras.callbacks.CSVLogger(save_dir / 'training.log')


    model = PelicanNano(conf['model'])

    dataset = load_dataset(conf['dataset'], keys=['train', 'valid'])

    hyperparams = conf['hyperparams']

    if True:
        data = dataset.train
        features, _ = data[0]
        model.build(features.shape)
        model.summary(features.shape)

    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=LinearWarmupCosineAnnealing(
            epochs=hyperparams['epochs'],
            steps_per_epoch=len(dataset.train),
        )),
        loss=loss,
        metrics=['accuracy'],
    )

    dataset.val.shuffle(keepratio=True)
    try:
        history = model.fit(
            dataset.train.shuffle(keepratio=True).batch(hyperparams['batch_size']),
            epochs = hyperparams['epochs'],
            validation_data = (dataset.val.x_data[:hyperparams['val_size']], dataset.val.y_data[:hyperparams['val_size']]),
            callbacks=[TqdmCallback(verbose=hyperparams['verbose']), train_log, tf.keras.callbacks.ModelCheckpoint(
                filepath = save_dir / 'model.best_acc.keras',
                monitor='val_accuracy',
                mode='max',
                save_best_only=True
            ), tf.keras.callbacks.ModelCheckpoint(
                filepath = save_dir / 'model.best_loss.keras',
                monitor='val_loss',
                mode='min',
                save_best_only=True
            )
        ],
            verbose=0
        )
        history = history.history

    except KeyboardInterrupt:
        logger.info("Keyboard Interrupt! Saving progress")
        history = {}

    save_experiment(save_dir, model, history)


def main():
    conf = load_arguments()
    return run(conf)



if __name__ == '__main__':
    main()

