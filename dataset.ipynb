{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading of data**\n",
    "\n",
    "Initial code taken from: https://github.com/pierinim/tutorials/blob/master/GGI_Jan2021/Lecture1/Notebook1_ExploreDataset.ipynb\n",
    "\n",
    "And "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datahandling import download_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already downloaded.. \n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILE_ITERATOR, TEST_FILE_ITERATOR = download_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fourvectors(file):\n",
    "    file = h5py.File(file)\n",
    "    jetconstituents = file.get('jetConstituentList')\n",
    "    # Shape: num_jets x num_particles x 4\n",
    "    fourvectors = jetconstituents[:, :, :4] # Particles (px, py, pz, E)\n",
    "    fourvectors.shape\n",
    "\n",
    "    jet_data = file.get('jets')\n",
    "    target = jet_data[:, -6:-1]\n",
    "    return fourvectors, target\n",
    "\n",
    "def make_outer_product(fourvectors):\n",
    "    M = np.diag([-1, -1, -1, 1])\n",
    "    return np.einsum(\"...pi, ij, ...qj->...pq\", fourvectors, M, fourvectors)\n",
    "\n",
    "fourvecs, y_training = get_fourvectors(next(TRAIN_FILE_ITERATOR))\n",
    "x_training = make_outer_product(fourvecs)\n",
    "\n",
    "fourvecs, y_testing = get_fourvectors(next(TRAIN_FILE_ITERATOR))\n",
    "x_testing = make_outer_product(fourvecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 150, 150, 1) (100, 5)\n",
      "(100, 150, 150, 1) (100, 5)\n"
     ]
    }
   ],
   "source": [
    "NUM_JETS = 100\n",
    "X_train = np.expand_dims(x_training, -1)[:NUM_JETS]\n",
    "y_train = y_training[:NUM_JETS]\n",
    "X_test = np.expand_dims(x_testing, -1)[:NUM_JETS]\n",
    "y_test = y_testing[:NUM_JETS]\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the PELICAN architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\otkul\\ETH\\vår\\project\\.env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\otkul\\ETH\\vår\\project\\.env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from layers import Msg, LinEq2v2, LinEq2v0, InputLayer\n",
    "from keras.layers import Dropout, Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "from keras.optimizers import AdamW\n",
    "from keras.models import load_model\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\otkul\\ETH\\vår\\project\\.env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(layers = [\n",
    "        InputLayer(),\n",
    "        Msg(35, activation='relu'),\n",
    "        LinEq2v2(60, activation='relu'),\n",
    "        Msg(35, activation='relu'),\n",
    "        LinEq2v2(60, activation='relu'),\n",
    "        Msg(35, activation='relu'),\n",
    "        LinEq2v2(60, activation='relu'),\n",
    "        Msg(35, activation='relu'),\n",
    "        LinEq2v2(60, activation='relu'),\n",
    "        Msg(35, activation='relu'),\n",
    "        LinEq2v2(60, activation='relu'),\n",
    "        Msg(35, activation='relu'),\n",
    "        LinEq2v0(60, activation='relu'),\n",
    "        Dense(5, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=AdamW(),\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=[CategoricalAccuracy()],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\otkul\\ETH\\vår\\project\\.env\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    (1, 150, 150, 1)          0         \n",
      "                                                                 \n",
      " msg (Msg)                   (1, 150, 150, 35)         210       \n",
      "                                                                 \n",
      " lin_eq2v2 (LinEq2v2)        (1, 150, 150, 60)         5745      \n",
      "                                                                 \n",
      " msg_1 (Msg)                 (1, 150, 150, 35)         2275      \n",
      "                                                                 \n",
      " lin_eq2v2_1 (LinEq2v2)      (1, 150, 150, 60)         5745      \n",
      "                                                                 \n",
      " msg_2 (Msg)                 (1, 150, 150, 35)         2275      \n",
      "                                                                 \n",
      " lin_eq2v2_2 (LinEq2v2)      (1, 150, 150, 60)         5745      \n",
      "                                                                 \n",
      " msg_3 (Msg)                 (1, 150, 150, 35)         2275      \n",
      "                                                                 \n",
      " lin_eq2v2_3 (LinEq2v2)      (1, 150, 150, 60)         5745      \n",
      "                                                                 \n",
      " msg_4 (Msg)                 (1, 150, 150, 35)         2275      \n",
      "                                                                 \n",
      " lin_eq2v2_4 (LinEq2v2)      (1, 150, 150, 60)         5745      \n",
      "                                                                 \n",
      " msg_5 (Msg)                 (1, 150, 150, 35)         2275      \n",
      "                                                                 \n",
      " lin_eq2v0 (LinEq2v0)        (1, 60)                   4260      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, 5)                    305       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44875 (175.29 KB)\n",
      "Trainable params: 44455 (173.65 KB)\n",
      "Non-trainable params: 420 (1.64 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(1, 150, 150, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0epoch [00:00, ?epoch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\otkul\\ETH\\vår\\project\\.env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs = EPOCHS,\n",
    "    batch_size = BATCH,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[TqdmCallback(data_size=len(X_train), batch_size=BATCH, verbose=1)],\n",
    "    verbose = 0\n",
    ")\n",
    "# [30:06<07:40, 230.23s/epoch, loss=435, categorical_accuracy=0.596, val_loss=1.06e+3, val_categorical_accuracy=0.468]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    (None, 150, 150, 1)       0         \n",
      "                                                                 \n",
      " msg (Msg)                   (None, 150, 150, 30)      150       \n",
      "                                                                 \n",
      " lin_eq2v2 (LinEq2v2)        (None, 150, 150, 60)      4950      \n",
      "                                                                 \n",
      " msg_1 (Msg)                 (None, 150, 150, 30)      1920      \n",
      "                                                                 \n",
      " lin_eq2v0 (LinEq2v0)        (None, 120)               7200      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 605       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14825 (57.91 KB)\n",
      "Trainable params: 14705 (57.44 KB)\n",
      "Non-trainable params: 120 (480.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.60s/epoch, loss=6.47e+3, categorical_accuracy=0.22, val_loss=1.32e+4, val_categorical_accuracy=0.19]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs = EPOCHS,\n",
    "    batch_size = BATCH,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[TqdmCallback(data_size=len(X_train), batch_size=BATCH, verbose=1)],\n",
    "    verbose=0\n",
    ")\n",
    "# 89.33s/epoch, loss=325, categorical_accuracy=0.517, val_loss=3.53e+3, val_categorical_accuracy=0.129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
