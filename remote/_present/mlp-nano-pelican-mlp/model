#!/usr/bin/env python
from nanopelican.layers import *
from nanopelican.scripts import run
from keras import layers, Model


def mlp(units, activs, x, diag_bias=False):
    for unit, activ in zip(units, activs):
        if diag_bias:
            x = DiagBiasDense(
                units=unit,
                activation=activ
            )(x)
        else:
            x = layers.Dense(
                units=unit,
                activation=activ
            )(x)
    return x

def CreateModel(shape, conf):
    x = x_in = layers.Input(shape)

    x, mask = InnerProduct(conf['inner_product'])(x)
    
    x = LogLayer()(x)

    x = mlp(conf['input']['units'], conf['input']['activs'], x, diag_bias=True)

    if conf['batchnorm']:
        x = layers.BatchNormalization()(x)

    x = Lineq2v2(
        num_avg=conf['num_avg'],
    )(x)

    x = mlp(conf['hidden']['units'], conf['hidden']['activs'], x, diag_bias=True)

    x = layers.Multiply()([x, mask])

    if conf['batchnorm']:
        x = layers.BatchNormalization()(x)

    x = Lineq2v0(num_avg=conf['num_avg'])(x)

    x = mlp(conf['out']['units'], conf['out']['activs'], x)

    return Model(inputs=x_in, outputs=x)

def main():
    run(CreateModel)

if __name__ == '__main__':
    main()

