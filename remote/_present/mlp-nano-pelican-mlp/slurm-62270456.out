2024-06-15 18:36:24.433764: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-15 18:36:24.435287: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-15 18:36:24.481907: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-15 18:36:24.685329: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-15 18:36:26.868981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-15 18:36:35.943044: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer           │ (None, 32, 32, 1) │          1 │ inner_product[0]… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32,    │         30 │ log_layer[0][0]   │
│ (DiagBiasDense)     │ 10)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense_1   │ (None, 32, 32, 5) │         60 │ diag_bias_dense[… │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 5) │         20 │ diag_bias_dense_… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 75)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense_2   │ (None, 32, 32,    │        770 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │ 10)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense_3   │ (None, 32, 32, 5) │         60 │ diag_bias_dense_… │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 5) │          0 │ diag_bias_dense_… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 5) │         20 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 10)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 64)        │        704 │ lineq2v0[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 32)        │      2,080 │ dense[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 5)         │        165 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 3,910 (15.27 KB)
 Trainable params: 3,890 (15.20 KB)
 Non-trainable params: 20 (80.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [16:21<272:15:09, 981.09s/epoch, accuracy=0.649, loss=0.951, lr=0.002, val_accuracy=0.568, val_loss=1.1, val_lr=0.002]  0%|          | 2/1000 [32:19<268:18:51, 967.87s/epoch, accuracy=0.691, loss=0.858, lr=0.002, val_accuracy=0.661, val_loss=0.919, val_lr=0.002]  0%|          | 3/1000 [48:11<266:02:38, 960.64s/epoch, accuracy=0.698, loss=0.842, lr=0.002, val_accuracy=0.686, val_loss=0.882, val_lr=0.002]  0%|          | 4/1000 [1:03:54<263:47:05, 953.44s/epoch, accuracy=0.703, loss=0.831, lr=0.002, val_accuracy=0.672, val_loss=0.902, val_lr=0.002]  0%|          | 5/1000 [1:19:43<263:06:01, 951.92s/epoch, accuracy=0.708, loss=0.822, lr=0.002, val_accuracy=0.711, val_loss=0.823, val_lr=0.002]  1%|          | 6/1000 [1:34:45<258:07:19, 934.85s/epoch, accuracy=0.71, loss=0.815, lr=0.002, val_accuracy=0.638, val_loss=0.991, val_lr=0.002]   1%|          | 7/1000 [1:48:11<246:14:26, 892.72s/epoch, accuracy=0.712, loss=0.81, lr=0.002, val_accuracy=0.694, val_loss=0.858, val_lr=0.002]  1%|          | 8/1000 [2:00:35<233:00:30, 845.60s/epoch, accuracy=0.714, loss=0.805, lr=0.002, val_accuracy=0.715, val_loss=0.805, val_lr=0.002]  1%|          | 9/1000 [2:12:50<223:16:17, 811.08s/epoch, accuracy=0.715, loss=0.801, lr=0.002, val_accuracy=0.718, val_loss=0.792, val_lr=0.002]  1%|          | 10/1000 [2:25:03<216:23:54, 786.90s/epoch, accuracy=0.716, loss=0.797, lr=0.002, val_accuracy=0.715, val_loss=0.8, val_lr=0.002]   1%|          | 11/1000 [2:36:59<210:09:35, 764.99s/epoch, accuracy=0.717, loss=0.795, lr=0.002, val_accuracy=0.689, val_loss=0.861, val_lr=0.002]  1%|          | 12/1000 [2:48:19<202:53:07, 739.26s/epoch, accuracy=0.718, loss=0.791, lr=0.002, val_accuracy=0.69, val_loss=0.854, val_lr=0.002]   1%|▏         | 13/1000 [2:59:41<197:57:22, 722.03s/epoch, accuracy=0.72, loss=0.788, lr=0.002, val_accuracy=0.71, val_loss=0.811, val_lr=0.002]   1%|▏         | 14/1000 [3:11:16<195:30:57, 713.85s/epoch, accuracy=0.72, loss=0.786, lr=0.002, val_accuracy=0.708, val_loss=0.819, val_lr=0.002]  2%|▏         | 15/1000 [3:22:52<193:47:03, 708.25s/epoch, accuracy=0.721, loss=0.785, lr=0.002, val_accuracy=0.728, val_loss=0.77, val_lr=0.002]  2%|▏         | 16/1000 [3:34:27<192:30:09, 704.28s/epoch, accuracy=0.722, loss=0.783, lr=0.002, val_accuracy=0.675, val_loss=0.892, val_lr=0.002]  2%|▏         | 17/1000 [3:47:09<197:03:04, 721.65s/epoch, accuracy=0.722, loss=0.781, lr=0.002, val_accuracy=0.705, val_loss=0.821, val_lr=0.002]  2%|▏         | 18/1000 [4:00:13<201:59:19, 740.49s/epoch, accuracy=0.723, loss=0.78, lr=0.002, val_accuracy=0.726, val_loss=0.775, val_lr=0.002]   2%|▏         | 19/1000 [4:13:16<205:17:39, 753.37s/epoch, accuracy=0.723, loss=0.779, lr=0.002, val_accuracy=0.697, val_loss=0.838, val_lr=0.002]  2%|▏         | 20/1000 [4:26:20<207:34:05, 762.50s/epoch, accuracy=0.723, loss=0.778, lr=0.002, val_accuracy=0.719, val_loss=0.785, val_lr=0.002]  2%|▏         | 21/1000 [4:39:20<208:47:28, 767.77s/epoch, accuracy=0.724, loss=0.776, lr=0.002, val_accuracy=0.712, val_loss=0.806, val_lr=0.002]  2%|▏         | 22/1000 [4:52:20<209:33:07, 771.36s/epoch, accuracy=0.724, loss=0.777, lr=0.002, val_accuracy=0.718, val_loss=0.793, val_lr=0.002]  2%|▏         | 23/1000 [5:05:20<210:01:52, 773.91s/epoch, accuracy=0.724, loss=0.775, lr=0.002, val_accuracy=0.721, val_loss=0.786, val_lr=0.002]  2%|▏         | 24/1000 [5:18:20<210:19:53, 775.81s/epoch, accuracy=0.725, loss=0.775, lr=0.002, val_accuracy=0.716, val_loss=0.79, val_lr=0.002]   2%|▎         | 25/1000 [5:31:19<210:24:10, 776.87s/epoch, accuracy=0.726, loss=0.773, lr=0.002, val_accuracy=0.726, val_loss=0.778, val_lr=0.002]  3%|▎         | 26/1000 [5:44:19<210:22:49, 777.59s/epoch, accuracy=0.729, loss=0.764, lr=0.0002, val_accuracy=0.733, val_loss=0.758, val_lr=0.0002]  3%|▎         | 27/1000 [5:57:12<209:48:39, 776.28s/epoch, accuracy=0.729, loss=0.763, lr=0.0002, val_accuracy=0.733, val_loss=0.757, val_lr=0.0002]  3%|▎         | 28/1000 [6:09:49<208:00:58, 770.43s/epoch, accuracy=0.73, loss=0.763, lr=0.0002, val_accuracy=0.732, val_loss=0.759, val_lr=0.0002]   3%|▎         | 29/1000 [6:22:32<207:15:13, 768.40s/epoch, accuracy=0.73, loss=0.763, lr=0.0002, val_accuracy=0.733, val_loss=0.757, val_lr=0.0002]  3%|▎         | 30/1000 [6:35:21<207:05:23, 768.58s/epoch, accuracy=0.73, loss=0.762, lr=0.0002, val_accuracy=0.733, val_loss=0.758, val_lr=0.0002]  3%|▎         | 31/1000 [6:48:05<206:30:23, 767.21s/epoch, accuracy=0.73, loss=0.762, lr=0.0002, val_accuracy=0.734, val_loss=0.756, val_lr=0.0002]  3%|▎         | 32/1000 [7:00:50<206:06:22, 766.51s/epoch, accuracy=0.73, loss=0.762, lr=0.0002, val_accuracy=0.733, val_loss=0.757, val_lr=0.0002]  3%|▎         | 33/1000 [7:13:34<205:40:51, 765.72s/epoch, accuracy=0.73, loss=0.761, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  3%|▎         | 34/1000 [7:26:20<205:31:07, 765.91s/epoch, accuracy=0.73, loss=0.761, lr=0.0002, val_accuracy=0.733, val_loss=0.759, val_lr=0.0002]  4%|▎         | 35/1000 [7:39:36<207:42:06, 774.85s/epoch, accuracy=0.73, loss=0.761, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  4%|▎         | 36/1000 [7:52:25<206:59:56, 773.03s/epoch, accuracy=0.73, loss=0.761, lr=0.0002, val_accuracy=0.733, val_loss=0.757, val_lr=0.0002]  4%|▎         | 37/1000 [8:06:15<211:23:56, 790.28s/epoch, accuracy=0.73, loss=0.761, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  4%|▍         | 38/1000 [8:20:04<214:16:02, 801.83s/epoch, accuracy=0.731, loss=0.76, lr=0.0002, val_accuracy=0.731, val_loss=0.762, val_lr=0.0002]  4%|▍         | 39/1000 [8:33:52<216:09:07, 809.73s/epoch, accuracy=0.731, loss=0.76, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  4%|▍         | 40/1000 [8:47:42<217:29:20, 815.58s/epoch, accuracy=0.731, loss=0.76, lr=0.0002, val_accuracy=0.734, val_loss=0.757, val_lr=0.0002]  4%|▍         | 41/1000 [9:02:03<220:55:22, 829.33s/epoch, accuracy=0.731, loss=0.76, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  4%|▍         | 42/1000 [9:18:00<230:54:40, 867.73s/epoch, accuracy=0.731, loss=0.76, lr=0.0002, val_accuracy=0.733, val_loss=0.759, val_lr=0.0002]  4%|▍         | 43/1000 [9:34:37<240:57:10, 906.41s/epoch, accuracy=0.731, loss=0.759, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  4%|▍         | 44/1000 [9:51:13<247:49:34, 933.24s/epoch, accuracy=0.731, loss=0.759, lr=0.0002, val_accuracy=0.734, val_loss=0.754, val_lr=0.0002]  4%|▍         | 45/1000 [10:07:48<252:28:30, 951.74s/epoch, accuracy=0.731, loss=0.759, lr=0.0002, val_accuracy=0.733, val_loss=0.756, val_lr=0.0002]  5%|▍         | 46/1000 [10:24:23<255:42:08, 964.91s/epoch, accuracy=0.731, loss=0.759, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  5%|▍         | 47/1000 [10:40:57<257:44:43, 973.65s/epoch, accuracy=0.731, loss=0.759, lr=0.0002, val_accuracy=0.734, val_loss=0.754, val_lr=0.0002]  5%|▍         | 48/1000 [10:56:13<252:52:24, 956.24s/epoch, accuracy=0.731, loss=0.759, lr=0.0002, val_accuracy=0.735, val_loss=0.754, val_lr=0.0002]  5%|▍         | 49/1000 [11:11:32<249:40:23, 945.14s/epoch, accuracy=0.732, loss=0.759, lr=0.0002, val_accuracy=0.734, val_loss=0.757, val_lr=0.0002]  5%|▌         | 50/1000 [11:26:50<247:16:13, 937.02s/epoch, accuracy=0.731, loss=0.758, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  5%|▌         | 51/1000 [11:42:09<245:34:10, 931.56s/epoch, accuracy=0.731, loss=0.758, lr=0.0002, val_accuracy=0.733, val_loss=0.758, val_lr=0.0002]  5%|▌         | 52/1000 [11:57:26<244:09:19, 927.17s/epoch, accuracy=0.732, loss=0.758, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  5%|▌         | 53/1000 [12:11:37<237:54:23, 904.40s/epoch, accuracy=0.732, loss=0.758, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  5%|▌         | 54/1000 [12:25:32<232:08:24, 883.41s/epoch, accuracy=0.732, loss=0.758, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  6%|▌         | 55/1000 [12:38:52<225:18:58, 858.35s/epoch, accuracy=0.732, loss=0.758, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  6%|▌         | 56/1000 [12:52:14<220:40:53, 841.58s/epoch, accuracy=0.732, loss=0.758, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  6%|▌         | 57/1000 [13:05:40<217:38:32, 830.87s/epoch, accuracy=0.732, loss=0.758, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  6%|▌         | 58/1000 [13:20:01<219:44:32, 839.78s/epoch, accuracy=0.732, loss=0.758, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  6%|▌         | 59/1000 [13:35:09<224:54:02, 860.41s/epoch, accuracy=0.732, loss=0.757, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  6%|▌         | 60/1000 [13:50:29<229:21:04, 878.37s/epoch, accuracy=0.732, loss=0.757, lr=0.0002, val_accuracy=0.735, val_loss=0.754, val_lr=0.0002]  6%|▌         | 61/1000 [14:04:43<227:08:18, 870.82s/epoch, accuracy=0.732, loss=0.757, lr=0.0002, val_accuracy=0.736, val_loss=0.752, val_lr=0.0002]  6%|▌         | 62/1000 [14:17:58<220:58:44, 848.11s/epoch, accuracy=0.732, loss=0.757, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  6%|▋         | 63/1000 [14:30:27<213:01:42, 818.47s/epoch, accuracy=0.733, loss=0.757, lr=0.0002, val_accuracy=0.735, val_loss=0.755, val_lr=0.0002]  6%|▋         | 64/1000 [14:42:36<205:48:32, 791.57s/epoch, accuracy=0.732, loss=0.757, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  6%|▋         | 65/1000 [14:54:31<199:37:06, 768.58s/epoch, accuracy=0.732, loss=0.757, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  7%|▋         | 66/1000 [15:05:22<190:15:43, 733.34s/epoch, accuracy=0.732, loss=0.756, lr=0.0002, val_accuracy=0.734, val_loss=0.755, val_lr=0.0002]  7%|▋         | 67/1000 [15:15:50<181:53:51, 701.86s/epoch, accuracy=0.733, loss=0.756, lr=0.0002, val_accuracy=0.735, val_loss=0.752, val_lr=0.0002]  7%|▋         | 68/1000 [15:26:19<175:59:53, 679.82s/epoch, accuracy=0.733, loss=0.756, lr=0.0002, val_accuracy=0.735, val_loss=0.753, val_lr=0.0002]  7%|▋         | 69/1000 [15:36:47<171:49:30, 664.42s/epoch, accuracy=0.733, loss=0.756, lr=0.0002, val_accuracy=0.735, val_loss=0.752, val_lr=0.0002]  7%|▋         | 70/1000 [15:47:20<169:13:09, 655.04s/epoch, accuracy=0.733, loss=0.756, lr=0.0002, val_accuracy=0.734, val_loss=0.754, val_lr=0.0002]  7%|▋         | 71/1000 [15:58:34<170:28:55, 660.64s/epoch, accuracy=0.733, loss=0.756, lr=0.0002, val_accuracy=0.735, val_loss=0.751, val_lr=0.0002]  7%|▋         | 72/1000 [16:10:48<175:56:53, 682.56s/epoch, accuracy=0.733, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]      7%|▋         | 73/1000 [16:23:01<179:41:51, 697.86s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  7%|▋         | 74/1000 [16:35:14<182:11:33, 708.31s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  8%|▊         | 75/1000 [16:47:27<183:53:21, 715.68s/epoch, accuracy=0.733, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  8%|▊         | 76/1000 [16:59:39<184:58:36, 720.69s/epoch, accuracy=0.733, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.75, val_lr=2e-5]   8%|▊         | 77/1000 [17:11:52<185:42:44, 724.34s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  8%|▊         | 78/1000 [17:24:06<186:13:31, 727.13s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.75, val_lr=2e-5]   8%|▊         | 79/1000 [17:36:19<186:31:07, 729.06s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.75, val_lr=2e-5]  8%|▊         | 80/1000 [17:48:33<186:40:19, 730.46s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  8%|▊         | 81/1000 [18:00:45<186:35:55, 730.96s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  8%|▊         | 82/1000 [18:12:58<186:32:21, 731.53s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  8%|▊         | 83/1000 [18:25:52<189:36:23, 744.37s/epoch, accuracy=0.733, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  8%|▊         | 84/1000 [18:40:39<200:15:07, 787.02s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  8%|▊         | 85/1000 [18:55:06<206:09:21, 811.11s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  9%|▊         | 86/1000 [19:09:01<207:46:24, 818.36s/epoch, accuracy=0.733, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.75, val_lr=2e-5]   9%|▊         | 87/1000 [19:19:48<194:28:41, 766.84s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.75, val_lr=2e-5]  9%|▉         | 88/1000 [19:31:05<187:25:46, 739.85s/epoch, accuracy=0.734, loss=0.754, lr=2e-5, val_accuracy=0.736, val_loss=0.751, val_lr=2e-5]  9%|▉         | 89/1000 [19:46:40<202:03:00, 798.44s/epoch, accuracy=0.734, loss=0.754, lr=2e-6, val_accuracy=0.736, val_loss=0.751, val_lr=2e-6]slurmstepd: error: *** JOB 62270456 ON eu-g9-020-4 CANCELLED AT 2024-06-16T14:36:33 DUE TO TIME LIMIT ***
