2024-06-18 11:20:14.110419: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-18 11:20:14.112126: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 11:20:14.169820: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 11:20:14.387762: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-18 11:20:16.473459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-18 11:20:25.639657: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 1) │          4 │ inner_product[0]… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32, 8) │         64 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 8) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 8) │         32 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 16)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         85 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 185 (740.00 B)
 Trainable params: 167 (668.00 B)
 Non-trainable params: 18 (72.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [03:44<62:13:29, 224.23s/epoch, accuracy=0.601, loss=1.1, lr=0.002, val_accuracy=0.653, val_loss=0.979, val_lr=0.002]  0%|          | 2/1000 [07:25<61:44:09, 222.69s/epoch, accuracy=0.65, loss=0.971, lr=0.002, val_accuracy=0.659, val_loss=0.955, val_lr=0.002]  0%|          | 3/1000 [11:07<61:33:38, 222.29s/epoch, accuracy=0.654, loss=0.957, lr=0.002, val_accuracy=0.663, val_loss=0.945, val_lr=0.002]  0%|          | 4/1000 [14:49<61:25:53, 222.04s/epoch, accuracy=0.657, loss=0.949, lr=0.002, val_accuracy=0.664, val_loss=0.941, val_lr=0.002]  0%|          | 5/1000 [18:30<61:17:18, 221.75s/epoch, accuracy=0.659, loss=0.942, lr=0.002, val_accuracy=0.667, val_loss=0.935, val_lr=0.002]  1%|          | 6/1000 [22:12<61:16:11, 221.90s/epoch, accuracy=0.659, loss=0.938, lr=0.002, val_accuracy=0.659, val_loss=0.941, val_lr=0.002]  1%|          | 7/1000 [25:54<61:09:26, 221.72s/epoch, accuracy=0.66, loss=0.935, lr=0.002, val_accuracy=0.663, val_loss=0.931, val_lr=0.002]   1%|          | 8/1000 [29:37<61:12:52, 222.15s/epoch, accuracy=0.661, loss=0.931, lr=0.002, val_accuracy=0.668, val_loss=0.925, val_lr=0.002]  1%|          | 9/1000 [33:20<61:13:47, 222.43s/epoch, accuracy=0.661, loss=0.928, lr=0.002, val_accuracy=0.657, val_loss=0.94, val_lr=0.002]   1%|          | 10/1000 [37:03<61:13:12, 222.62s/epoch, accuracy=0.661, loss=0.927, lr=0.002, val_accuracy=0.669, val_loss=0.923, val_lr=0.002]  1%|          | 11/1000 [40:39<60:36:28, 220.62s/epoch, accuracy=0.662, loss=0.924, lr=0.002, val_accuracy=0.67, val_loss=0.91, val_lr=0.002]    1%|          | 12/1000 [44:08<59:34:19, 217.06s/epoch, accuracy=0.663, loss=0.921, lr=0.002, val_accuracy=0.67, val_loss=0.911, val_lr=0.002]  1%|▏         | 13/1000 [47:36<58:48:53, 214.52s/epoch, accuracy=0.663, loss=0.919, lr=0.002, val_accuracy=0.668, val_loss=0.915, val_lr=0.002]  1%|▏         | 14/1000 [51:05<58:14:41, 212.66s/epoch, accuracy=0.664, loss=0.918, lr=0.002, val_accuracy=0.667, val_loss=0.915, val_lr=0.002]  2%|▏         | 15/1000 [54:33<57:48:54, 211.30s/epoch, accuracy=0.664, loss=0.917, lr=0.002, val_accuracy=0.67, val_loss=0.912, val_lr=0.002]   2%|▏         | 16/1000 [58:01<57:28:37, 210.28s/epoch, accuracy=0.664, loss=0.916, lr=0.002, val_accuracy=0.661, val_loss=0.927, val_lr=0.002]  2%|▏         | 17/1000 [1:01:27<57:04:49, 209.04s/epoch, accuracy=0.664, loss=0.915, lr=0.002, val_accuracy=0.671, val_loss=0.913, val_lr=0.002]  2%|▏         | 18/1000 [1:04:55<56:54:12, 208.61s/epoch, accuracy=0.665, loss=0.914, lr=0.002, val_accuracy=0.67, val_loss=0.919, val_lr=0.002]   2%|▏         | 19/1000 [1:08:22<56:45:40, 208.30s/epoch, accuracy=0.666, loss=0.914, lr=0.002, val_accuracy=0.664, val_loss=0.909, val_lr=0.002]  2%|▏         | 20/1000 [1:11:53<56:52:36, 208.93s/epoch, accuracy=0.666, loss=0.912, lr=0.002, val_accuracy=0.669, val_loss=0.901, val_lr=0.002]  2%|▏         | 21/1000 [1:15:24<57:00:25, 209.63s/epoch, accuracy=0.666, loss=0.912, lr=0.002, val_accuracy=0.667, val_loss=0.912, val_lr=0.002]  2%|▏         | 22/1000 [1:18:55<57:03:08, 210.01s/epoch, accuracy=0.667, loss=0.912, lr=0.002, val_accuracy=0.638, val_loss=0.94, val_lr=0.002]   2%|▏         | 23/1000 [1:22:19<56:31:57, 208.31s/epoch, accuracy=0.668, loss=0.911, lr=0.002, val_accuracy=0.666, val_loss=0.91, val_lr=0.002]  2%|▏         | 24/1000 [1:25:46<56:19:35, 207.76s/epoch, accuracy=0.668, loss=0.911, lr=0.002, val_accuracy=0.674, val_loss=0.898, val_lr=0.002]  2%|▎         | 25/1000 [1:29:08<55:51:16, 206.23s/epoch, accuracy=0.668, loss=0.91, lr=0.002, val_accuracy=0.672, val_loss=0.899, val_lr=0.002]   3%|▎         | 26/1000 [1:32:25<55:02:52, 203.46s/epoch, accuracy=0.668, loss=0.91, lr=0.002, val_accuracy=0.669, val_loss=0.913, val_lr=0.002]  3%|▎         | 27/1000 [1:35:39<54:11:53, 200.53s/epoch, accuracy=0.669, loss=0.909, lr=0.002, val_accuracy=0.67, val_loss=0.902, val_lr=0.002]  3%|▎         | 28/1000 [1:38:49<53:15:25, 197.25s/epoch, accuracy=0.669, loss=0.909, lr=0.002, val_accuracy=0.672, val_loss=0.909, val_lr=0.002]  3%|▎         | 29/1000 [1:41:58<52:33:18, 194.85s/epoch, accuracy=0.669, loss=0.909, lr=0.002, val_accuracy=0.661, val_loss=0.927, val_lr=0.002]  3%|▎         | 30/1000 [1:45:09<52:10:26, 193.64s/epoch, accuracy=0.669, loss=0.908, lr=0.002, val_accuracy=0.67, val_loss=0.901, val_lr=0.002]   3%|▎         | 31/1000 [1:48:40<53:32:35, 198.92s/epoch, accuracy=0.669, loss=0.908, lr=0.002, val_accuracy=0.672, val_loss=0.897, val_lr=0.002]  3%|▎         | 32/1000 [1:52:10<54:25:58, 202.44s/epoch, accuracy=0.67, loss=0.907, lr=0.002, val_accuracy=0.612, val_loss=0.987, val_lr=0.002]   3%|▎         | 33/1000 [1:55:42<55:05:11, 205.08s/epoch, accuracy=0.669, loss=0.908, lr=0.002, val_accuracy=0.673, val_loss=0.909, val_lr=0.002]  3%|▎         | 34/1000 [1:59:13<55:33:02, 207.02s/epoch, accuracy=0.67, loss=0.907, lr=0.002, val_accuracy=0.672, val_loss=0.904, val_lr=0.002]   4%|▎         | 35/1000 [2:02:45<55:51:19, 208.37s/epoch, accuracy=0.673, loss=0.902, lr=0.0002, val_accuracy=0.677, val_loss=0.894, val_lr=0.0002]  4%|▎         | 36/1000 [2:06:17<56:08:22, 209.65s/epoch, accuracy=0.673, loss=0.902, lr=0.0002, val_accuracy=0.677, val_loss=0.892, val_lr=0.0002]  4%|▎         | 37/1000 [2:09:50<56:20:36, 210.63s/epoch, accuracy=0.673, loss=0.902, lr=0.0002, val_accuracy=0.675, val_loss=0.893, val_lr=0.0002]  4%|▍         | 38/1000 [2:13:23<56:27:26, 211.28s/epoch, accuracy=0.673, loss=0.902, lr=0.0002, val_accuracy=0.678, val_loss=0.893, val_lr=0.0002]  4%|▍         | 39/1000 [2:16:56<56:33:05, 211.85s/epoch, accuracy=0.673, loss=0.902, lr=0.0002, val_accuracy=0.678, val_loss=0.892, val_lr=0.0002]  4%|▍         | 40/1000 [2:20:27<56:25:24, 211.59s/epoch, accuracy=0.673, loss=0.902, lr=0.0002, val_accuracy=0.678, val_loss=0.892, val_lr=0.0002]  4%|▍         | 41/1000 [2:23:57<56:12:02, 210.97s/epoch, accuracy=0.673, loss=0.901, lr=0.0002, val_accuracy=0.678, val_loss=0.892, val_lr=0.0002]  4%|▍         | 42/1000 [2:27:26<55:58:56, 210.37s/epoch, accuracy=0.673, loss=0.901, lr=0.0002, val_accuracy=0.678, val_loss=0.892, val_lr=0.0002]  4%|▍         | 43/1000 [2:30:54<55:46:43, 209.83s/epoch, accuracy=0.673, loss=0.902, lr=0.0002, val_accuracy=0.678, val_loss=0.893, val_lr=0.0002]  4%|▍         | 44/1000 [2:34:23<55:35:57, 209.37s/epoch, accuracy=0.673, loss=0.901, lr=0.0002, val_accuracy=0.676, val_loss=0.894, val_lr=0.0002]  4%|▍         | 45/1000 [2:37:51<55:29:03, 209.16s/epoch, accuracy=0.673, loss=0.901, lr=0.0002, val_accuracy=0.678, val_loss=0.893, val_lr=0.0002]  5%|▍         | 46/1000 [2:41:19<55:19:51, 208.80s/epoch, accuracy=0.673, loss=0.901, lr=0.0002, val_accuracy=0.677, val_loss=0.892, val_lr=0.0002]  5%|▍         | 47/1000 [2:44:48<55:13:40, 208.63s/epoch, accuracy=0.673, loss=0.901, lr=0.0002, val_accuracy=0.677, val_loss=0.892, val_lr=0.0002]  5%|▍         | 48/1000 [2:48:16<55:07:25, 208.45s/epoch, accuracy=0.673, loss=0.901, lr=0.0002, val_accuracy=0.678, val_loss=0.891, val_lr=0.0002]  5%|▍         | 49/1000 [2:51:43<54:57:09, 208.02s/epoch, accuracy=0.673, loss=0.901, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]      5%|▌         | 50/1000 [2:55:09<54:47:54, 207.66s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]    5%|▌         | 51/1000 [2:58:42<55:09:32, 209.24s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]  5%|▌         | 52/1000 [3:02:25<56:10:17, 213.31s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.892, val_lr=2e-5]  5%|▌         | 53/1000 [3:06:07<56:49:31, 216.02s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]  5%|▌         | 54/1000 [3:09:50<57:14:32, 217.84s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]  6%|▌         | 55/1000 [3:13:32<57:31:39, 219.15s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]  6%|▌         | 56/1000 [3:17:14<57:44:28, 220.20s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]  6%|▌         | 57/1000 [3:20:56<57:46:15, 220.55s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]  6%|▌         | 58/1000 [3:24:37<57:48:01, 220.89s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]  6%|▌         | 58/1000 [3:24:37<55:23:31, 211.69s/epoch, accuracy=0.673, loss=0.9, lr=2e-5, val_accuracy=0.678, val_loss=0.891, val_lr=2e-5]
