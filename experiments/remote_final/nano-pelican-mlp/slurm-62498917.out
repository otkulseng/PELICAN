2024-06-18 12:59:34.016573: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-18 12:59:34.016892: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 12:59:34.019961: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 12:59:34.054106: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-18 12:59:35.672705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-18 12:59:44.716870: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 8, 4)      │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 8, 8, 1), │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ (None, 8, 8, 1)]  │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 8, 8, 1)   │          4 │ inner_product[0]… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 8, 8, 6)   │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 8, 8, 2)   │         16 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 8, 8, 2)   │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 2)   │          8 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 4)         │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         25 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 53 (212.00 B)
 Trainable params: 47 (188.00 B)
 Non-trainable params: 6 (24.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [00:18<5:06:39, 18.42s/epoch, accuracy=0.355, loss=1.43, lr=0.002, val_accuracy=0.381, val_loss=1.38, val_lr=0.002]  0%|          | 2/1000 [00:34<4:46:12, 17.21s/epoch, accuracy=0.384, loss=1.37, lr=0.002, val_accuracy=0.381, val_loss=1.37, val_lr=0.002]  0%|          | 3/1000 [00:51<4:39:59, 16.85s/epoch, accuracy=0.387, loss=1.36, lr=0.002, val_accuracy=0.389, val_loss=1.35, val_lr=0.002]  0%|          | 4/1000 [01:07<4:35:51, 16.62s/epoch, accuracy=0.393, loss=1.35, lr=0.002, val_accuracy=0.394, val_loss=1.35, val_lr=0.002]  0%|          | 5/1000 [01:23<4:33:45, 16.51s/epoch, accuracy=0.402, loss=1.34, lr=0.002, val_accuracy=0.404, val_loss=1.34, val_lr=0.002]  1%|          | 6/1000 [01:40<4:32:23, 16.44s/epoch, accuracy=0.407, loss=1.34, lr=0.002, val_accuracy=0.403, val_loss=1.34, val_lr=0.002]  1%|          | 7/1000 [01:56<4:31:14, 16.39s/epoch, accuracy=0.409, loss=1.33, lr=0.002, val_accuracy=0.407, val_loss=1.33, val_lr=0.002]  1%|          | 8/1000 [02:12<4:30:23, 16.35s/epoch, accuracy=0.411, loss=1.33, lr=0.002, val_accuracy=0.409, val_loss=1.33, val_lr=0.002]  1%|          | 9/1000 [02:28<4:29:50, 16.34s/epoch, accuracy=0.412, loss=1.33, lr=0.002, val_accuracy=0.412, val_loss=1.33, val_lr=0.002]  1%|          | 10/1000 [02:45<4:29:46, 16.35s/epoch, accuracy=0.413, loss=1.33, lr=0.002, val_accuracy=0.411, val_loss=1.33, val_lr=0.002]  1%|          | 11/1000 [03:05<4:50:20, 17.61s/epoch, accuracy=0.413, loss=1.33, lr=0.002, val_accuracy=0.412, val_loss=1.33, val_lr=0.002]  1%|          | 12/1000 [03:22<4:43:32, 17.22s/epoch, accuracy=0.414, loss=1.33, lr=0.002, val_accuracy=0.41, val_loss=1.33, val_lr=0.002]   1%|▏         | 13/1000 [03:38<4:38:33, 16.93s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.408, val_loss=1.33, val_lr=0.002]  1%|▏         | 14/1000 [03:54<4:34:56, 16.73s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.409, val_loss=1.33, val_lr=0.002]  2%|▏         | 15/1000 [04:10<4:32:13, 16.58s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.408, val_loss=1.33, val_lr=0.002]  2%|▏         | 16/1000 [04:27<4:30:18, 16.48s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.413, val_loss=1.33, val_lr=0.002]  2%|▏         | 17/1000 [04:43<4:29:36, 16.46s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.411, val_loss=1.33, val_lr=0.002]  2%|▏         | 18/1000 [04:59<4:29:15, 16.45s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.411, val_loss=1.32, val_lr=0.002]  2%|▏         | 19/1000 [05:16<4:28:47, 16.44s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.411, val_loss=1.33, val_lr=0.002]  2%|▏         | 20/1000 [05:32<4:28:17, 16.43s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.411, val_loss=1.32, val_lr=0.002]  2%|▏         | 21/1000 [05:49<4:27:23, 16.39s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.405, val_loss=1.33, val_lr=0.002]  2%|▏         | 22/1000 [06:05<4:26:11, 16.33s/epoch, accuracy=0.415, loss=1.32, lr=0.002, val_accuracy=0.41, val_loss=1.32, val_lr=0.002]   2%|▏         | 23/1000 [06:21<4:26:24, 16.36s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.408, val_loss=1.33, val_lr=0.002]  2%|▏         | 24/1000 [06:38<4:26:15, 16.37s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.412, val_loss=1.33, val_lr=0.002]  2%|▎         | 25/1000 [06:54<4:25:31, 16.34s/epoch, accuracy=0.414, loss=1.32, lr=0.002, val_accuracy=0.411, val_loss=1.33, val_lr=0.002]  3%|▎         | 26/1000 [07:10<4:24:38, 16.30s/epoch, accuracy=0.415, loss=1.32, lr=0.002, val_accuracy=0.411, val_loss=1.32, val_lr=0.002]  3%|▎         | 27/1000 [07:26<4:24:07, 16.29s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.411, val_loss=1.32, val_lr=0.0002]  3%|▎         | 28/1000 [07:43<4:24:24, 16.32s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.411, val_loss=1.32, val_lr=0.0002]  3%|▎         | 29/1000 [07:59<4:23:43, 16.30s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.409, val_loss=1.33, val_lr=0.0002]  3%|▎         | 30/1000 [08:15<4:23:58, 16.33s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.411, val_loss=1.32, val_lr=0.0002]  3%|▎         | 31/1000 [08:32<4:23:16, 16.30s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.41, val_loss=1.33, val_lr=0.0002]   3%|▎         | 32/1000 [08:48<4:22:42, 16.28s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.412, val_loss=1.32, val_lr=0.0002]  3%|▎         | 33/1000 [09:04<4:22:07, 16.26s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.41, val_loss=1.33, val_lr=0.0002]   3%|▎         | 34/1000 [09:20<4:22:02, 16.28s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.411, val_loss=1.32, val_lr=0.0002]  4%|▎         | 35/1000 [09:37<4:21:28, 16.26s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.412, val_loss=1.33, val_lr=0.0002]  4%|▎         | 36/1000 [09:53<4:21:26, 16.27s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.412, val_loss=1.33, val_lr=0.0002]  4%|▎         | 36/1000 [09:53<4:24:50, 16.48s/epoch, accuracy=0.415, loss=1.32, lr=0.0002, val_accuracy=0.412, val_loss=1.33, val_lr=0.0002]
