2024-06-18 11:44:40.427453: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 11:44:40.501098: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 11:44:40.797653: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-18 11:44:44.900835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-18 11:44:56.513036: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 16, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 16, 16,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 16,    │            │                   │
│                     │ 16, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 16, 16, 1) │          4 │ inner_product[0]… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 16, 16, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 16, 16, 8) │         64 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 16, 16, 8) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16, 8) │         32 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 16)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         85 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 185 (740.00 B)
 Trainable params: 167 (668.00 B)
 Non-trainable params: 18 (72.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [01:23<23:11:52, 83.60s/epoch, accuracy=0.497, loss=1.23, lr=0.002, val_accuracy=0.527, val_loss=1.15, val_lr=0.002]  0%|          | 2/1000 [02:44<22:41:38, 81.86s/epoch, accuracy=0.53, loss=1.14, lr=0.002, val_accuracy=0.533, val_loss=1.15, val_lr=0.002]   0%|          | 3/1000 [04:08<22:56:14, 82.82s/epoch, accuracy=0.537, loss=1.14, lr=0.002, val_accuracy=0.533, val_loss=1.14, val_lr=0.002]  0%|          | 4/1000 [05:32<23:05:59, 83.49s/epoch, accuracy=0.544, loss=1.13, lr=0.002, val_accuracy=0.558, val_loss=1.12, val_lr=0.002]  0%|          | 5/1000 [06:53<22:46:07, 82.38s/epoch, accuracy=0.549, loss=1.12, lr=0.002, val_accuracy=0.564, val_loss=1.12, val_lr=0.002]  1%|          | 6/1000 [08:13<22:34:30, 81.76s/epoch, accuracy=0.553, loss=1.11, lr=0.002, val_accuracy=0.544, val_loss=1.12, val_lr=0.002]  1%|          | 7/1000 [09:34<22:28:12, 81.46s/epoch, accuracy=0.556, loss=1.11, lr=0.002, val_accuracy=0.569, val_loss=1.11, val_lr=0.002]  1%|          | 8/1000 [10:55<22:26:41, 81.45s/epoch, accuracy=0.557, loss=1.1, lr=0.002, val_accuracy=0.571, val_loss=1.1, val_lr=0.002]    1%|          | 9/1000 [12:16<22:22:55, 81.31s/epoch, accuracy=0.559, loss=1.1, lr=0.002, val_accuracy=0.56, val_loss=1.1, val_lr=0.002]   1%|          | 10/1000 [13:37<22:18:59, 81.15s/epoch, accuracy=0.561, loss=1.1, lr=0.002, val_accuracy=0.551, val_loss=1.1, val_lr=0.002]  1%|          | 11/1000 [14:58<22:16:23, 81.08s/epoch, accuracy=0.561, loss=1.09, lr=0.002, val_accuracy=0.55, val_loss=1.09, val_lr=0.002]  1%|          | 12/1000 [16:19<22:14:52, 81.07s/epoch, accuracy=0.561, loss=1.09, lr=0.002, val_accuracy=0.571, val_loss=1.09, val_lr=0.002]  1%|▏         | 13/1000 [17:40<22:12:30, 81.00s/epoch, accuracy=0.562, loss=1.09, lr=0.002, val_accuracy=0.566, val_loss=1.08, val_lr=0.002]  1%|▏         | 14/1000 [19:01<22:12:00, 81.06s/epoch, accuracy=0.563, loss=1.09, lr=0.002, val_accuracy=0.563, val_loss=1.08, val_lr=0.002]  2%|▏         | 15/1000 [20:22<22:08:18, 80.91s/epoch, accuracy=0.563, loss=1.08, lr=0.002, val_accuracy=0.574, val_loss=1.08, val_lr=0.002]  2%|▏         | 16/1000 [21:43<22:07:22, 80.94s/epoch, accuracy=0.564, loss=1.08, lr=0.002, val_accuracy=0.566, val_loss=1.09, val_lr=0.002]  2%|▏         | 17/1000 [23:04<22:07:11, 81.01s/epoch, accuracy=0.564, loss=1.08, lr=0.002, val_accuracy=0.563, val_loss=1.08, val_lr=0.002]  2%|▏         | 18/1000 [24:25<22:03:24, 80.86s/epoch, accuracy=0.564, loss=1.08, lr=0.002, val_accuracy=0.572, val_loss=1.08, val_lr=0.002]  2%|▏         | 19/1000 [25:46<22:02:57, 80.91s/epoch, accuracy=0.564, loss=1.08, lr=0.002, val_accuracy=0.55, val_loss=1.11, val_lr=0.002]   2%|▏         | 20/1000 [27:06<21:57:00, 80.63s/epoch, accuracy=0.565, loss=1.08, lr=0.002, val_accuracy=0.574, val_loss=1.08, val_lr=0.002]  2%|▏         | 21/1000 [28:26<21:52:43, 80.45s/epoch, accuracy=0.566, loss=1.08, lr=0.002, val_accuracy=0.565, val_loss=1.08, val_lr=0.002]  2%|▏         | 22/1000 [29:46<21:51:30, 80.46s/epoch, accuracy=0.566, loss=1.08, lr=0.002, val_accuracy=0.57, val_loss=1.08, val_lr=0.002]   2%|▏         | 23/1000 [31:06<21:46:26, 80.23s/epoch, accuracy=0.567, loss=1.08, lr=0.002, val_accuracy=0.556, val_loss=1.08, val_lr=0.002]  2%|▏         | 24/1000 [32:27<21:47:58, 80.41s/epoch, accuracy=0.566, loss=1.08, lr=0.002, val_accuracy=0.571, val_loss=1.07, val_lr=0.002]  2%|▎         | 25/1000 [33:46<21:42:58, 80.18s/epoch, accuracy=0.567, loss=1.08, lr=0.002, val_accuracy=0.567, val_loss=1.08, val_lr=0.002]  3%|▎         | 26/1000 [35:07<21:44:11, 80.34s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  3%|▎         | 27/1000 [36:28<21:45:30, 80.50s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.573, val_loss=1.07, val_lr=0.0002]  3%|▎         | 28/1000 [37:49<21:45:38, 80.60s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.575, val_loss=1.07, val_lr=0.0002]  3%|▎         | 29/1000 [39:09<21:45:34, 80.67s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  3%|▎         | 30/1000 [40:30<21:44:27, 80.69s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.575, val_loss=1.07, val_lr=0.0002]  3%|▎         | 31/1000 [41:51<21:45:43, 80.85s/epoch, accuracy=0.571, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  3%|▎         | 32/1000 [43:12<21:44:23, 80.85s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.577, val_loss=1.07, val_lr=0.0002]   3%|▎         | 33/1000 [44:32<21:39:06, 80.61s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  3%|▎         | 34/1000 [45:53<21:38:01, 80.62s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  4%|▎         | 35/1000 [47:14<21:36:58, 80.64s/epoch, accuracy=0.57, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  4%|▎         | 36/1000 [48:34<21:34:41, 80.58s/epoch, accuracy=0.571, loss=1.07, lr=0.0002, val_accuracy=0.572, val_loss=1.07, val_lr=0.0002]  4%|▎         | 37/1000 [49:55<21:34:33, 80.66s/epoch, accuracy=0.571, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  4%|▍         | 38/1000 [51:16<21:34:05, 80.71s/epoch, accuracy=0.571, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  4%|▍         | 39/1000 [52:36<21:30:52, 80.60s/epoch, accuracy=0.571, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  4%|▍         | 40/1000 [53:57<21:32:51, 80.80s/epoch, accuracy=0.571, loss=1.07, lr=0.0002, val_accuracy=0.577, val_loss=1.07, val_lr=0.0002]  4%|▍         | 41/1000 [55:17<21:27:19, 80.54s/epoch, accuracy=0.571, loss=1.07, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  4%|▍         | 42/1000 [56:37<21:23:04, 80.36s/epoch, accuracy=0.571, loss=1.07, lr=0.0002, val_accuracy=0.574, val_loss=1.07, val_lr=0.0002]  4%|▍         | 43/1000 [57:58<21:23:32, 80.47s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]      4%|▍         | 44/1000 [59:19<21:24:22, 80.61s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  4%|▍         | 45/1000 [1:00:40<21:23:02, 80.61s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  5%|▍         | 46/1000 [1:02:00<21:21:14, 80.58s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  5%|▍         | 47/1000 [1:03:20<21:19:06, 80.53s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  5%|▍         | 48/1000 [1:04:41<21:18:44, 80.59s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  5%|▍         | 49/1000 [1:06:01<21:15:55, 80.50s/epoch, accuracy=0.571, loss=1.07, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  5%|▌         | 50/1000 [1:07:22<21:14:37, 80.50s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  5%|▌         | 51/1000 [1:08:42<21:13:16, 80.50s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  5%|▌         | 52/1000 [1:10:03<21:11:47, 80.49s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.575, val_loss=1.07, val_lr=2e-5]  5%|▌         | 53/1000 [1:11:23<21:10:08, 80.47s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  5%|▌         | 54/1000 [1:12:44<21:09:51, 80.54s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  6%|▌         | 55/1000 [1:14:04<21:07:30, 80.48s/epoch, accuracy=0.572, loss=1.07, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  6%|▌         | 56/1000 [1:15:25<21:07:44, 80.58s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.577, val_loss=1.07, val_lr=2e-6]  6%|▌         | 57/1000 [1:16:46<21:06:39, 80.59s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.577, val_loss=1.07, val_lr=2e-6]  6%|▌         | 58/1000 [1:18:07<21:07:20, 80.72s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  6%|▌         | 59/1000 [1:19:28<21:08:44, 80.90s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.577, val_loss=1.07, val_lr=2e-6]  6%|▌         | 60/1000 [1:20:49<21:08:02, 80.94s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.577, val_loss=1.07, val_lr=2e-6]  6%|▌         | 61/1000 [1:22:10<21:05:20, 80.85s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  6%|▌         | 62/1000 [1:23:30<21:00:19, 80.62s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  6%|▋         | 63/1000 [1:24:49<20:53:52, 80.29s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.577, val_loss=1.07, val_lr=2e-6]  6%|▋         | 64/1000 [1:26:10<20:53:24, 80.35s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  6%|▋         | 65/1000 [1:27:31<20:53:35, 80.44s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  6%|▋         | 65/1000 [1:27:31<20:58:55, 80.79s/epoch, accuracy=0.572, loss=1.07, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]
