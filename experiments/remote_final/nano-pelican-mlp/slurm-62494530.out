2024-06-18 11:44:29.906962: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-18 11:44:29.908923: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 11:44:29.978365: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 11:44:30.262915: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-18 11:44:32.813368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-18 11:44:46.249670: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 16, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 16, 16,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 16,    │            │                   │
│                     │ 16, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 16, 16, 1) │          4 │ inner_product[0]… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 16, 16, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 16, 16, 8) │         64 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 16, 16, 8) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16, 8) │         32 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 16)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         85 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 185 (740.00 B)
 Trainable params: 167 (668.00 B)
 Non-trainable params: 18 (72.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [00:56<15:36:24, 56.24s/epoch, accuracy=0.493, loss=1.24, lr=0.002, val_accuracy=0.52, val_loss=1.16, val_lr=0.002]  0%|          | 2/1000 [01:49<15:05:20, 54.43s/epoch, accuracy=0.528, loss=1.15, lr=0.002, val_accuracy=0.53, val_loss=1.14, val_lr=0.002]  0%|          | 3/1000 [02:43<14:58:10, 54.05s/epoch, accuracy=0.536, loss=1.13, lr=0.002, val_accuracy=0.536, val_loss=1.13, val_lr=0.002]  0%|          | 4/1000 [03:35<14:50:01, 53.62s/epoch, accuracy=0.541, loss=1.12, lr=0.002, val_accuracy=0.519, val_loss=1.12, val_lr=0.002]  0%|          | 5/1000 [04:29<14:47:26, 53.51s/epoch, accuracy=0.545, loss=1.12, lr=0.002, val_accuracy=0.548, val_loss=1.11, val_lr=0.002]  1%|          | 6/1000 [05:22<14:45:53, 53.47s/epoch, accuracy=0.547, loss=1.11, lr=0.002, val_accuracy=0.537, val_loss=1.11, val_lr=0.002]  1%|          | 7/1000 [06:16<14:46:13, 53.55s/epoch, accuracy=0.549, loss=1.11, lr=0.002, val_accuracy=0.547, val_loss=1.11, val_lr=0.002]  1%|          | 8/1000 [07:10<14:46:25, 53.61s/epoch, accuracy=0.551, loss=1.1, lr=0.002, val_accuracy=0.551, val_loss=1.1, val_lr=0.002]    1%|          | 9/1000 [08:03<14:43:39, 53.50s/epoch, accuracy=0.552, loss=1.1, lr=0.002, val_accuracy=0.547, val_loss=1.1, val_lr=0.002]  1%|          | 10/1000 [08:56<14:41:29, 53.42s/epoch, accuracy=0.553, loss=1.1, lr=0.002, val_accuracy=0.557, val_loss=1.1, val_lr=0.002]  1%|          | 11/1000 [09:50<14:40:37, 53.43s/epoch, accuracy=0.554, loss=1.1, lr=0.002, val_accuracy=0.563, val_loss=1.1, val_lr=0.002]  1%|          | 12/1000 [10:43<14:38:13, 53.33s/epoch, accuracy=0.554, loss=1.09, lr=0.002, val_accuracy=0.549, val_loss=1.1, val_lr=0.002]  1%|▏         | 13/1000 [11:36<14:37:34, 53.35s/epoch, accuracy=0.556, loss=1.09, lr=0.002, val_accuracy=0.551, val_loss=1.09, val_lr=0.002]  1%|▏         | 14/1000 [12:30<14:37:15, 53.38s/epoch, accuracy=0.556, loss=1.09, lr=0.002, val_accuracy=0.552, val_loss=1.09, val_lr=0.002]  2%|▏         | 15/1000 [13:23<14:36:20, 53.38s/epoch, accuracy=0.558, loss=1.09, lr=0.002, val_accuracy=0.551, val_loss=1.09, val_lr=0.002]  2%|▏         | 16/1000 [14:16<14:35:41, 53.40s/epoch, accuracy=0.558, loss=1.09, lr=0.002, val_accuracy=0.563, val_loss=1.09, val_lr=0.002]  2%|▏         | 17/1000 [15:10<14:35:43, 53.45s/epoch, accuracy=0.559, loss=1.09, lr=0.002, val_accuracy=0.567, val_loss=1.09, val_lr=0.002]  2%|▏         | 18/1000 [16:03<14:34:30, 53.43s/epoch, accuracy=0.56, loss=1.09, lr=0.002, val_accuracy=0.546, val_loss=1.09, val_lr=0.002]   2%|▏         | 19/1000 [16:57<14:33:41, 53.44s/epoch, accuracy=0.56, loss=1.09, lr=0.002, val_accuracy=0.566, val_loss=1.08, val_lr=0.002]  2%|▏         | 20/1000 [17:50<14:31:22, 53.35s/epoch, accuracy=0.562, loss=1.09, lr=0.002, val_accuracy=0.565, val_loss=1.08, val_lr=0.002]  2%|▏         | 21/1000 [18:43<14:30:53, 53.37s/epoch, accuracy=0.563, loss=1.08, lr=0.002, val_accuracy=0.548, val_loss=1.09, val_lr=0.002]  2%|▏         | 22/1000 [19:37<14:29:22, 53.34s/epoch, accuracy=0.564, loss=1.08, lr=0.002, val_accuracy=0.55, val_loss=1.09, val_lr=0.002]   2%|▏         | 23/1000 [20:30<14:28:20, 53.33s/epoch, accuracy=0.565, loss=1.08, lr=0.002, val_accuracy=0.546, val_loss=1.09, val_lr=0.002]  2%|▏         | 24/1000 [21:23<14:27:00, 53.30s/epoch, accuracy=0.565, loss=1.08, lr=0.002, val_accuracy=0.557, val_loss=1.08, val_lr=0.002]  2%|▎         | 25/1000 [22:17<14:27:06, 53.36s/epoch, accuracy=0.566, loss=1.08, lr=0.002, val_accuracy=0.549, val_loss=1.09, val_lr=0.002]  3%|▎         | 26/1000 [23:11<14:28:56, 53.53s/epoch, accuracy=0.565, loss=1.08, lr=0.002, val_accuracy=0.545, val_loss=1.09, val_lr=0.002]  3%|▎         | 27/1000 [24:04<14:26:30, 53.43s/epoch, accuracy=0.565, loss=1.08, lr=0.002, val_accuracy=0.55, val_loss=1.09, val_lr=0.002]   3%|▎         | 28/1000 [24:57<14:25:35, 53.43s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.575, val_loss=1.08, val_lr=0.0002]  3%|▎         | 29/1000 [25:50<14:23:58, 53.39s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.571, val_loss=1.08, val_lr=0.0002]  3%|▎         | 30/1000 [26:44<14:23:00, 53.38s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.573, val_loss=1.08, val_lr=0.0002]  3%|▎         | 31/1000 [27:37<14:20:30, 53.28s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.578, val_loss=1.08, val_lr=0.0002]  3%|▎         | 32/1000 [28:30<14:19:14, 53.26s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.578, val_loss=1.08, val_lr=0.0002]  3%|▎         | 33/1000 [29:23<14:17:20, 53.20s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.568, val_loss=1.08, val_lr=0.0002]  3%|▎         | 34/1000 [30:17<14:17:23, 53.25s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.576, val_loss=1.08, val_lr=0.0002]  4%|▎         | 35/1000 [31:10<14:17:09, 53.30s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.575, val_loss=1.07, val_lr=0.0002]  4%|▎         | 36/1000 [32:03<14:15:51, 53.27s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.576, val_loss=1.08, val_lr=0.0002]  4%|▎         | 37/1000 [32:56<14:14:10, 53.22s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.573, val_loss=1.07, val_lr=0.0002]  4%|▍         | 38/1000 [33:50<14:14:41, 53.31s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.578, val_loss=1.08, val_lr=0.0002]  4%|▍         | 39/1000 [34:43<14:12:52, 53.25s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.57, val_loss=1.07, val_lr=0.0002]   4%|▍         | 40/1000 [35:36<14:11:56, 53.25s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.575, val_loss=1.07, val_lr=0.0002]  4%|▍         | 41/1000 [36:29<14:09:41, 53.16s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.576, val_loss=1.07, val_lr=0.0002]  4%|▍         | 42/1000 [37:23<14:10:43, 53.28s/epoch, accuracy=0.568, loss=1.08, lr=0.0002, val_accuracy=0.575, val_loss=1.07, val_lr=0.0002]  4%|▍         | 43/1000 [38:16<14:09:11, 53.24s/epoch, accuracy=0.568, loss=1.08, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]      4%|▍         | 44/1000 [39:09<14:09:10, 53.30s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.575, val_loss=1.07, val_lr=2e-5]  4%|▍         | 45/1000 [40:03<14:08:53, 53.33s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  5%|▍         | 46/1000 [40:56<14:06:47, 53.26s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  5%|▍         | 47/1000 [41:49<14:05:28, 53.23s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.574, val_loss=1.07, val_lr=2e-5]  5%|▍         | 48/1000 [42:42<14:03:32, 53.16s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  5%|▍         | 49/1000 [43:34<13:59:51, 52.99s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.579, val_loss=1.07, val_lr=2e-5]  5%|▌         | 50/1000 [44:28<14:01:31, 53.15s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.573, val_loss=1.07, val_lr=2e-5]  5%|▌         | 51/1000 [45:22<14:02:24, 53.26s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.574, val_loss=1.07, val_lr=2e-5]  5%|▌         | 52/1000 [46:15<14:00:46, 53.21s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.575, val_loss=1.07, val_lr=2e-5]  5%|▌         | 53/1000 [47:08<14:01:49, 53.34s/epoch, accuracy=0.568, loss=1.08, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  5%|▌         | 54/1000 [48:02<14:01:52, 53.40s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.574, val_loss=1.07, val_lr=2e-5]  6%|▌         | 55/1000 [48:55<14:01:16, 53.41s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.572, val_loss=1.07, val_lr=2e-5]  6%|▌         | 56/1000 [49:48<13:58:29, 53.29s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  6%|▌         | 57/1000 [50:41<13:56:48, 53.24s/epoch, accuracy=0.568, loss=1.08, lr=2e-5, val_accuracy=0.577, val_loss=1.07, val_lr=2e-5]  6%|▌         | 58/1000 [51:35<13:56:16, 53.27s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.576, val_loss=1.07, val_lr=2e-5]  6%|▌         | 59/1000 [52:28<13:54:20, 53.20s/epoch, accuracy=0.569, loss=1.08, lr=2e-5, val_accuracy=0.573, val_loss=1.07, val_lr=2e-5]  6%|▌         | 60/1000 [53:21<13:55:04, 53.30s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.577, val_loss=1.07, val_lr=2e-6]  6%|▌         | 61/1000 [54:14<13:52:53, 53.22s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.577, val_loss=1.07, val_lr=2e-6]  6%|▌         | 62/1000 [55:08<13:54:41, 53.39s/epoch, accuracy=0.568, loss=1.08, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  6%|▋         | 63/1000 [56:01<13:53:08, 53.35s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.577, val_loss=1.07, val_lr=2e-6]  6%|▋         | 64/1000 [56:55<13:52:16, 53.35s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  6%|▋         | 65/1000 [57:48<13:50:48, 53.31s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.574, val_loss=1.07, val_lr=2e-6]  7%|▋         | 66/1000 [58:41<13:49:54, 53.31s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.575, val_loss=1.07, val_lr=2e-6]  7%|▋         | 67/1000 [59:34<13:48:33, 53.28s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  7%|▋         | 68/1000 [1:00:28<13:47:17, 53.26s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.575, val_loss=1.07, val_lr=2e-6]  7%|▋         | 69/1000 [1:01:21<13:47:39, 53.34s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]  7%|▋         | 69/1000 [1:01:21<13:47:55, 53.36s/epoch, accuracy=0.569, loss=1.08, lr=2e-6, val_accuracy=0.576, val_loss=1.07, val_lr=2e-6]
