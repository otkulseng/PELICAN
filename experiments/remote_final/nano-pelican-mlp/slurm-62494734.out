2024-06-18 12:44:00.648647: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-18 12:44:00.650634: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 12:44:00.875796: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 12:44:01.115582: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-18 12:44:03.797058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-18 12:44:12.929474: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 8, 4)      │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 8, 8, 1), │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ (None, 8, 8, 1)]  │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 8, 8, 1)   │          4 │ inner_product[0]… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 8, 8, 6)   │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 8, 8, 8)   │         64 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 8, 8, 8)   │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 8)   │         32 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 16)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         85 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 185 (740.00 B)
 Trainable params: 167 (668.00 B)
 Non-trainable params: 18 (72.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [00:24<6:53:17, 24.82s/epoch, accuracy=0.391, loss=1.4, lr=0.002, val_accuracy=0.393, val_loss=1.35, val_lr=0.002]  0%|          | 2/1000 [00:46<6:26:19, 23.23s/epoch, accuracy=0.421, loss=1.32, lr=0.002, val_accuracy=0.429, val_loss=1.31, val_lr=0.002]  0%|          | 3/1000 [01:09<6:18:10, 22.76s/epoch, accuracy=0.44, loss=1.29, lr=0.002, val_accuracy=0.442, val_loss=1.29, val_lr=0.002]   0%|          | 4/1000 [01:31<6:13:01, 22.47s/epoch, accuracy=0.449, loss=1.28, lr=0.002, val_accuracy=0.447, val_loss=1.28, val_lr=0.002]  0%|          | 5/1000 [01:53<6:10:15, 22.33s/epoch, accuracy=0.454, loss=1.27, lr=0.002, val_accuracy=0.45, val_loss=1.28, val_lr=0.002]   1%|          | 6/1000 [02:15<6:09:07, 22.28s/epoch, accuracy=0.458, loss=1.27, lr=0.002, val_accuracy=0.458, val_loss=1.27, val_lr=0.002]  1%|          | 7/1000 [02:37<6:06:45, 22.16s/epoch, accuracy=0.46, loss=1.27, lr=0.002, val_accuracy=0.457, val_loss=1.27, val_lr=0.002]   1%|          | 8/1000 [02:59<6:05:25, 22.10s/epoch, accuracy=0.461, loss=1.26, lr=0.002, val_accuracy=0.463, val_loss=1.26, val_lr=0.002]  1%|          | 9/1000 [03:21<6:05:11, 22.11s/epoch, accuracy=0.462, loss=1.26, lr=0.002, val_accuracy=0.455, val_loss=1.26, val_lr=0.002]  1%|          | 10/1000 [03:43<6:03:58, 22.06s/epoch, accuracy=0.463, loss=1.26, lr=0.002, val_accuracy=0.437, val_loss=1.3, val_lr=0.002]  1%|          | 11/1000 [04:05<6:03:38, 22.06s/epoch, accuracy=0.463, loss=1.26, lr=0.002, val_accuracy=0.462, val_loss=1.26, val_lr=0.002]  1%|          | 12/1000 [04:27<6:03:19, 22.06s/epoch, accuracy=0.464, loss=1.26, lr=0.002, val_accuracy=0.459, val_loss=1.26, val_lr=0.002]  1%|▏         | 13/1000 [04:49<6:02:24, 22.03s/epoch, accuracy=0.464, loss=1.26, lr=0.002, val_accuracy=0.461, val_loss=1.26, val_lr=0.002]  1%|▏         | 14/1000 [05:11<6:02:25, 22.05s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.457, val_loss=1.26, val_lr=0.002]  2%|▏         | 15/1000 [05:33<6:01:55, 22.05s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.421, val_loss=1.27, val_lr=0.002]  2%|▏         | 16/1000 [05:55<6:01:04, 22.02s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.452, val_loss=1.26, val_lr=0.002]  2%|▏         | 17/1000 [06:17<6:00:59, 22.03s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.462, val_loss=1.26, val_lr=0.002]  2%|▏         | 18/1000 [06:39<6:00:09, 22.01s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.454, val_loss=1.26, val_lr=0.002]  2%|▏         | 19/1000 [07:01<5:59:23, 21.98s/epoch, accuracy=0.465, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  2%|▏         | 20/1000 [07:23<5:59:05, 21.98s/epoch, accuracy=0.465, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  2%|▏         | 21/1000 [07:45<5:58:54, 22.00s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.462, val_loss=1.26, val_lr=0.0002]  2%|▏         | 22/1000 [08:07<5:57:50, 21.95s/epoch, accuracy=0.465, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  2%|▏         | 23/1000 [08:29<5:58:07, 21.99s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  2%|▏         | 24/1000 [08:51<5:57:56, 22.00s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.462, val_loss=1.26, val_lr=0.0002]  2%|▎         | 25/1000 [09:13<5:57:31, 22.00s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.463, val_loss=1.25, val_lr=0.0002]  3%|▎         | 26/1000 [09:35<5:57:05, 22.00s/epoch, accuracy=0.465, loss=1.25, lr=0.0002, val_accuracy=0.46, val_loss=1.26, val_lr=0.0002]   3%|▎         | 27/1000 [09:57<5:56:38, 21.99s/epoch, accuracy=0.465, loss=1.25, lr=0.0002, val_accuracy=0.462, val_loss=1.26, val_lr=0.0002]  3%|▎         | 28/1000 [10:19<5:55:44, 21.96s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.463, val_loss=1.25, val_lr=0.0002]  3%|▎         | 29/1000 [10:41<5:55:37, 21.98s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.26, val_lr=0.0002]  3%|▎         | 30/1000 [11:03<5:55:17, 21.98s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  3%|▎         | 31/1000 [11:25<5:54:53, 21.97s/epoch, accuracy=0.465, loss=1.25, lr=0.0002, val_accuracy=0.463, val_loss=1.25, val_lr=0.0002]  3%|▎         | 32/1000 [11:47<5:54:46, 21.99s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  3%|▎         | 33/1000 [12:09<5:54:06, 21.97s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  3%|▎         | 34/1000 [12:31<5:53:02, 21.93s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.463, val_loss=1.25, val_lr=2e-5]      4%|▎         | 35/1000 [12:53<5:52:55, 21.94s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  4%|▎         | 36/1000 [13:15<5:53:20, 21.99s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  4%|▎         | 37/1000 [13:37<5:53:07, 22.00s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.463, val_loss=1.26, val_lr=2e-5]  4%|▍         | 38/1000 [13:59<5:52:34, 21.99s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.463, val_loss=1.25, val_lr=2e-5]  4%|▍         | 39/1000 [14:21<5:52:10, 21.99s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.462, val_loss=1.25, val_lr=2e-5]  4%|▍         | 40/1000 [14:43<5:51:25, 21.96s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.463, val_loss=1.26, val_lr=2e-5]  4%|▍         | 41/1000 [15:04<5:50:50, 21.95s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  4%|▍         | 42/1000 [15:26<5:50:27, 21.95s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.463, val_loss=1.25, val_lr=2e-5]  4%|▍         | 43/1000 [15:48<5:50:14, 21.96s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  4%|▍         | 43/1000 [15:48<5:51:58, 22.07s/epoch, accuracy=0.466, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]
