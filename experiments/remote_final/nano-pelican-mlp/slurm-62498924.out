2024-06-18 13:06:09.624608: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-18 13:06:09.626107: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 13:06:09.672858: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 13:06:09.878438: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-18 13:06:11.589159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-18 13:06:18.819572: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 16, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 16, 16,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 16,    │            │                   │
│                     │ 16, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 16, 16, 1) │          4 │ inner_product[0]… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 16, 16, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 16, 16, 2) │         16 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 16, 16, 2) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16, 2) │          8 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 4)         │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         25 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 53 (212.00 B)
 Trainable params: 47 (188.00 B)
 Non-trainable params: 6 (24.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [00:39<10:56:50, 39.45s/epoch, accuracy=0.402, loss=1.44, lr=0.002, val_accuracy=0.388, val_loss=1.4, val_lr=0.002]  0%|          | 2/1000 [01:16<10:35:08, 38.18s/epoch, accuracy=0.493, loss=1.28, lr=0.002, val_accuracy=0.447, val_loss=1.31, val_lr=0.002]  0%|          | 3/1000 [01:54<10:27:31, 37.77s/epoch, accuracy=0.494, loss=1.21, lr=0.002, val_accuracy=0.497, val_loss=1.2, val_lr=0.002]   0%|          | 4/1000 [02:31<10:25:57, 37.71s/epoch, accuracy=0.5, loss=1.2, lr=0.002, val_accuracy=0.463, val_loss=1.2, val_lr=0.002]     0%|          | 5/1000 [03:08<10:22:34, 37.54s/epoch, accuracy=0.503, loss=1.19, lr=0.002, val_accuracy=0.508, val_loss=1.21, val_lr=0.002]  1%|          | 6/1000 [03:46<10:22:26, 37.57s/epoch, accuracy=0.505, loss=1.19, lr=0.002, val_accuracy=0.493, val_loss=1.2, val_lr=0.002]   1%|          | 7/1000 [04:24<10:23:07, 37.65s/epoch, accuracy=0.505, loss=1.19, lr=0.002, val_accuracy=0.507, val_loss=1.21, val_lr=0.002]  1%|          | 8/1000 [05:02<10:22:53, 37.67s/epoch, accuracy=0.506, loss=1.19, lr=0.002, val_accuracy=0.51, val_loss=1.22, val_lr=0.002]   1%|          | 9/1000 [05:39<10:22:30, 37.69s/epoch, accuracy=0.506, loss=1.19, lr=0.002, val_accuracy=0.475, val_loss=1.2, val_lr=0.002]  1%|          | 10/1000 [06:17<10:21:54, 37.69s/epoch, accuracy=0.51, loss=1.19, lr=0.002, val_accuracy=0.523, val_loss=1.17, val_lr=0.002]  1%|          | 11/1000 [06:55<10:20:37, 37.65s/epoch, accuracy=0.527, loss=1.16, lr=0.002, val_accuracy=0.526, val_loss=1.16, val_lr=0.002]  1%|          | 12/1000 [07:32<10:18:51, 37.58s/epoch, accuracy=0.53, loss=1.16, lr=0.002, val_accuracy=0.525, val_loss=1.18, val_lr=0.002]   1%|▏         | 13/1000 [08:09<10:14:47, 37.37s/epoch, accuracy=0.531, loss=1.16, lr=0.002, val_accuracy=0.525, val_loss=1.19, val_lr=0.002]  1%|▏         | 14/1000 [08:46<10:13:14, 37.32s/epoch, accuracy=0.532, loss=1.16, lr=0.002, val_accuracy=0.528, val_loss=1.16, val_lr=0.002]  2%|▏         | 15/1000 [09:23<10:09:49, 37.15s/epoch, accuracy=0.532, loss=1.16, lr=0.002, val_accuracy=0.491, val_loss=1.18, val_lr=0.002]  2%|▏         | 16/1000 [09:59<10:05:53, 36.94s/epoch, accuracy=0.532, loss=1.16, lr=0.002, val_accuracy=0.511, val_loss=1.16, val_lr=0.002]  2%|▏         | 17/1000 [10:36<10:04:36, 36.90s/epoch, accuracy=0.533, loss=1.16, lr=0.002, val_accuracy=0.529, val_loss=1.16, val_lr=0.002]  2%|▏         | 18/1000 [11:13<10:04:33, 36.94s/epoch, accuracy=0.533, loss=1.16, lr=0.002, val_accuracy=0.541, val_loss=1.15, val_lr=0.002]  2%|▏         | 19/1000 [11:50<10:02:02, 36.82s/epoch, accuracy=0.534, loss=1.16, lr=0.002, val_accuracy=0.523, val_loss=1.16, val_lr=0.002]  2%|▏         | 20/1000 [12:26<9:58:06, 36.62s/epoch, accuracy=0.534, loss=1.15, lr=0.002, val_accuracy=0.505, val_loss=1.16, val_lr=0.002]   2%|▏         | 21/1000 [13:02<9:54:36, 36.44s/epoch, accuracy=0.535, loss=1.15, lr=0.002, val_accuracy=0.51, val_loss=1.15, val_lr=0.002]   2%|▏         | 22/1000 [13:38<9:52:05, 36.32s/epoch, accuracy=0.535, loss=1.15, lr=0.002, val_accuracy=0.51, val_loss=1.16, val_lr=0.002]  2%|▏         | 23/1000 [14:14<9:49:00, 36.17s/epoch, accuracy=0.536, loss=1.15, lr=0.002, val_accuracy=0.545, val_loss=1.15, val_lr=0.002]  2%|▏         | 24/1000 [14:49<9:45:42, 36.01s/epoch, accuracy=0.536, loss=1.15, lr=0.002, val_accuracy=0.515, val_loss=1.15, val_lr=0.002]  2%|▎         | 25/1000 [15:25<9:44:24, 35.96s/epoch, accuracy=0.536, loss=1.15, lr=0.002, val_accuracy=0.538, val_loss=1.14, val_lr=0.002]  3%|▎         | 26/1000 [16:01<9:43:15, 35.93s/epoch, accuracy=0.538, loss=1.15, lr=0.002, val_accuracy=0.513, val_loss=1.15, val_lr=0.002]  3%|▎         | 27/1000 [16:37<9:44:18, 36.03s/epoch, accuracy=0.538, loss=1.14, lr=0.002, val_accuracy=0.511, val_loss=1.15, val_lr=0.002]  3%|▎         | 28/1000 [17:14<9:45:15, 36.13s/epoch, accuracy=0.538, loss=1.14, lr=0.002, val_accuracy=0.544, val_loss=1.14, val_lr=0.002]  3%|▎         | 29/1000 [17:50<9:45:33, 36.18s/epoch, accuracy=0.539, loss=1.14, lr=0.002, val_accuracy=0.536, val_loss=1.14, val_lr=0.002]  3%|▎         | 30/1000 [18:26<9:45:16, 36.20s/epoch, accuracy=0.54, loss=1.14, lr=0.002, val_accuracy=0.546, val_loss=1.13, val_lr=0.002]   3%|▎         | 31/1000 [19:03<9:45:13, 36.24s/epoch, accuracy=0.541, loss=1.13, lr=0.002, val_accuracy=0.518, val_loss=1.14, val_lr=0.002]  3%|▎         | 32/1000 [19:39<9:44:23, 36.22s/epoch, accuracy=0.542, loss=1.13, lr=0.002, val_accuracy=0.539, val_loss=1.13, val_lr=0.002]  3%|▎         | 33/1000 [20:15<9:43:05, 36.18s/epoch, accuracy=0.542, loss=1.13, lr=0.002, val_accuracy=0.548, val_loss=1.13, val_lr=0.002]  3%|▎         | 34/1000 [20:51<9:42:47, 36.20s/epoch, accuracy=0.543, loss=1.13, lr=0.002, val_accuracy=0.555, val_loss=1.13, val_lr=0.002]  4%|▎         | 35/1000 [21:27<9:43:18, 36.27s/epoch, accuracy=0.544, loss=1.13, lr=0.002, val_accuracy=0.523, val_loss=1.15, val_lr=0.002]  4%|▎         | 36/1000 [22:04<9:42:23, 36.25s/epoch, accuracy=0.544, loss=1.13, lr=0.002, val_accuracy=0.542, val_loss=1.13, val_lr=0.002]  4%|▎         | 37/1000 [22:40<9:41:31, 36.23s/epoch, accuracy=0.546, loss=1.13, lr=0.002, val_accuracy=0.542, val_loss=1.13, val_lr=0.002]  4%|▍         | 38/1000 [23:16<9:42:14, 36.31s/epoch, accuracy=0.547, loss=1.13, lr=0.002, val_accuracy=0.539, val_loss=1.13, val_lr=0.002]  4%|▍         | 39/1000 [23:53<9:41:16, 36.29s/epoch, accuracy=0.547, loss=1.13, lr=0.002, val_accuracy=0.538, val_loss=1.13, val_lr=0.002]  4%|▍         | 40/1000 [24:29<9:39:48, 36.24s/epoch, accuracy=0.548, loss=1.13, lr=0.002, val_accuracy=0.548, val_loss=1.13, val_lr=0.002]  4%|▍         | 41/1000 [25:05<9:39:06, 36.23s/epoch, accuracy=0.548, loss=1.12, lr=0.002, val_accuracy=0.531, val_loss=1.14, val_lr=0.002]  4%|▍         | 42/1000 [25:41<9:39:23, 36.29s/epoch, accuracy=0.548, loss=1.12, lr=0.002, val_accuracy=0.541, val_loss=1.13, val_lr=0.002]  4%|▍         | 43/1000 [26:18<9:38:17, 36.26s/epoch, accuracy=0.548, loss=1.12, lr=0.002, val_accuracy=0.549, val_loss=1.12, val_lr=0.002]  4%|▍         | 44/1000 [26:53<9:36:15, 36.17s/epoch, accuracy=0.549, loss=1.12, lr=0.002, val_accuracy=0.545, val_loss=1.12, val_lr=0.002]  4%|▍         | 45/1000 [27:30<9:38:43, 36.36s/epoch, accuracy=0.551, loss=1.12, lr=0.0002, val_accuracy=0.554, val_loss=1.12, val_lr=0.0002]  5%|▍         | 46/1000 [28:07<9:41:30, 36.57s/epoch, accuracy=0.551, loss=1.12, lr=0.0002, val_accuracy=0.555, val_loss=1.12, val_lr=0.0002]  5%|▍         | 47/1000 [28:44<9:40:01, 36.52s/epoch, accuracy=0.551, loss=1.12, lr=0.0002, val_accuracy=0.549, val_loss=1.13, val_lr=0.0002]  5%|▍         | 48/1000 [29:20<9:39:59, 36.55s/epoch, accuracy=0.551, loss=1.12, lr=0.0002, val_accuracy=0.557, val_loss=1.12, val_lr=0.0002]  5%|▍         | 49/1000 [29:57<9:40:45, 36.64s/epoch, accuracy=0.551, loss=1.12, lr=0.0002, val_accuracy=0.556, val_loss=1.12, val_lr=0.0002]  5%|▌         | 50/1000 [30:34<9:39:26, 36.60s/epoch, accuracy=0.552, loss=1.12, lr=0.0002, val_accuracy=0.548, val_loss=1.12, val_lr=0.0002]  5%|▌         | 51/1000 [31:10<9:38:18, 36.56s/epoch, accuracy=0.551, loss=1.12, lr=0.0002, val_accuracy=0.548, val_loss=1.12, val_lr=0.0002]  5%|▌         | 52/1000 [31:46<9:35:59, 36.46s/epoch, accuracy=0.552, loss=1.12, lr=0.0002, val_accuracy=0.551, val_loss=1.12, val_lr=0.0002]  5%|▌         | 53/1000 [32:23<9:34:01, 36.37s/epoch, accuracy=0.551, loss=1.12, lr=0.0002, val_accuracy=0.557, val_loss=1.12, val_lr=0.0002]  5%|▌         | 54/1000 [32:59<9:32:51, 36.33s/epoch, accuracy=0.551, loss=1.12, lr=0.0002, val_accuracy=0.543, val_loss=1.13, val_lr=0.0002]  6%|▌         | 55/1000 [33:35<9:31:36, 36.29s/epoch, accuracy=0.552, loss=1.12, lr=0.0002, val_accuracy=0.555, val_loss=1.12, val_lr=0.0002]  6%|▌         | 56/1000 [34:11<9:29:01, 36.17s/epoch, accuracy=0.552, loss=1.12, lr=0.0002, val_accuracy=0.548, val_loss=1.12, val_lr=0.0002]  6%|▌         | 57/1000 [34:48<9:31:08, 36.34s/epoch, accuracy=0.552, loss=1.12, lr=0.0002, val_accuracy=0.555, val_loss=1.12, val_lr=0.0002]  6%|▌         | 58/1000 [35:24<9:31:06, 36.38s/epoch, accuracy=0.552, loss=1.12, lr=0.0002, val_accuracy=0.553, val_loss=1.12, val_lr=0.0002]  6%|▌         | 59/1000 [36:01<9:31:10, 36.42s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.555, val_loss=1.12, val_lr=2e-5]      6%|▌         | 60/1000 [36:37<9:30:57, 36.44s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.554, val_loss=1.12, val_lr=2e-5]  6%|▌         | 61/1000 [37:14<9:30:41, 36.47s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.553, val_loss=1.12, val_lr=2e-5]  6%|▌         | 62/1000 [37:50<9:31:06, 36.53s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.553, val_loss=1.12, val_lr=2e-5]  6%|▋         | 63/1000 [38:27<9:29:49, 36.49s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.554, val_loss=1.12, val_lr=2e-5]  6%|▋         | 64/1000 [39:03<9:28:29, 36.44s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.554, val_loss=1.12, val_lr=2e-5]  6%|▋         | 65/1000 [39:40<9:27:59, 36.45s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.554, val_loss=1.12, val_lr=2e-5]  7%|▋         | 66/1000 [40:16<9:27:59, 36.49s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.555, val_loss=1.12, val_lr=2e-5]  7%|▋         | 67/1000 [40:53<9:29:00, 36.59s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.554, val_loss=1.12, val_lr=2e-5]  7%|▋         | 68/1000 [41:30<9:31:12, 36.77s/epoch, accuracy=0.552, loss=1.12, lr=2e-5, val_accuracy=0.554, val_loss=1.12, val_lr=2e-5]  7%|▋         | 69/1000 [42:07<9:30:15, 36.75s/epoch, accuracy=0.552, loss=1.12, lr=2e-6, val_accuracy=0.554, val_loss=1.12, val_lr=2e-6]  7%|▋         | 70/1000 [42:44<9:31:30, 36.87s/epoch, accuracy=0.552, loss=1.12, lr=2e-6, val_accuracy=0.554, val_loss=1.12, val_lr=2e-6]  7%|▋         | 71/1000 [43:21<9:33:09, 37.02s/epoch, accuracy=0.552, loss=1.12, lr=2e-6, val_accuracy=0.553, val_loss=1.12, val_lr=2e-6]  7%|▋         | 72/1000 [43:58<9:31:15, 36.93s/epoch, accuracy=0.552, loss=1.12, lr=2e-6, val_accuracy=0.554, val_loss=1.12, val_lr=2e-6]  7%|▋         | 73/1000 [44:35<9:31:10, 36.97s/epoch, accuracy=0.552, loss=1.12, lr=2e-6, val_accuracy=0.554, val_loss=1.12, val_lr=2e-6]  7%|▋         | 73/1000 [44:35<9:26:16, 36.65s/epoch, accuracy=0.552, loss=1.12, lr=2e-6, val_accuracy=0.554, val_loss=1.12, val_lr=2e-6]
