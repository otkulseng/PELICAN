2024-06-18 12:36:24.057382: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-18 12:36:24.062242: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 12:36:24.200338: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-18 12:36:24.734791: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-18 12:36:27.167036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-18 12:36:43.054520: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 8, 4)      │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 8, 8, 1), │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ (None, 8, 8, 1)]  │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 8, 8, 1)   │          4 │ inner_product[0]… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 8, 8, 6)   │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 8, 8, 8)   │         64 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 8, 8, 8)   │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 8)   │         32 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 16)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         85 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 185 (740.00 B)
 Trainable params: 167 (668.00 B)
 Non-trainable params: 18 (72.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [00:24<6:39:58, 24.02s/epoch, accuracy=0.397, loss=1.37, lr=0.002, val_accuracy=0.416, val_loss=1.33, val_lr=0.002]  0%|          | 2/1000 [00:45<6:16:05, 22.61s/epoch, accuracy=0.422, loss=1.31, lr=0.002, val_accuracy=0.423, val_loss=1.31, val_lr=0.002]  0%|          | 3/1000 [01:07<6:09:00, 22.21s/epoch, accuracy=0.435, loss=1.3, lr=0.002, val_accuracy=0.434, val_loss=1.29, val_lr=0.002]   0%|          | 4/1000 [01:28<6:04:26, 21.95s/epoch, accuracy=0.444, loss=1.28, lr=0.002, val_accuracy=0.441, val_loss=1.29, val_lr=0.002]  0%|          | 5/1000 [01:50<6:03:15, 21.90s/epoch, accuracy=0.449, loss=1.28, lr=0.002, val_accuracy=0.447, val_loss=1.28, val_lr=0.002]  1%|          | 6/1000 [02:12<6:01:54, 21.85s/epoch, accuracy=0.453, loss=1.27, lr=0.002, val_accuracy=0.449, val_loss=1.27, val_lr=0.002]  1%|          | 7/1000 [02:34<6:01:11, 21.82s/epoch, accuracy=0.456, loss=1.27, lr=0.002, val_accuracy=0.452, val_loss=1.27, val_lr=0.002]  1%|          | 8/1000 [02:56<6:00:31, 21.81s/epoch, accuracy=0.456, loss=1.26, lr=0.002, val_accuracy=0.453, val_loss=1.26, val_lr=0.002]  1%|          | 9/1000 [03:17<5:59:47, 21.78s/epoch, accuracy=0.456, loss=1.26, lr=0.002, val_accuracy=0.449, val_loss=1.26, val_lr=0.002]  1%|          | 10/1000 [03:39<5:58:27, 21.73s/epoch, accuracy=0.457, loss=1.26, lr=0.002, val_accuracy=0.453, val_loss=1.26, val_lr=0.002]  1%|          | 11/1000 [04:01<5:58:00, 21.72s/epoch, accuracy=0.458, loss=1.26, lr=0.002, val_accuracy=0.454, val_loss=1.26, val_lr=0.002]  1%|          | 12/1000 [04:22<5:57:20, 21.70s/epoch, accuracy=0.458, loss=1.26, lr=0.002, val_accuracy=0.454, val_loss=1.26, val_lr=0.002]  1%|▏         | 13/1000 [04:44<5:56:22, 21.66s/epoch, accuracy=0.459, loss=1.26, lr=0.002, val_accuracy=0.458, val_loss=1.26, val_lr=0.002]  1%|▏         | 14/1000 [05:05<5:55:26, 21.63s/epoch, accuracy=0.46, loss=1.26, lr=0.002, val_accuracy=0.455, val_loss=1.26, val_lr=0.002]   2%|▏         | 15/1000 [05:27<5:53:55, 21.56s/epoch, accuracy=0.46, loss=1.26, lr=0.002, val_accuracy=0.457, val_loss=1.26, val_lr=0.002]  2%|▏         | 16/1000 [05:48<5:53:32, 21.56s/epoch, accuracy=0.461, loss=1.25, lr=0.002, val_accuracy=0.458, val_loss=1.26, val_lr=0.002]  2%|▏         | 17/1000 [06:10<5:52:50, 21.54s/epoch, accuracy=0.461, loss=1.25, lr=0.002, val_accuracy=0.452, val_loss=1.26, val_lr=0.002]  2%|▏         | 18/1000 [06:31<5:52:08, 21.52s/epoch, accuracy=0.461, loss=1.25, lr=0.002, val_accuracy=0.46, val_loss=1.26, val_lr=0.002]   2%|▏         | 19/1000 [06:53<5:51:44, 21.51s/epoch, accuracy=0.462, loss=1.25, lr=0.002, val_accuracy=0.46, val_loss=1.26, val_lr=0.002]  2%|▏         | 20/1000 [07:14<5:51:06, 21.50s/epoch, accuracy=0.462, loss=1.25, lr=0.002, val_accuracy=0.456, val_loss=1.26, val_lr=0.002]  2%|▏         | 21/1000 [07:36<5:50:14, 21.47s/epoch, accuracy=0.462, loss=1.25, lr=0.002, val_accuracy=0.461, val_loss=1.25, val_lr=0.002]  2%|▏         | 22/1000 [07:57<5:50:24, 21.50s/epoch, accuracy=0.462, loss=1.25, lr=0.002, val_accuracy=0.461, val_loss=1.26, val_lr=0.002]  2%|▏         | 23/1000 [08:19<5:50:29, 21.53s/epoch, accuracy=0.463, loss=1.25, lr=0.002, val_accuracy=0.461, val_loss=1.25, val_lr=0.002]  2%|▏         | 24/1000 [08:40<5:50:31, 21.55s/epoch, accuracy=0.463, loss=1.25, lr=0.002, val_accuracy=0.462, val_loss=1.25, val_lr=0.002]  2%|▎         | 25/1000 [09:01<5:47:13, 21.37s/epoch, accuracy=0.463, loss=1.25, lr=0.002, val_accuracy=0.461, val_loss=1.25, val_lr=0.002]  3%|▎         | 26/1000 [09:22<5:44:15, 21.21s/epoch, accuracy=0.463, loss=1.25, lr=0.002, val_accuracy=0.454, val_loss=1.26, val_lr=0.002]  3%|▎         | 27/1000 [09:43<5:41:49, 21.08s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.459, val_loss=1.26, val_lr=0.002]  3%|▎         | 28/1000 [10:04<5:39:14, 20.94s/epoch, accuracy=0.463, loss=1.25, lr=0.002, val_accuracy=0.455, val_loss=1.26, val_lr=0.002]  3%|▎         | 29/1000 [10:24<5:37:53, 20.88s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.447, val_loss=1.27, val_lr=0.002]  3%|▎         | 30/1000 [10:45<5:36:57, 20.84s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.46, val_loss=1.25, val_lr=0.002]   3%|▎         | 31/1000 [11:06<5:35:57, 20.80s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.428, val_loss=1.28, val_lr=0.002]  3%|▎         | 32/1000 [11:27<5:36:01, 20.83s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.461, val_loss=1.26, val_lr=0.002]  3%|▎         | 33/1000 [11:47<5:35:22, 20.81s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.463, val_loss=1.26, val_lr=0.002]  3%|▎         | 34/1000 [12:08<5:34:11, 20.76s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.461, val_loss=1.26, val_lr=0.002]  4%|▎         | 35/1000 [12:29<5:33:57, 20.76s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.459, val_loss=1.26, val_lr=0.002]  4%|▎         | 36/1000 [12:50<5:33:12, 20.74s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.458, val_loss=1.26, val_lr=0.002]  4%|▎         | 37/1000 [13:10<5:32:25, 20.71s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.459, val_loss=1.26, val_lr=0.002]  4%|▍         | 38/1000 [13:31<5:32:04, 20.71s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.456, val_loss=1.26, val_lr=0.002]  4%|▍         | 39/1000 [13:52<5:31:58, 20.73s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.431, val_loss=1.28, val_lr=0.002]  4%|▍         | 40/1000 [14:13<5:32:34, 20.79s/epoch, accuracy=0.464, loss=1.25, lr=0.002, val_accuracy=0.461, val_loss=1.25, val_lr=0.002]  4%|▍         | 41/1000 [14:33<5:31:59, 20.77s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.463, val_loss=1.26, val_lr=0.002]  4%|▍         | 42/1000 [14:54<5:33:01, 20.86s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.458, val_loss=1.26, val_lr=0.002]  4%|▍         | 43/1000 [15:15<5:32:00, 20.82s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.464, val_loss=1.25, val_lr=0.002]  4%|▍         | 44/1000 [15:36<5:30:44, 20.76s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.462, val_loss=1.26, val_lr=0.002]  4%|▍         | 45/1000 [15:56<5:29:56, 20.73s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.46, val_loss=1.26, val_lr=0.002]   5%|▍         | 46/1000 [16:17<5:29:22, 20.72s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.456, val_loss=1.26, val_lr=0.002]  5%|▍         | 47/1000 [16:38<5:28:56, 20.71s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.463, val_loss=1.25, val_lr=0.002]  5%|▍         | 48/1000 [16:58<5:28:48, 20.72s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.458, val_loss=1.26, val_lr=0.002]  5%|▍         | 49/1000 [17:19<5:28:00, 20.70s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.442, val_loss=1.28, val_lr=0.002]  5%|▌         | 50/1000 [17:40<5:27:55, 20.71s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.438, val_loss=1.27, val_lr=0.002]  5%|▌         | 51/1000 [18:01<5:27:18, 20.69s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.458, val_loss=1.26, val_lr=0.002]  5%|▌         | 52/1000 [18:21<5:26:40, 20.68s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.46, val_loss=1.25, val_lr=0.002]   5%|▌         | 53/1000 [18:42<5:26:26, 20.68s/epoch, accuracy=0.465, loss=1.25, lr=0.002, val_accuracy=0.462, val_loss=1.25, val_lr=0.002]  5%|▌         | 54/1000 [19:03<5:26:10, 20.69s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  6%|▌         | 55/1000 [19:23<5:26:03, 20.70s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.462, val_loss=1.25, val_lr=0.0002]  6%|▌         | 56/1000 [19:44<5:25:49, 20.71s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.465, val_loss=1.25, val_lr=0.0002]  6%|▌         | 57/1000 [20:05<5:25:31, 20.71s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.463, val_loss=1.25, val_lr=0.0002]  6%|▌         | 58/1000 [20:25<5:25:10, 20.71s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.465, val_loss=1.25, val_lr=0.0002]  6%|▌         | 59/1000 [20:46<5:24:57, 20.72s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.463, val_loss=1.25, val_lr=0.0002]  6%|▌         | 60/1000 [21:07<5:24:35, 20.72s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  6%|▌         | 61/1000 [21:28<5:23:43, 20.69s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  6%|▌         | 62/1000 [21:48<5:23:13, 20.68s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.463, val_loss=1.25, val_lr=0.0002]  6%|▋         | 63/1000 [22:09<5:22:29, 20.65s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.462, val_loss=1.25, val_lr=0.0002]  6%|▋         | 64/1000 [22:29<5:22:11, 20.65s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.463, val_loss=1.25, val_lr=0.0002]  6%|▋         | 65/1000 [22:50<5:22:03, 20.67s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.464, val_loss=1.25, val_lr=0.0002]  7%|▋         | 66/1000 [23:11<5:21:22, 20.64s/epoch, accuracy=0.466, loss=1.25, lr=0.0002, val_accuracy=0.463, val_loss=1.25, val_lr=0.0002]  7%|▋         | 67/1000 [23:31<5:20:54, 20.64s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]      7%|▋         | 68/1000 [23:52<5:20:58, 20.66s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  7%|▋         | 69/1000 [24:13<5:21:08, 20.70s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.465, val_loss=1.25, val_lr=2e-5]  7%|▋         | 70/1000 [24:34<5:20:53, 20.70s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  7%|▋         | 71/1000 [24:54<5:20:44, 20.72s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.463, val_loss=1.25, val_lr=2e-5]  7%|▋         | 72/1000 [25:15<5:20:36, 20.73s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  7%|▋         | 73/1000 [25:36<5:20:04, 20.72s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  7%|▋         | 74/1000 [25:56<5:19:54, 20.73s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.465, val_loss=1.25, val_lr=2e-5]  8%|▊         | 75/1000 [26:17<5:19:04, 20.70s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.464, val_loss=1.25, val_lr=2e-5]  8%|▊         | 76/1000 [26:38<5:19:56, 20.78s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.465, val_loss=1.25, val_lr=2e-5]  8%|▊         | 76/1000 [26:38<5:23:55, 21.03s/epoch, accuracy=0.467, loss=1.25, lr=2e-5, val_accuracy=0.465, val_loss=1.25, val_lr=2e-5]
