#include "../nPELICAN.h"


// WARNING: Have been trained with the following assumptions: 
// internal_t == ap_fixed<20,12> 
// weight_t=bias_t == ap_fixed<11,3> 

//normalization constants
//these are currently NOT quantized, so should be FP
internal_t const2v0 = 0.19558259711506268;
internal_t const2v02 = 0.03825255229427292;

internal_t const2v2 = 0.1036361648878646;
internal_t const2v22 = 0.01074045467266466;

//first batchnorm [mean, weight/sqrt(var), bias]
weight_t batch1_2to2[3] = {3.996093750000000, 0.181640625000000, 0.015625000000000};

//2to2 linear layer
weight_t w1_2to2[NHIDDEN*6] = {-0.078125000000000,  0.347656250000000, -0.023437500000000,  0.363281250000000, -1.062500000000000,  0.378906250000000, -0.773437500000000,  0.480468750000000, -0.230468750000000, -0.195312500000000,  0.089843750000000, -1.285156250000000, -0.628906250000000,  0.164062500000000, -0.683593750000000,  0.070312500000000,  0.210937500000000,  0.207031250000000, -1.128906250000000, -0.050781250000000,  0.117187500000000, -0.453125000000000, -0.449218750000000, -0.730468750000000,  0.078125000000000, -0.269531250000000,  0.011718750000000,  0.050781250000000, -0.687500000000000, -0.371093750000000,  0.726562500000000,  0.445312500000000, -0.148437500000000,  0.222656250000000,  0.019531250000000,  0.335937500000000,  0.894531250000000, -1.195312500000000,  0.976562500000000,  0.222656250000000, -0.488281250000000,  0.312500000000000, -0.441406250000000,  0.105468750000000,  0.058593750000000,  0.417968750000000,  1.230468750000000, -0.031250000000000};
bias_t b1_2to2[NHIDDEN] = {-0.214843750000000, -1.093750000000000, -0.515625000000000,  0.242187500000000, -0.230468750000000, -0.113281250000000, -0.253906250000000, -0.128906250000000};
bias_t b1_diag_2to2[NHIDDEN] = { 0.304687500000000, -0.683593750000000, -0.328125000000000, -0.039062500000000, -0.199218750000000,  0.078125000000000,  1.207031250000000,  0.011718750000000};

//second batchnorm [channel][mean, weight/sqrt(var), bias]
weight_t batch2_2to0[NHIDDEN][3] = {{ 0.183593750000000,  2.922835588455200,  0.015625000000000}, { 0.601562500000000,  1.454698681831360,  0.050781250000000}, { 0.062500000000000,  7.067798137664795, -0.011718750000000}, { 0.214843750000000,  1.727672219276428,  0.187500000000000}, { 0.058593750000000,  8.720664978027344, -0.121093750000000}, { 0.410156250000000,  1.274327158927917,  0.234375000000000}, { 1.187500000000000,  0.671357691287994,  0.085937500000000}, { 0.613281250000000,  0.882586777210236, -0.222656250000000}};

//2to1 linear layer
weight_t w2_2to0[NHIDDEN*2*NOUT] = {-0.472656250000000,  0.015625000000000,  1.046875000000000,  0.562500000000000, -0.746093750000000,  0.058593750000000, -0.460937500000000, -0.308593750000000,  0.011718750000000,  0.847656250000000, -0.253906250000000,  0.496093750000000, -0.042968750000000,  0.101562500000000,  0.062500000000000, -0.125000000000000, -0.089843750000000, -0.367187500000000, -0.183593750000000, -0.429687500000000,  0.378906250000000, -0.058593750000000,  0.359375000000000,  0.195312500000000,  0.289062500000000, -0.062500000000000,  0.875000000000000,  0.542968750000000,  0.394531250000000, -0.535156250000000, -0.089843750000000, -0.203125000000000,  0.046875000000000,  0.062500000000000,  0.636718750000000, -0.988281250000000, -0.062500000000000,  0.714843750000000,  0.304687500000000, -0.511718750000000,  0.230468750000000,  0.289062500000000, -0.476562500000000, -0.117187500000000,  0.128906250000000,  0.339843750000000,  0.214843750000000, -1.468750000000000, -0.792968750000000,  0.046875000000000, -0.812500000000000,  0.785156250000000,  0.000000000000000,  0.128906250000000, -0.636718750000000, -0.492187500000000, -0.027343750000000,  0.406250000000000,  0.218750000000000,  0.066406250000000,  0.480468750000000, -0.656250000000000, -0.156250000000000, -0.089843750000000,  0.300781250000000,  0.230468750000000,  0.425781250000000,  0.199218750000000,  0.210937500000000,  0.179687500000000,  0.148437500000000,  0.828125000000000, -0.359375000000000, -0.222656250000000, -0.242187500000000, -0.109375000000000, -0.757812500000000, -0.312500000000000, -0.156250000000000, -0.097656250000000};
bias_t b2_2to0[NOUT] = {-0.070312500000000,  0.292968750000000,  0.007812500000000,  0.121093750000000, -0.242187500000000};
