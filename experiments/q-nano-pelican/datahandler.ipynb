{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\otkul\\ETH\\v√•r\\project\\experiments\\q-nano-pelican\\nano-4\\best_acc.weights.h5\n"
     ]
    }
   ],
   "source": [
    "root = Path.cwd()\n",
    "experiment = 'nano-4'\n",
    "weight_file = None\n",
    "look_for = 'best_acc'\n",
    "\n",
    "for file in (root / experiment).iterdir():\n",
    "    if look_for not in file.name:\n",
    "        continue\n",
    "    weight_file = file\n",
    "print(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'feature_key': 'Pmu', 'folder': '../../data/nano_data', 'label_key': 'is_signal', 'num_particles': 32}, 'hyperparams': {'batch_size': 512, 'epochs': 1000, 'lr_init': 0.01, 'patience': 15, 'val_size': -1, 'verbose': 1}, 'model': {'activation': 'relu', 'inner_product': {'data_format': 'epxpypz', 'spurions': False}, 'n_bits': 8, 'n_hidden': 2, 'n_outputs': 1, 'num_avg': 25, 'out_activation': 'linear'}, 'save_dir': 'nano', 'seed': 545944663}\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "from keras import models\n",
    "from qkeras.utils import load_qmodel\n",
    "from model import CreateModel\n",
    "import yaml\n",
    "import numpy as np\n",
    "def load_yaml(filename):\n",
    "    with open(filename, \"r\") as stream:\n",
    "        config = yaml.load(stream, Loader=yaml.Loader)\n",
    "    return config\n",
    "\n",
    "conf = load_yaml(root / experiment / 'config.yml')\n",
    "print(conf)\n",
    "\n",
    "const = tf.shape(np.zeros((10, 4)))\n",
    "\n",
    "my_model = CreateModel(const, conf['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\otkul\\anaconda3\\envs\\keras2\\Lib\\site-packages\\keras\\src\\constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "my_model.load_weights(str(weight_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_15\n",
      "inner_product_6\n",
      "q_batch_normalization_10\n",
      "lineq2v2_5\n",
      "q_dense_10\n",
      "multiply_5\n",
      "q_activation_5\n",
      "q_batch_normalization_11\n",
      "lineq2v0_5\n",
      "q_dense_11\n",
      "activation_5\n",
      "[<qkeras.qnormalization.QBatchNormalization object at 0x0000021A5316C290>, <qkeras.qnormalization.QBatchNormalization object at 0x0000021A52B84ED0>]\n",
      "[<qkeras.qlayers.QDense object at 0x0000021A53083B10>, <qkeras.qlayers.QDense object at 0x0000021A5340C550>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bnorms = []\n",
    "denses = []\n",
    "for layer in my_model.layers:\n",
    "    print(layer.name)\n",
    "    if 'batch_norm' in layer.name:\n",
    "        bnorms.append(layer)\n",
    "    if 'dense' in layer.name:\n",
    "        denses.append(layer)\n",
    "print(bnorms)\n",
    "print(denses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5610447  0.5056122]\n",
      " [ 2.104964   2.2404537]\n",
      " [ 0.6903273 -0.284152 ]]\n",
      "weight [1. 1.]\n",
      "bias [ 0.6903273 -0.284152 ]\n",
      "mean [0.5610447 0.5056122]\n",
      "var [0.22568916 0.19921777]\n"
     ]
    }
   ],
   "source": [
    "bnorm1 = bnorms[1]\n",
    "weights = [w for w in bnorm1.weights]\n",
    "names = [w.name for w in weights]\n",
    "\n",
    "elems = {}\n",
    "for idx, name in enumerate(names):\n",
    "    if 'mean' in name:\n",
    "        elems['mean'] = weights[idx].numpy()\n",
    "    if 'var' in name:\n",
    "        elems['var'] = weights[idx].numpy()\n",
    "    if 'gamma' in name:\n",
    "        elems['weight'] = weights[idx].numpy()\n",
    "    if 'beta' in name:\n",
    "        elems['bias'] = weights[idx].numpy()\n",
    "\n",
    "batch = np.array((elems['mean'], elems['weight']/np.sqrt(elems['var']), elems['bias']))\n",
    "print(batch)\n",
    "\n",
    "for k, v in elems.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "nconst=8\n",
    "n_int=2\n",
    "n_bits=16\n",
    "filename = Path(f'nconst{nconst}-nint{n_int}-nbits{n_bits}-0')\n",
    "weights = h5py.File(filename / 'best_acc.weights.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_layer_checkpoint_dependencies\\activation\n",
      "---------\n",
      "_layer_checkpoint_dependencies\\inner_product\n",
      "---------\n",
      "_layer_checkpoint_dependencies\\input_layer\n",
      "---------\n",
      "_layer_checkpoint_dependencies\\lineq2v0\n",
      "---------\n",
      "_layer_checkpoint_dependencies\\lineq2v2\n",
      "---------\n",
      "_layer_checkpoint_dependencies\\q_activation\n",
      "---------\n",
      "_layer_checkpoint_dependencies\\q_batch_normalization\n",
      "---------\n",
      "0 [0.87140965]\n",
      "1 [-0.78587985]\n",
      "2 [37.89413]\n",
      "3 [11701.205]\n",
      "_layer_checkpoint_dependencies\\q_batch_normalization_1\n",
      "---------\n",
      "0 [3.9979346 4.       ]\n",
      "1 [-0.51040316  0.26416543]\n",
      "2 [0.16906661 0.8389411 ]\n",
      "3 [0.15442237 2.3903692 ]\n",
      "_layer_checkpoint_dependencies\\q_dense\n",
      "---------\n",
      "0 [[ 0.25958037  1.6814182 ]\n",
      " [-1.1072558   1.2651433 ]\n",
      " [-0.5591952  -0.19366042]\n",
      " [-0.55918086 -0.1936602 ]\n",
      " [ 0.994865    0.5419006 ]\n",
      " [ 0.06902391  0.2707818 ]\n",
      " [ 0.73842156  0.40322497]]\n",
      "1 [ 0.00831572 -2.2211697 ]\n",
      "_layer_checkpoint_dependencies\\q_dense_1\n",
      "---------\n",
      "0 [[-4.         4.         4.         4.        -4.       ]\n",
      " [-3.999856  -4.        -4.        -4.         4.       ]\n",
      " [ 1.734024   1.8705581 -1.9646695 -2.0125728 -1.283105 ]\n",
      " [ 1.3186313  1.0972354 -3.996898  -0.8287864  1.0894002]]\n",
      "1 [ 0.15483229 -0.0645858  -0.2432327   0.53521353  0.26054662]\n"
     ]
    }
   ],
   "source": [
    "for k, v in weights.items():\n",
    "    if 'layer' not in k:\n",
    "        continue\n",
    "    print(k)\n",
    "    print('---------')\n",
    "\n",
    "    if 'vars' not in v:\n",
    "        continue\n",
    "\n",
    "    v = v['vars']\n",
    "    for i, j in v.items():\n",
    "        print(i, j[:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pelican",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
