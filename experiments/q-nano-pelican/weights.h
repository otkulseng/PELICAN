#include "../nPELICAN.h"


// WARNING: Have been trained with the following assumptions:
// input_t == ap_fixed<20,12>
// internal_t == ap_fixed<20,12>
// weight_t=bias_t == ap_fixed<11,3>

//normalization constants
//these are currently NOT quantized, so should be FP
internal_t const2v0 = 0.19561107427281468;
internal_t const2v02 = 0.03826369237816462;

internal_t const2v2 = 0.10615466134511138;
internal_t const2v22 = 0.011268812125295284;

//first batchnorm [mean, weight/sqrt(var), bias]
weight_t batch1_2to2[3] = { 33.57515716552734,  0.00006244819815037772, -0.9240869283676147};

//2to2 linear layer
weight_t w1_2to2[NHIDDEN*6] = { 1.222897171974182, -0.011534460820258, -0.554618537425995, -0.862180054187775,  0.401177138090134, -0.622186899185181,  0.697747647762299,  0.196878612041473, -0.545747816562653,  0.331831812858582, -0.727353155612946,  0.310612648725510};
bias_t b1_2to2[NHIDDEN] = {0.112768843770027, 0.328055977821350};
bias_t b1_diag_2to2[NHIDDEN] = {-0.946933746337891,  1.157122015953064};

//second batchnorm [channel][mean, weight/sqrt(var), bias]
weight_t batch2_2to0[NHIDDEN][3] = {{ 0.465339839458466,  2.265971422195435,  0.494464397430420}, { 0.685920238494873,  1.993130207061768, -0.425209850072861}};

//2to1 linear layer
weight_t w2_2to0[NHIDDEN*2*NOUT] = {-0.368256360292435,  0.876240015029907,  2.034760713577271,  1.462650537490845, -1.000098109245300,  0.316522479057312,  0.886536657810211,  0.787571370601654,  0.643666148185730, -0.666706860065460,  1.429318308830261,  0.714367568492889, -1.012766480445862, -0.168536394834518,  1.683495283126831,  0.572638690471649,  0.246489554643631, -1.215704083442688, -0.802217721939087,  0.450419604778290};
bias_t b2_2to0[NOUT] = {-0.152804300189018, -0.300544261932373,  1.114011764526367,  0.750502347946167, -0.964951634407043};
