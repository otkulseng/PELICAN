2024-06-08 22:20:35.854007: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 22:20:35.969378: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 22:20:36.567763: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 22:20:39.458501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 22:20:50.125564: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/two-layer-nano-pelican/conf-pelican-0/config.yml


Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 1) │          4 │ inner_product[0]… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32, 2) │         16 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 2) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 2) │          8 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2_1          │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Lineq2v2)          │ 30)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense_1   │ (None, 32, 32, 2) │         64 │ lineq2v2_1[0][0]  │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply_1          │ (None, 32, 32, 2) │          0 │ diag_bias_dense_… │
│ (Multiply)          │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 2) │          8 │ multiply_1[0][0]  │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 4)         │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 64)        │        320 │ lineq2v0[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 32)        │      2,080 │ dense[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 5)         │        165 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,665 (10.41 KB)
 Trainable params: 2,655 (10.37 KB)
 Non-trainable params: 10 (40.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [10:05<168:06:54, 605.82s/epoch, accuracy=0.614, loss=1.01, lr=0.002, val_accuracy=0.634, val_loss=0.967, val_lr=0.002]  0%|          | 2/1000 [20:04<166:49:16, 601.76s/epoch, accuracy=0.666, loss=0.894, lr=0.002, val_accuracy=0.667, val_loss=0.894, val_lr=0.002]  0%|          | 3/1000 [30:00<165:50:54, 598.85s/epoch, accuracy=0.674, loss=0.879, lr=0.002, val_accuracy=0.61, val_loss=1.01, val_lr=0.002]    0%|          | 4/1000 [41:04<172:53:32, 624.91s/epoch, accuracy=0.679, loss=0.872, lr=0.002, val_accuracy=0.684, val_loss=0.863, val_lr=0.002]  0%|          | 5/1000 [52:19<177:38:01, 642.69s/epoch, accuracy=0.68, loss=0.868, lr=0.002, val_accuracy=0.689, val_loss=0.85, val_lr=0.002]    1%|          | 6/1000 [1:03:17<178:55:58, 648.05s/epoch, accuracy=0.68, loss=0.866, lr=0.002, val_accuracy=0.684, val_loss=0.857, val_lr=0.002]  1%|          | 7/1000 [1:14:29<180:53:41, 655.81s/epoch, accuracy=0.681, loss=0.864, lr=0.002, val_accuracy=0.641, val_loss=0.92, val_lr=0.002]  1%|          | 8/1000 [1:25:46<182:32:04, 662.42s/epoch, accuracy=0.681, loss=0.862, lr=0.002, val_accuracy=0.682, val_loss=0.851, val_lr=0.002]  1%|          | 9/1000 [1:35:57<178:00:28, 646.65s/epoch, accuracy=0.682, loss=0.859, lr=0.002, val_accuracy=0.694, val_loss=0.842, val_lr=0.002]  1%|          | 10/1000 [1:46:34<176:58:40, 643.56s/epoch, accuracy=0.683, loss=0.857, lr=0.002, val_accuracy=0.675, val_loss=0.87, val_lr=0.002]  1%|          | 11/1000 [1:57:43<178:56:53, 651.38s/epoch, accuracy=0.684, loss=0.854, lr=0.002, val_accuracy=0.675, val_loss=0.887, val_lr=0.002]  1%|          | 12/1000 [2:08:59<180:47:30, 658.76s/epoch, accuracy=0.683, loss=0.854, lr=0.002, val_accuracy=0.638, val_loss=0.953, val_lr=0.002]  1%|▏         | 13/1000 [2:19:38<178:57:43, 652.75s/epoch, accuracy=0.684, loss=0.852, lr=0.002, val_accuracy=0.664, val_loss=0.898, val_lr=0.002]  1%|▏         | 14/1000 [2:30:08<176:57:04, 646.07s/epoch, accuracy=0.684, loss=0.851, lr=0.002, val_accuracy=0.666, val_loss=0.886, val_lr=0.002]  2%|▏         | 15/1000 [2:40:11<173:12:50, 633.07s/epoch, accuracy=0.685, loss=0.849, lr=0.002, val_accuracy=0.681, val_loss=0.847, val_lr=0.002]  2%|▏         | 16/1000 [2:50:06<169:53:01, 621.53s/epoch, accuracy=0.685, loss=0.849, lr=0.002, val_accuracy=0.695, val_loss=0.832, val_lr=0.002]  2%|▏         | 17/1000 [2:59:57<167:11:48, 612.32s/epoch, accuracy=0.685, loss=0.849, lr=0.002, val_accuracy=0.67, val_loss=0.89, val_lr=0.002]    2%|▏         | 18/1000 [3:09:47<165:13:02, 605.69s/epoch, accuracy=0.685, loss=0.849, lr=0.002, val_accuracy=0.677, val_loss=0.859, val_lr=0.002]  2%|▏         | 19/1000 [3:19:38<163:49:17, 601.18s/epoch, accuracy=0.686, loss=0.847, lr=0.002, val_accuracy=0.677, val_loss=0.866, val_lr=0.002]  2%|▏         | 20/1000 [3:29:30<162:52:32, 598.32s/epoch, accuracy=0.686, loss=0.846, lr=0.002, val_accuracy=0.661, val_loss=0.903, val_lr=0.002]  2%|▏         | 21/1000 [3:39:21<162:10:03, 596.33s/epoch, accuracy=0.686, loss=0.847, lr=0.002, val_accuracy=0.691, val_loss=0.835, val_lr=0.002]  2%|▏         | 22/1000 [3:49:14<161:41:06, 595.16s/epoch, accuracy=0.686, loss=0.846, lr=0.002, val_accuracy=0.677, val_loss=0.862, val_lr=0.002]  2%|▏         | 23/1000 [3:59:06<161:15:59, 594.23s/epoch, accuracy=0.686, loss=0.845, lr=0.002, val_accuracy=0.677, val_loss=0.852, val_lr=0.002]  2%|▏         | 24/1000 [4:08:58<160:56:39, 593.65s/epoch, accuracy=0.686, loss=0.845, lr=0.002, val_accuracy=0.64, val_loss=0.955, val_lr=0.002]   2%|▎         | 25/1000 [4:18:49<160:33:33, 592.83s/epoch, accuracy=0.685, loss=0.846, lr=0.002, val_accuracy=0.685, val_loss=0.842, val_lr=0.002]  3%|▎         | 26/1000 [4:28:40<160:13:10, 592.19s/epoch, accuracy=0.687, loss=0.845, lr=0.002, val_accuracy=0.657, val_loss=0.91, val_lr=0.002]   3%|▎         | 27/1000 [4:38:31<159:57:52, 591.85s/epoch, accuracy=0.69, loss=0.839, lr=0.0002, val_accuracy=0.696, val_loss=0.827, val_lr=0.0002]  3%|▎         | 28/1000 [4:48:21<159:40:44, 591.40s/epoch, accuracy=0.69, loss=0.838, lr=0.0002, val_accuracy=0.698, val_loss=0.826, val_lr=0.0002]  3%|▎         | 29/1000 [4:58:11<159:25:34, 591.08s/epoch, accuracy=0.69, loss=0.838, lr=0.0002, val_accuracy=0.691, val_loss=0.833, val_lr=0.0002]  3%|▎         | 30/1000 [5:08:01<159:10:21, 590.74s/epoch, accuracy=0.691, loss=0.838, lr=0.0002, val_accuracy=0.697, val_loss=0.827, val_lr=0.0002]  3%|▎         | 31/1000 [5:17:52<159:00:02, 590.72s/epoch, accuracy=0.69, loss=0.838, lr=0.0002, val_accuracy=0.698, val_loss=0.826, val_lr=0.0002]   3%|▎         | 32/1000 [5:27:43<158:50:02, 590.71s/epoch, accuracy=0.69, loss=0.838, lr=0.0002, val_accuracy=0.692, val_loss=0.83, val_lr=0.0002]   3%|▎         | 33/1000 [5:37:30<158:21:24, 589.54s/epoch, accuracy=0.69, loss=0.838, lr=0.0002, val_accuracy=0.69, val_loss=0.833, val_lr=0.0002]  3%|▎         | 34/1000 [5:47:16<157:55:40, 588.55s/epoch, accuracy=0.69, loss=0.838, lr=0.0002, val_accuracy=0.698, val_loss=0.826, val_lr=0.0002]  4%|▎         | 35/1000 [5:57:03<157:39:01, 588.13s/epoch, accuracy=0.691, loss=0.838, lr=0.0002, val_accuracy=0.691, val_loss=0.832, val_lr=0.0002]  4%|▎         | 36/1000 [6:06:50<157:26:13, 587.94s/epoch, accuracy=0.691, loss=0.838, lr=0.0002, val_accuracy=0.695, val_loss=0.827, val_lr=0.0002]  4%|▎         | 37/1000 [6:16:38<157:14:39, 587.83s/epoch, accuracy=0.691, loss=0.838, lr=0.0002, val_accuracy=0.699, val_loss=0.825, val_lr=0.0002]  4%|▍         | 38/1000 [6:26:27<157:08:27, 588.05s/epoch, accuracy=0.69, loss=0.837, lr=0.0002, val_accuracy=0.688, val_loss=0.836, val_lr=0.0002]   4%|▍         | 39/1000 [6:36:14<156:53:24, 587.73s/epoch, accuracy=0.69, loss=0.837, lr=0.0002, val_accuracy=0.698, val_loss=0.826, val_lr=0.0002]  4%|▍         | 40/1000 [6:46:00<156:39:33, 587.47s/epoch, accuracy=0.691, loss=0.837, lr=0.0002, val_accuracy=0.694, val_loss=0.831, val_lr=0.0002]  4%|▍         | 41/1000 [6:55:46<156:22:35, 587.02s/epoch, accuracy=0.691, loss=0.837, lr=0.0002, val_accuracy=0.698, val_loss=0.825, val_lr=0.0002]  4%|▍         | 42/1000 [7:05:33<156:08:48, 586.77s/epoch, accuracy=0.691, loss=0.837, lr=0.0002, val_accuracy=0.696, val_loss=0.827, val_lr=0.0002]  4%|▍         | 43/1000 [7:15:19<155:55:34, 586.56s/epoch, accuracy=0.69, loss=0.837, lr=0.0002, val_accuracy=0.695, val_loss=0.827, val_lr=0.0002]   4%|▍         | 44/1000 [7:25:04<155:41:02, 586.26s/epoch, accuracy=0.691, loss=0.837, lr=0.0002, val_accuracy=0.691, val_loss=0.832, val_lr=0.0002]  4%|▍         | 45/1000 [7:34:54<155:45:57, 587.18s/epoch, accuracy=0.691, loss=0.837, lr=0.0002, val_accuracy=0.691, val_loss=0.832, val_lr=0.0002]  5%|▍         | 46/1000 [7:44:43<155:47:44, 587.91s/epoch, accuracy=0.691, loss=0.837, lr=0.0002, val_accuracy=0.697, val_loss=0.827, val_lr=0.0002]  5%|▍         | 47/1000 [7:54:27<155:20:22, 586.80s/epoch, accuracy=0.691, loss=0.837, lr=0.0002, val_accuracy=0.699, val_loss=0.825, val_lr=0.0002]  5%|▍         | 48/1000 [8:04:12<155:02:37, 586.30s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.696, val_loss=0.826, val_lr=2e-5]      5%|▍         | 49/1000 [8:13:58<154:47:21, 585.95s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.694, val_loss=0.829, val_lr=2e-5]  5%|▌         | 50/1000 [8:23:43<154:33:16, 585.68s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.697, val_loss=0.825, val_lr=2e-5]  5%|▌         | 51/1000 [8:33:29<154:25:08, 585.78s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.699, val_loss=0.825, val_lr=2e-5]  5%|▌         | 52/1000 [8:43:14<154:13:08, 585.64s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.694, val_loss=0.828, val_lr=2e-5]  5%|▌         | 53/1000 [8:53:01<154:09:28, 586.03s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.696, val_loss=0.826, val_lr=2e-5]  5%|▌         | 54/1000 [9:02:52<154:21:27, 587.41s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.697, val_loss=0.825, val_lr=2e-5]  6%|▌         | 55/1000 [9:12:42<154:23:49, 588.18s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.697, val_loss=0.826, val_lr=2e-5]  6%|▌         | 56/1000 [9:22:32<154:24:47, 588.86s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.696, val_loss=0.826, val_lr=2e-5]  6%|▌         | 57/1000 [9:32:23<154:23:05, 589.38s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.698, val_loss=0.825, val_lr=2e-5]  6%|▌         | 57/1000 [9:32:23<157:49:26, 602.51s/epoch, accuracy=0.691, loss=0.836, lr=2e-5, val_accuracy=0.698, val_loss=0.825, val_lr=2e-5]
