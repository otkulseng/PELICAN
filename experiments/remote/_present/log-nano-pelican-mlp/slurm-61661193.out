2024-06-08 17:35:55.953069: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:35:56.012919: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:35:56.255241: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 17:35:58.331827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 17:36:08.642922: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/log-nano-pelican-mlp/conf-pelican-6/config.yml


Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer           │ (None, 32, 32, 1) │          1 │ inner_product[0]… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 1) │          4 │ log_layer[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32, 5) │         40 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 5) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 5) │         20 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 10)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 64)        │        704 │ lineq2v0[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 32)        │      2,080 │ dense[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 5)         │        165 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 3,014 (11.77 KB)
 Trainable params: 3,002 (11.73 KB)
 Non-trainable params: 12 (48.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [04:00<66:42:31, 240.39s/epoch, accuracy=0.638, loss=0.968, lr=0.002, val_accuracy=0.676, val_loss=0.889, val_lr=0.002]  0%|          | 2/1000 [08:07<67:41:14, 244.16s/epoch, accuracy=0.682, loss=0.87, lr=0.002, val_accuracy=0.691, val_loss=0.854, val_lr=0.002]   0%|          | 3/1000 [12:01<66:25:01, 239.82s/epoch, accuracy=0.686, loss=0.86, lr=0.002, val_accuracy=0.692, val_loss=0.852, val_lr=0.002]  0%|          | 4/1000 [15:50<65:06:15, 235.32s/epoch, accuracy=0.688, loss=0.854, lr=0.002, val_accuracy=0.697, val_loss=0.838, val_lr=0.002]  0%|          | 5/1000 [19:48<65:19:39, 236.36s/epoch, accuracy=0.693, loss=0.846, lr=0.002, val_accuracy=0.695, val_loss=0.848, val_lr=0.002]  1%|          | 6/1000 [23:45<65:20:27, 236.65s/epoch, accuracy=0.698, loss=0.835, lr=0.002, val_accuracy=0.695, val_loss=0.848, val_lr=0.002]  1%|          | 7/1000 [27:58<66:43:21, 241.89s/epoch, accuracy=0.701, loss=0.829, lr=0.002, val_accuracy=0.711, val_loss=0.81, val_lr=0.002]   1%|          | 8/1000 [31:53<66:06:11, 239.89s/epoch, accuracy=0.703, loss=0.824, lr=0.002, val_accuracy=0.703, val_loss=0.832, val_lr=0.002]  1%|          | 9/1000 [35:50<65:42:31, 238.70s/epoch, accuracy=0.704, loss=0.821, lr=0.002, val_accuracy=0.71, val_loss=0.812, val_lr=0.002]   1%|          | 10/1000 [39:58<66:25:46, 241.56s/epoch, accuracy=0.705, loss=0.819, lr=0.002, val_accuracy=0.713, val_loss=0.803, val_lr=0.002]  1%|          | 11/1000 [43:55<66:01:51, 240.36s/epoch, accuracy=0.706, loss=0.817, lr=0.002, val_accuracy=0.713, val_loss=0.8, val_lr=0.002]    1%|          | 12/1000 [47:54<65:48:14, 239.77s/epoch, accuracy=0.707, loss=0.814, lr=0.002, val_accuracy=0.711, val_loss=0.809, val_lr=0.002]  1%|▏         | 13/1000 [51:52<65:36:50, 239.32s/epoch, accuracy=0.709, loss=0.811, lr=0.002, val_accuracy=0.713, val_loss=0.803, val_lr=0.002]  1%|▏         | 14/1000 [55:53<65:39:53, 239.75s/epoch, accuracy=0.709, loss=0.81, lr=0.002, val_accuracy=0.716, val_loss=0.798, val_lr=0.002]   2%|▏         | 15/1000 [59:40<64:33:27, 235.95s/epoch, accuracy=0.71, loss=0.807, lr=0.002, val_accuracy=0.712, val_loss=0.808, val_lr=0.002]  2%|▏         | 16/1000 [1:03:29<63:56:33, 233.94s/epoch, accuracy=0.711, loss=0.807, lr=0.002, val_accuracy=0.716, val_loss=0.798, val_lr=0.002]  2%|▏         | 17/1000 [1:07:26<64:05:29, 234.72s/epoch, accuracy=0.712, loss=0.805, lr=0.002, val_accuracy=0.72, val_loss=0.791, val_lr=0.002]   2%|▏         | 18/1000 [1:11:28<64:40:32, 237.10s/epoch, accuracy=0.712, loss=0.804, lr=0.002, val_accuracy=0.715, val_loss=0.798, val_lr=0.002]  2%|▏         | 19/1000 [1:15:17<63:56:40, 234.66s/epoch, accuracy=0.713, loss=0.803, lr=0.002, val_accuracy=0.717, val_loss=0.796, val_lr=0.002]  2%|▏         | 20/1000 [1:19:09<63:38:48, 233.80s/epoch, accuracy=0.713, loss=0.802, lr=0.002, val_accuracy=0.72, val_loss=0.788, val_lr=0.002]   2%|▏         | 21/1000 [1:22:57<63:04:53, 231.96s/epoch, accuracy=0.713, loss=0.803, lr=0.002, val_accuracy=0.715, val_loss=0.798, val_lr=0.002]  2%|▏         | 22/1000 [1:26:59<63:50:57, 235.03s/epoch, accuracy=0.713, loss=0.801, lr=0.002, val_accuracy=0.717, val_loss=0.793, val_lr=0.002]  2%|▏         | 23/1000 [1:30:48<63:20:49, 233.42s/epoch, accuracy=0.713, loss=0.801, lr=0.002, val_accuracy=0.721, val_loss=0.788, val_lr=0.002]  2%|▏         | 24/1000 [1:34:42<63:17:02, 233.42s/epoch, accuracy=0.714, loss=0.8, lr=0.002, val_accuracy=0.721, val_loss=0.788, val_lr=0.002]    2%|▎         | 25/1000 [1:38:38<63:25:48, 234.20s/epoch, accuracy=0.714, loss=0.8, lr=0.002, val_accuracy=0.712, val_loss=0.811, val_lr=0.002]  3%|▎         | 26/1000 [1:42:41<64:07:01, 236.98s/epoch, accuracy=0.714, loss=0.799, lr=0.002, val_accuracy=0.706, val_loss=0.806, val_lr=0.002]  3%|▎         | 27/1000 [1:46:36<63:53:30, 236.39s/epoch, accuracy=0.714, loss=0.798, lr=0.002, val_accuracy=0.721, val_loss=0.786, val_lr=0.002]  3%|▎         | 28/1000 [1:50:24<63:07:20, 233.79s/epoch, accuracy=0.714, loss=0.798, lr=0.002, val_accuracy=0.72, val_loss=0.79, val_lr=0.002]    3%|▎         | 29/1000 [1:54:12<62:35:39, 232.07s/epoch, accuracy=0.715, loss=0.798, lr=0.002, val_accuracy=0.721, val_loss=0.787, val_lr=0.002]  3%|▎         | 30/1000 [1:58:15<63:22:02, 235.18s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.72, val_loss=0.787, val_lr=0.002]   3%|▎         | 31/1000 [2:02:06<62:58:51, 233.99s/epoch, accuracy=0.715, loss=0.798, lr=0.002, val_accuracy=0.717, val_loss=0.795, val_lr=0.002]  3%|▎         | 32/1000 [2:05:57<62:41:54, 233.18s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.722, val_loss=0.785, val_lr=0.002]  3%|▎         | 33/1000 [2:09:50<62:37:25, 233.14s/epoch, accuracy=0.715, loss=0.796, lr=0.002, val_accuracy=0.719, val_loss=0.793, val_lr=0.002]  3%|▎         | 34/1000 [2:13:47<62:52:35, 234.32s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.715, val_loss=0.795, val_lr=0.002]  4%|▎         | 35/1000 [2:17:41<62:44:07, 234.04s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.717, val_loss=0.796, val_lr=0.002]  4%|▎         | 36/1000 [2:21:34<62:36:31, 233.81s/epoch, accuracy=0.716, loss=0.796, lr=0.002, val_accuracy=0.72, val_loss=0.787, val_lr=0.002]   4%|▎         | 37/1000 [2:25:27<62:31:20, 233.73s/epoch, accuracy=0.716, loss=0.796, lr=0.002, val_accuracy=0.722, val_loss=0.783, val_lr=0.002]  4%|▍         | 38/1000 [2:29:28<62:59:13, 235.71s/epoch, accuracy=0.715, loss=0.796, lr=0.002, val_accuracy=0.717, val_loss=0.797, val_lr=0.002]  4%|▍         | 39/1000 [2:33:20<62:36:31, 234.54s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.722, val_loss=0.784, val_lr=0.002]  4%|▍         | 40/1000 [2:37:02<61:34:47, 230.92s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.714, val_loss=0.8, val_lr=0.002]    4%|▍         | 41/1000 [2:40:43<60:41:30, 227.83s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.718, val_loss=0.792, val_lr=0.002]  4%|▍         | 42/1000 [2:44:35<60:58:03, 229.11s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.721, val_loss=0.785, val_lr=0.002]  4%|▍         | 43/1000 [2:48:29<61:20:56, 230.78s/epoch, accuracy=0.715, loss=0.795, lr=0.002, val_accuracy=0.722, val_loss=0.783, val_lr=0.002]  4%|▍         | 44/1000 [2:52:27<61:50:41, 232.89s/epoch, accuracy=0.715, loss=0.795, lr=0.002, val_accuracy=0.72, val_loss=0.788, val_lr=0.002]   4%|▍         | 45/1000 [2:56:19<61:42:06, 232.59s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.718, val_loss=0.795, val_lr=0.002]  5%|▍         | 46/1000 [3:00:13<61:46:05, 233.09s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.721, val_loss=0.79, val_lr=0.002]   5%|▍         | 47/1000 [3:04:14<62:17:43, 235.32s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.722, val_loss=0.785, val_lr=0.002]  5%|▍         | 48/1000 [3:08:13<62:33:37, 236.57s/epoch, accuracy=0.719, loss=0.788, lr=0.0002, val_accuracy=0.724, val_loss=0.779, val_lr=0.0002]  5%|▍         | 49/1000 [3:12:06<62:12:24, 235.48s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  5%|▌         | 50/1000 [3:16:06<62:29:34, 236.82s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.724, val_loss=0.779, val_lr=0.0002]  5%|▌         | 51/1000 [3:20:03<62:25:31, 236.81s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.724, val_loss=0.778, val_lr=0.0002]  5%|▌         | 52/1000 [3:24:02<62:30:41, 237.39s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  5%|▌         | 53/1000 [3:27:55<62:06:32, 236.11s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.724, val_loss=0.779, val_lr=0.0002]  5%|▌         | 54/1000 [3:32:00<62:45:32, 238.83s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.724, val_loss=0.779, val_lr=0.0002]  6%|▌         | 55/1000 [3:35:52<62:09:44, 236.81s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  6%|▌         | 56/1000 [3:39:51<62:15:22, 237.42s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  6%|▌         | 57/1000 [3:43:46<62:00:19, 236.71s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  6%|▌         | 58/1000 [3:47:40<61:43:34, 235.90s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.724, val_loss=0.778, val_lr=0.0002]  6%|▌         | 59/1000 [3:51:39<61:53:32, 236.78s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  6%|▌         | 60/1000 [3:55:38<62:00:49, 237.50s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  6%|▌         | 61/1000 [3:59:35<61:53:43, 237.30s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.777, val_lr=0.0002]  6%|▌         | 62/1000 [4:03:30<61:37:20, 236.50s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.724, val_loss=0.778, val_lr=0.0002]  6%|▋         | 63/1000 [4:07:28<61:40:36, 236.97s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.724, val_loss=0.778, val_lr=0.0002]  6%|▋         | 64/1000 [4:11:23<61:31:20, 236.62s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  6%|▋         | 65/1000 [4:15:18<61:18:02, 236.02s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  7%|▋         | 66/1000 [4:19:10<60:54:23, 234.76s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.724, val_loss=0.779, val_lr=0.0002]  7%|▋         | 67/1000 [4:22:54<59:59:25, 231.47s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.724, val_loss=0.778, val_lr=0.0002]  7%|▋         | 68/1000 [4:26:39<59:26:25, 229.60s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  7%|▋         | 69/1000 [4:30:36<59:55:39, 231.73s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  7%|▋         | 70/1000 [4:34:32<60:12:37, 233.07s/epoch, accuracy=0.72, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.777, val_lr=0.0002]   7%|▋         | 71/1000 [4:38:25<60:07:01, 232.96s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.777, val_lr=0.0002]  7%|▋         | 72/1000 [4:42:20<60:16:02, 233.80s/epoch, accuracy=0.72, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]   7%|▋         | 73/1000 [4:46:19<60:34:04, 235.22s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.777, val_lr=0.0002]  7%|▋         | 74/1000 [4:50:14<60:31:46, 235.32s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.777, val_lr=0.0002]  8%|▊         | 75/1000 [4:54:07<60:16:53, 234.61s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.724, val_loss=0.778, val_lr=0.0002]  8%|▊         | 76/1000 [4:58:00<60:04:58, 234.09s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.777, val_lr=0.0002]  8%|▊         | 77/1000 [5:02:06<60:56:14, 237.68s/epoch, accuracy=0.719, loss=0.786, lr=0.0002, val_accuracy=0.725, val_loss=0.777, val_lr=0.0002]  8%|▊         | 78/1000 [5:06:00<60:33:39, 236.46s/epoch, accuracy=0.72, loss=0.786, lr=0.0002, val_accuracy=0.724, val_loss=0.778, val_lr=0.0002]   8%|▊         | 79/1000 [5:09:47<59:47:36, 233.72s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]      8%|▊         | 80/1000 [5:13:35<59:15:07, 231.86s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  8%|▊         | 81/1000 [5:17:32<59:36:35, 233.51s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  8%|▊         | 82/1000 [5:21:17<58:54:09, 230.99s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  8%|▊         | 83/1000 [5:25:02<58:22:18, 229.16s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  8%|▊         | 84/1000 [5:28:48<58:03:14, 228.16s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  8%|▊         | 85/1000 [5:32:27<57:19:36, 225.55s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  9%|▊         | 86/1000 [5:36:29<58:30:55, 230.48s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  9%|▊         | 87/1000 [5:40:24<58:47:30, 231.82s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  9%|▉         | 88/1000 [5:44:23<59:13:40, 233.79s/epoch, accuracy=0.72, loss=0.785, lr=2e-5, val_accuracy=0.725, val_loss=0.777, val_lr=2e-5]  9%|▉         | 89/1000 [5:48:16<59:07:14, 233.63s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6]  9%|▉         | 90/1000 [5:52:15<59:29:09, 235.33s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6]  9%|▉         | 91/1000 [5:56:20<60:06:47, 238.07s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6]  9%|▉         | 92/1000 [6:00:08<59:18:32, 235.15s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6]  9%|▉         | 93/1000 [6:04:00<58:59:56, 234.17s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6]  9%|▉         | 94/1000 [6:07:58<59:13:05, 235.30s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6] 10%|▉         | 95/1000 [6:12:01<59:42:42, 237.53s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6] 10%|▉         | 96/1000 [6:15:59<59:40:49, 237.67s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6] 10%|▉         | 97/1000 [6:19:48<59:00:51, 235.27s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6] 10%|▉         | 98/1000 [6:23:42<58:49:11, 234.76s/epoch, accuracy=0.72, loss=0.785, lr=2e-6, val_accuracy=0.725, val_loss=0.777, val_lr=2e-6] 10%|▉         | 99/1000 [6:27:37<58:46:27, 234.84s/epoch, accuracy=0.72, loss=0.785, lr=2e-7, val_accuracy=0.725, val_loss=0.777, val_lr=2e-7] 10%|█         | 100/1000 [6:31:41<59:25:54, 237.73s/epoch, accuracy=0.72, loss=0.785, lr=2e-7, val_accuracy=0.725, val_loss=0.777, val_lr=2e-7] 10%|█         | 100/1000 [6:31:41<58:45:16, 235.02s/epoch, accuracy=0.72, loss=0.785, lr=2e-7, val_accuracy=0.725, val_loss=0.777, val_lr=2e-7]


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/log-nano-pelican-mlp/conf-pelican-6/config.yml


Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer_1       │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product_1     │ [(None, 32, 32,   │          0 │ input_layer_1[0]… │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer_1         │ (None, 32, 32, 1) │          1 │ inner_product_1[… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 1) │          4 │ log_layer_1[0][0] │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2_1          │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
│ (Lineq2v2)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense_1   │ (None, 32, 32, 5) │         40 │ lineq2v2_1[0][0]  │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply_1          │ (None, 32, 32, 5) │          0 │ diag_bias_dense_… │
│ (Multiply)          │                   │            │ inner_product_1[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 5) │         20 │ multiply_1[0][0]  │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0_1          │ (None, 10)        │          0 │ batch_normalizat… │
│ (Lineq2v0)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_3 (Dense)     │ (None, 64)        │        704 │ lineq2v0_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_4 (Dense)     │ (None, 32)        │      2,080 │ dense_3[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_5 (Dense)     │ (None, 5)         │        165 │ dense_4[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 3,014 (11.77 KB)
 Trainable params: 3,002 (11.73 KB)
 Non-trainable params: 12 (48.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]  0%|          | 1/1000 [03:52<64:26:21, 232.21s/epoch, accuracy=0.638, loss=0.968, lr=0.002, val_accuracy=0.676, val_loss=0.889, val_lr=0.002]  0%|          | 2/1000 [07:42<64:05:25, 231.19s/epoch, accuracy=0.682, loss=0.87, lr=0.002, val_accuracy=0.691, val_loss=0.854, val_lr=0.002]   0%|          | 3/1000 [11:35<64:13:39, 231.92s/epoch, accuracy=0.686, loss=0.86, lr=0.002, val_accuracy=0.692, val_loss=0.852, val_lr=0.002]  0%|          | 4/1000 [15:32<64:42:34, 233.89s/epoch, accuracy=0.688, loss=0.854, lr=0.002, val_accuracy=0.697, val_loss=0.838, val_lr=0.002]  0%|          | 5/1000 [19:27<64:44:07, 234.22s/epoch, accuracy=0.693, loss=0.846, lr=0.002, val_accuracy=0.695, val_loss=0.848, val_lr=0.002]  1%|          | 6/1000 [23:21<64:41:02, 234.27s/epoch, accuracy=0.698, loss=0.835, lr=0.002, val_accuracy=0.695, val_loss=0.848, val_lr=0.002]  1%|          | 7/1000 [27:15<64:36:13, 234.21s/epoch, accuracy=0.701, loss=0.829, lr=0.002, val_accuracy=0.711, val_loss=0.81, val_lr=0.002]   1%|          | 8/1000 [31:13<64:51:49, 235.39s/epoch, accuracy=0.703, loss=0.824, lr=0.002, val_accuracy=0.703, val_loss=0.832, val_lr=0.002]  1%|          | 9/1000 [35:18<65:37:16, 238.38s/epoch, accuracy=0.704, loss=0.821, lr=0.002, val_accuracy=0.71, val_loss=0.812, val_lr=0.002]   1%|          | 10/1000 [39:04<64:31:33, 234.64s/epoch, accuracy=0.705, loss=0.819, lr=0.002, val_accuracy=0.713, val_loss=0.803, val_lr=0.002]  1%|          | 11/1000 [42:54<64:02:40, 233.12s/epoch, accuracy=0.706, loss=0.817, lr=0.002, val_accuracy=0.713, val_loss=0.8, val_lr=0.002]    1%|          | 12/1000 [46:43<63:38:59, 231.92s/epoch, accuracy=0.707, loss=0.814, lr=0.002, val_accuracy=0.711, val_loss=0.809, val_lr=0.002]  1%|▏         | 13/1000 [50:46<64:28:10, 235.15s/epoch, accuracy=0.709, loss=0.811, lr=0.002, val_accuracy=0.713, val_loss=0.803, val_lr=0.002]  1%|▏         | 14/1000 [54:39<64:14:52, 234.58s/epoch, accuracy=0.709, loss=0.81, lr=0.002, val_accuracy=0.716, val_loss=0.798, val_lr=0.002]   2%|▏         | 15/1000 [58:30<63:52:00, 233.42s/epoch, accuracy=0.71, loss=0.807, lr=0.002, val_accuracy=0.712, val_loss=0.808, val_lr=0.002]  2%|▏         | 16/1000 [1:02:24<63:50:14, 233.55s/epoch, accuracy=0.711, loss=0.807, lr=0.002, val_accuracy=0.716, val_loss=0.798, val_lr=0.002]  2%|▏         | 17/1000 [1:06:25<64:24:45, 235.90s/epoch, accuracy=0.712, loss=0.805, lr=0.002, val_accuracy=0.72, val_loss=0.791, val_lr=0.002]   2%|▏         | 18/1000 [1:10:11<63:32:02, 232.92s/epoch, accuracy=0.712, loss=0.804, lr=0.002, val_accuracy=0.715, val_loss=0.798, val_lr=0.002]  2%|▏         | 19/1000 [1:13:57<62:56:27, 230.98s/epoch, accuracy=0.713, loss=0.803, lr=0.002, val_accuracy=0.717, val_loss=0.796, val_lr=0.002]  2%|▏         | 20/1000 [1:17:49<62:53:35, 231.04s/epoch, accuracy=0.713, loss=0.802, lr=0.002, val_accuracy=0.72, val_loss=0.788, val_lr=0.002]   2%|▏         | 21/1000 [1:21:35<62:29:45, 229.81s/epoch, accuracy=0.713, loss=0.803, lr=0.002, val_accuracy=0.715, val_loss=0.798, val_lr=0.002]  2%|▏         | 22/1000 [1:25:35<63:14:55, 232.82s/epoch, accuracy=0.713, loss=0.801, lr=0.002, val_accuracy=0.717, val_loss=0.793, val_lr=0.002]  2%|▏         | 23/1000 [1:29:26<62:58:48, 232.07s/epoch, accuracy=0.713, loss=0.801, lr=0.002, val_accuracy=0.721, val_loss=0.788, val_lr=0.002]  2%|▏         | 24/1000 [1:33:17<62:49:30, 231.73s/epoch, accuracy=0.714, loss=0.8, lr=0.002, val_accuracy=0.721, val_loss=0.788, val_lr=0.002]    2%|▎         | 25/1000 [1:37:06<62:35:58, 231.14s/epoch, accuracy=0.714, loss=0.8, lr=0.002, val_accuracy=0.712, val_loss=0.811, val_lr=0.002]  3%|▎         | 26/1000 [1:40:56<62:27:17, 230.84s/epoch, accuracy=0.714, loss=0.799, lr=0.002, val_accuracy=0.706, val_loss=0.806, val_lr=0.002]  3%|▎         | 27/1000 [1:44:55<63:02:03, 233.22s/epoch, accuracy=0.714, loss=0.798, lr=0.002, val_accuracy=0.721, val_loss=0.786, val_lr=0.002]  3%|▎         | 28/1000 [1:48:55<63:28:28, 235.09s/epoch, accuracy=0.714, loss=0.798, lr=0.002, val_accuracy=0.72, val_loss=0.79, val_lr=0.002]    3%|▎         | 29/1000 [1:52:40<62:35:05, 232.03s/epoch, accuracy=0.715, loss=0.798, lr=0.002, val_accuracy=0.721, val_loss=0.787, val_lr=0.002]  3%|▎         | 30/1000 [1:56:24<61:55:51, 229.85s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.72, val_loss=0.787, val_lr=0.002]   3%|▎         | 31/1000 [2:00:09<61:27:49, 228.35s/epoch, accuracy=0.715, loss=0.798, lr=0.002, val_accuracy=0.717, val_loss=0.795, val_lr=0.002]  3%|▎         | 32/1000 [2:04:00<61:35:58, 229.09s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.722, val_loss=0.785, val_lr=0.002]  3%|▎         | 33/1000 [2:07:52<61:45:50, 229.94s/epoch, accuracy=0.715, loss=0.796, lr=0.002, val_accuracy=0.719, val_loss=0.793, val_lr=0.002]  3%|▎         | 34/1000 [2:11:37<61:17:37, 228.42s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.715, val_loss=0.795, val_lr=0.002]  4%|▎         | 35/1000 [2:15:28<61:28:57, 229.37s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.717, val_loss=0.796, val_lr=0.002]  4%|▎         | 36/1000 [2:19:20<61:36:15, 230.06s/epoch, accuracy=0.716, loss=0.796, lr=0.002, val_accuracy=0.72, val_loss=0.787, val_lr=0.002]   4%|▎         | 37/1000 [2:23:21<62:23:21, 233.23s/epoch, accuracy=0.716, loss=0.796, lr=0.002, val_accuracy=0.722, val_loss=0.783, val_lr=0.002]  4%|▍         | 38/1000 [2:27:11<62:05:22, 232.35s/epoch, accuracy=0.715, loss=0.796, lr=0.002, val_accuracy=0.717, val_loss=0.797, val_lr=0.002]  4%|▍         | 39/1000 [2:31:02<61:55:22, 231.97s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.722, val_loss=0.784, val_lr=0.002]  4%|▍         | 40/1000 [2:34:55<61:55:33, 232.22s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.714, val_loss=0.8, val_lr=0.002]    4%|▍         | 41/1000 [2:38:50<62:05:45, 233.10s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.718, val_loss=0.792, val_lr=0.002]  4%|▍         | 42/1000 [2:42:42<61:54:04, 232.61s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.721, val_loss=0.785, val_lr=0.002]  4%|▍         | 43/1000 [2:46:32<61:41:25, 232.06s/epoch, accuracy=0.715, loss=0.795, lr=0.002, val_accuracy=0.722, val_loss=0.783, val_lr=0.002]  4%|▍         | 44/1000 [2:50:23<61:32:45, 231.76s/epoch, accuracy=0.715, loss=0.795, lr=0.002, val_accuracy=0.72, val_loss=0.788, val_lr=0.002]   4%|▍         | 45/1000 [2:54:24<62:11:22, 234.43s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.718, val_loss=0.795, val_lr=0.002]  5%|▍         | 46/1000 [2:58:16<61:54:16, 233.60s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.721, val_loss=0.79, val_lr=0.002]   5%|▍         | 47/1000 [3:02:06<61:34:11, 232.58s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.722, val_loss=0.785, val_lr=0.002]  5%|▍         | 48/1000 [3:06:01<61:40:23, 233.22s/epoch, accuracy=0.719, loss=0.788, lr=0.0002, val_accuracy=0.724, val_loss=0.779, val_lr=0.0002]  5%|▍         | 49/1000 [3:10:06<62:34:04, 236.85s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  5%|▌         | 50/1000 [3:13:58<62:06:42, 235.37s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.724, val_loss=0.779, val_lr=0.0002]  5%|▌         | 51/1000 [3:17:45<61:26:10, 233.06s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.724, val_loss=0.778, val_lr=0.0002]  5%|▌         | 52/1000 [3:21:36<61:09:25, 232.24s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.725, val_loss=0.778, val_lr=0.0002]  5%|▌         | 53/1000 [3:25:32<61:26:24, 233.56s/epoch, accuracy=0.719, loss=0.787, lr=0.0002, val_accuracy=0.724, val_loss=0.779, val_lr=0.0002]slurmstepd: error: *** JOB 61661193 ON eu-a2p-524 CANCELLED AT 2024-06-09T03:35:54 DUE TO TIME LIMIT ***
