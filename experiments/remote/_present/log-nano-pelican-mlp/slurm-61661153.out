2024-06-08 17:35:11.243968: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:35:11.247470: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:35:11.298367: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 17:35:13.262197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 17:35:22.375408: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/log-nano-pelican-mlp/conf-pelican-4/config.yml


Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer           │ (None, 32, 32, 1) │          1 │ inner_product[0]… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 1) │          4 │ log_layer[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32, 2) │         16 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 2) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 2) │          8 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 4)         │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 64)        │        320 │ lineq2v0[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 32)        │      2,080 │ dense[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 5)         │        165 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,594 (10.13 KB)
 Trainable params: 2,588 (10.11 KB)
 Non-trainable params: 6 (24.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [03:27<57:42:42, 207.97s/epoch, accuracy=0.612, loss=1.02, lr=0.002, val_accuracy=0.653, val_loss=0.941, val_lr=0.002]  0%|          | 2/1000 [06:52<57:07:20, 206.05s/epoch, accuracy=0.655, loss=0.927, lr=0.002, val_accuracy=0.671, val_loss=0.901, val_lr=0.002]  0%|          | 3/1000 [10:19<57:09:40, 206.40s/epoch, accuracy=0.659, loss=0.915, lr=0.002, val_accuracy=0.665, val_loss=0.904, val_lr=0.002]  0%|          | 4/1000 [13:46<57:11:28, 206.72s/epoch, accuracy=0.661, loss=0.909, lr=0.002, val_accuracy=0.674, val_loss=0.886, val_lr=0.002]  0%|          | 5/1000 [17:13<57:09:46, 206.82s/epoch, accuracy=0.664, loss=0.903, lr=0.002, val_accuracy=0.675, val_loss=0.883, val_lr=0.002]  1%|          | 6/1000 [20:41<57:09:12, 206.99s/epoch, accuracy=0.666, loss=0.898, lr=0.002, val_accuracy=0.672, val_loss=0.886, val_lr=0.002]  1%|          | 7/1000 [24:08<57:08:43, 207.17s/epoch, accuracy=0.667, loss=0.896, lr=0.002, val_accuracy=0.671, val_loss=0.889, val_lr=0.002]  1%|          | 8/1000 [27:37<57:11:53, 207.57s/epoch, accuracy=0.668, loss=0.891, lr=0.002, val_accuracy=0.68, val_loss=0.876, val_lr=0.002]   1%|          | 9/1000 [31:05<57:11:28, 207.76s/epoch, accuracy=0.67, loss=0.886, lr=0.002, val_accuracy=0.68, val_loss=0.865, val_lr=0.002]   1%|          | 10/1000 [34:31<57:02:55, 207.45s/epoch, accuracy=0.672, loss=0.88, lr=0.002, val_accuracy=0.678, val_loss=0.868, val_lr=0.002]  1%|          | 11/1000 [37:59<57:01:47, 207.59s/epoch, accuracy=0.673, loss=0.877, lr=0.002, val_accuracy=0.682, val_loss=0.859, val_lr=0.002]  1%|          | 12/1000 [41:28<57:01:24, 207.78s/epoch, accuracy=0.673, loss=0.875, lr=0.002, val_accuracy=0.68, val_loss=0.866, val_lr=0.002]   1%|▏         | 13/1000 [44:56<57:01:35, 208.00s/epoch, accuracy=0.674, loss=0.873, lr=0.002, val_accuracy=0.684, val_loss=0.852, val_lr=0.002]  1%|▏         | 14/1000 [48:24<56:59:04, 208.06s/epoch, accuracy=0.675, loss=0.871, lr=0.002, val_accuracy=0.684, val_loss=0.855, val_lr=0.002]  2%|▏         | 15/1000 [51:52<56:52:57, 207.90s/epoch, accuracy=0.676, loss=0.868, lr=0.002, val_accuracy=0.681, val_loss=0.863, val_lr=0.002]  2%|▏         | 16/1000 [55:20<56:49:33, 207.90s/epoch, accuracy=0.677, loss=0.866, lr=0.002, val_accuracy=0.686, val_loss=0.855, val_lr=0.002]  2%|▏         | 17/1000 [58:48<56:48:24, 208.04s/epoch, accuracy=0.678, loss=0.864, lr=0.002, val_accuracy=0.687, val_loss=0.852, val_lr=0.002]  2%|▏         | 18/1000 [1:02:16<56:46:33, 208.14s/epoch, accuracy=0.679, loss=0.863, lr=0.002, val_accuracy=0.688, val_loss=0.848, val_lr=0.002]  2%|▏         | 19/1000 [1:05:41<56:27:23, 207.18s/epoch, accuracy=0.681, loss=0.86, lr=0.002, val_accuracy=0.689, val_loss=0.844, val_lr=0.002]   2%|▏         | 20/1000 [1:09:06<56:12:44, 206.49s/epoch, accuracy=0.681, loss=0.86, lr=0.002, val_accuracy=0.688, val_loss=0.845, val_lr=0.002]  2%|▏         | 21/1000 [1:12:31<56:02:31, 206.08s/epoch, accuracy=0.683, loss=0.859, lr=0.002, val_accuracy=0.684, val_loss=0.864, val_lr=0.002]  2%|▏         | 22/1000 [1:15:57<55:55:08, 205.84s/epoch, accuracy=0.683, loss=0.857, lr=0.002, val_accuracy=0.69, val_loss=0.842, val_lr=0.002]   2%|▏         | 23/1000 [1:19:23<55:53:15, 205.93s/epoch, accuracy=0.683, loss=0.857, lr=0.002, val_accuracy=0.682, val_loss=0.864, val_lr=0.002]  2%|▏         | 24/1000 [1:22:50<55:56:41, 206.35s/epoch, accuracy=0.684, loss=0.857, lr=0.002, val_accuracy=0.696, val_loss=0.838, val_lr=0.002]  2%|▎         | 25/1000 [1:26:18<55:59:28, 206.74s/epoch, accuracy=0.684, loss=0.856, lr=0.002, val_accuracy=0.691, val_loss=0.845, val_lr=0.002]  3%|▎         | 26/1000 [1:29:46<56:03:52, 207.22s/epoch, accuracy=0.685, loss=0.855, lr=0.002, val_accuracy=0.689, val_loss=0.843, val_lr=0.002]  3%|▎         | 27/1000 [1:33:15<56:08:00, 207.69s/epoch, accuracy=0.686, loss=0.854, lr=0.002, val_accuracy=0.69, val_loss=0.843, val_lr=0.002]   3%|▎         | 28/1000 [1:36:42<56:02:03, 207.53s/epoch, accuracy=0.686, loss=0.854, lr=0.002, val_accuracy=0.693, val_loss=0.84, val_lr=0.002]  3%|▎         | 29/1000 [1:40:10<56:00:12, 207.63s/epoch, accuracy=0.687, loss=0.854, lr=0.002, val_accuracy=0.687, val_loss=0.851, val_lr=0.002]  3%|▎         | 30/1000 [1:43:38<55:57:32, 207.68s/epoch, accuracy=0.687, loss=0.854, lr=0.002, val_accuracy=0.678, val_loss=0.851, val_lr=0.002]  3%|▎         | 31/1000 [1:47:05<55:51:03, 207.50s/epoch, accuracy=0.688, loss=0.853, lr=0.002, val_accuracy=0.693, val_loss=0.847, val_lr=0.002]  3%|▎         | 32/1000 [1:50:32<55:46:14, 207.41s/epoch, accuracy=0.69, loss=0.851, lr=0.002, val_accuracy=0.698, val_loss=0.836, val_lr=0.002]   3%|▎         | 33/1000 [1:53:59<55:38:46, 207.16s/epoch, accuracy=0.69, loss=0.85, lr=0.002, val_accuracy=0.694, val_loss=0.841, val_lr=0.002]   3%|▎         | 34/1000 [1:57:26<55:38:50, 207.38s/epoch, accuracy=0.69, loss=0.851, lr=0.002, val_accuracy=0.697, val_loss=0.837, val_lr=0.002]  4%|▎         | 35/1000 [2:00:54<55:36:47, 207.47s/epoch, accuracy=0.69, loss=0.851, lr=0.002, val_accuracy=0.697, val_loss=0.838, val_lr=0.002]  4%|▎         | 36/1000 [2:04:21<55:28:23, 207.16s/epoch, accuracy=0.691, loss=0.85, lr=0.002, val_accuracy=0.699, val_loss=0.835, val_lr=0.002]  4%|▎         | 37/1000 [2:07:47<55:23:00, 207.04s/epoch, accuracy=0.69, loss=0.85, lr=0.002, val_accuracy=0.698, val_loss=0.84, val_lr=0.002]    4%|▍         | 38/1000 [2:11:15<55:22:20, 207.21s/epoch, accuracy=0.691, loss=0.85, lr=0.002, val_accuracy=0.696, val_loss=0.838, val_lr=0.002]  4%|▍         | 39/1000 [2:14:43<55:22:50, 207.46s/epoch, accuracy=0.691, loss=0.849, lr=0.002, val_accuracy=0.698, val_loss=0.836, val_lr=0.002]  4%|▍         | 40/1000 [2:18:12<55:24:53, 207.81s/epoch, accuracy=0.691, loss=0.849, lr=0.002, val_accuracy=0.688, val_loss=0.854, val_lr=0.002]  4%|▍         | 41/1000 [2:21:42<55:33:46, 208.58s/epoch, accuracy=0.691, loss=0.848, lr=0.002, val_accuracy=0.696, val_loss=0.838, val_lr=0.002]  4%|▍         | 42/1000 [2:25:11<55:31:05, 208.63s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.695, val_loss=0.838, val_lr=0.002]  4%|▍         | 43/1000 [2:28:39<55:26:09, 208.54s/epoch, accuracy=0.691, loss=0.849, lr=0.002, val_accuracy=0.693, val_loss=0.839, val_lr=0.002]  4%|▍         | 44/1000 [2:32:06<55:16:35, 208.15s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.696, val_loss=0.837, val_lr=0.002]  4%|▍         | 45/1000 [2:35:33<55:03:50, 207.57s/epoch, accuracy=0.692, loss=0.849, lr=0.002, val_accuracy=0.694, val_loss=0.842, val_lr=0.002]  5%|▍         | 46/1000 [2:38:57<54:47:12, 206.74s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.7, val_loss=0.835, val_lr=0.002]    5%|▍         | 47/1000 [2:42:22<54:34:30, 206.16s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.693, val_loss=0.843, val_lr=0.002]  5%|▍         | 48/1000 [2:45:42<54:02:42, 204.37s/epoch, accuracy=0.691, loss=0.849, lr=0.002, val_accuracy=0.701, val_loss=0.834, val_lr=0.002]  5%|▍         | 49/1000 [2:49:02<53:38:26, 203.06s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.698, val_loss=0.836, val_lr=0.002]  5%|▌         | 50/1000 [2:52:24<53:30:41, 202.78s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.7, val_loss=0.832, val_lr=0.002]    5%|▌         | 51/1000 [2:55:47<53:23:59, 202.57s/epoch, accuracy=0.692, loss=0.847, lr=0.002, val_accuracy=0.7, val_loss=0.831, val_lr=0.002]  5%|▌         | 52/1000 [2:59:08<53:15:13, 202.23s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.699, val_loss=0.835, val_lr=0.002]  5%|▌         | 53/1000 [3:02:30<53:09:38, 202.09s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.698, val_loss=0.835, val_lr=0.002]  5%|▌         | 54/1000 [3:05:52<53:06:00, 202.07s/epoch, accuracy=0.692, loss=0.847, lr=0.002, val_accuracy=0.701, val_loss=0.835, val_lr=0.002]  6%|▌         | 55/1000 [3:09:14<53:02:44, 202.08s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.694, val_loss=0.846, val_lr=0.002]  6%|▌         | 56/1000 [3:12:35<52:57:08, 201.94s/epoch, accuracy=0.692, loss=0.847, lr=0.002, val_accuracy=0.698, val_loss=0.837, val_lr=0.002]  6%|▌         | 57/1000 [3:15:58<52:55:29, 202.05s/epoch, accuracy=0.692, loss=0.848, lr=0.002, val_accuracy=0.701, val_loss=0.836, val_lr=0.002]  6%|▌         | 58/1000 [3:19:18<52:43:59, 201.53s/epoch, accuracy=0.692, loss=0.847, lr=0.002, val_accuracy=0.698, val_loss=0.841, val_lr=0.002]  6%|▌         | 59/1000 [3:22:36<52:22:14, 200.36s/epoch, accuracy=0.695, loss=0.841, lr=0.0002, val_accuracy=0.7, val_loss=0.83, val_lr=0.0002]   6%|▌         | 60/1000 [3:25:54<52:07:04, 199.60s/epoch, accuracy=0.695, loss=0.841, lr=0.0002, val_accuracy=0.7, val_loss=0.83, val_lr=0.0002]  6%|▌         | 61/1000 [3:29:11<51:54:13, 198.99s/epoch, accuracy=0.695, loss=0.841, lr=0.0002, val_accuracy=0.699, val_loss=0.831, val_lr=0.0002]  6%|▌         | 62/1000 [3:32:29<51:44:21, 198.57s/epoch, accuracy=0.695, loss=0.841, lr=0.0002, val_accuracy=0.699, val_loss=0.831, val_lr=0.0002]  6%|▋         | 63/1000 [3:35:46<51:37:04, 198.32s/epoch, accuracy=0.695, loss=0.841, lr=0.0002, val_accuracy=0.701, val_loss=0.829, val_lr=0.0002]  6%|▋         | 64/1000 [3:39:04<51:30:51, 198.13s/epoch, accuracy=0.695, loss=0.841, lr=0.0002, val_accuracy=0.702, val_loss=0.829, val_lr=0.0002]  6%|▋         | 65/1000 [3:42:22<51:25:14, 197.98s/epoch, accuracy=0.695, loss=0.841, lr=0.0002, val_accuracy=0.701, val_loss=0.829, val_lr=0.0002]  7%|▋         | 66/1000 [3:45:40<51:21:35, 197.96s/epoch, accuracy=0.695, loss=0.841, lr=0.0002, val_accuracy=0.701, val_loss=0.829, val_lr=0.0002]  7%|▋         | 67/1000 [3:48:58<51:19:49, 198.06s/epoch, accuracy=0.696, loss=0.841, lr=0.0002, val_accuracy=0.699, val_loss=0.832, val_lr=0.0002]  7%|▋         | 68/1000 [3:52:16<51:17:14, 198.11s/epoch, accuracy=0.696, loss=0.841, lr=0.0002, val_accuracy=0.7, val_loss=0.83, val_lr=0.0002]     7%|▋         | 69/1000 [3:55:34<51:10:45, 197.90s/epoch, accuracy=0.696, loss=0.841, lr=0.0002, val_accuracy=0.701, val_loss=0.829, val_lr=0.0002]  7%|▋         | 70/1000 [3:58:51<51:03:15, 197.63s/epoch, accuracy=0.696, loss=0.841, lr=0.0002, val_accuracy=0.702, val_loss=0.829, val_lr=0.0002]  7%|▋         | 71/1000 [4:02:07<50:56:20, 197.40s/epoch, accuracy=0.696, loss=0.84, lr=0.0002, val_accuracy=0.699, val_loss=0.832, val_lr=0.0002]   7%|▋         | 72/1000 [4:05:24<50:50:55, 197.26s/epoch, accuracy=0.696, loss=0.84, lr=0.0002, val_accuracy=0.701, val_loss=0.829, val_lr=0.0002]  7%|▋         | 73/1000 [4:08:41<50:44:14, 197.04s/epoch, accuracy=0.696, loss=0.841, lr=0.0002, val_accuracy=0.702, val_loss=0.829, val_lr=0.0002]  7%|▋         | 74/1000 [4:11:58<50:41:34, 197.08s/epoch, accuracy=0.696, loss=0.84, lr=0.0002, val_accuracy=0.701, val_loss=0.829, val_lr=0.0002]   8%|▊         | 75/1000 [4:15:15<50:37:11, 197.01s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.702, val_loss=0.828, val_lr=2e-5]      8%|▊         | 76/1000 [4:18:32<50:32:46, 196.93s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.701, val_loss=0.828, val_lr=2e-5]  8%|▊         | 77/1000 [4:21:48<50:28:11, 196.85s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.701, val_loss=0.828, val_lr=2e-5]  8%|▊         | 78/1000 [4:25:05<50:25:08, 196.86s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.702, val_loss=0.828, val_lr=2e-5]  8%|▊         | 79/1000 [4:28:22<50:21:12, 196.82s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.701, val_loss=0.829, val_lr=2e-5]  8%|▊         | 80/1000 [4:31:38<50:16:19, 196.72s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.701, val_loss=0.828, val_lr=2e-5]  8%|▊         | 81/1000 [4:34:56<50:15:00, 196.85s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.701, val_loss=0.828, val_lr=2e-5]  8%|▊         | 82/1000 [4:38:15<50:23:31, 197.62s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.702, val_loss=0.828, val_lr=2e-5]  8%|▊         | 83/1000 [4:41:35<50:31:29, 198.35s/epoch, accuracy=0.696, loss=0.84, lr=2e-5, val_accuracy=0.702, val_loss=0.828, val_lr=2e-5]  8%|▊         | 84/1000 [4:44:58<50:47:37, 199.63s/epoch, accuracy=0.696, loss=0.839, lr=2e-5, val_accuracy=0.701, val_loss=0.829, val_lr=2e-5]  8%|▊         | 84/1000 [4:44:58<51:47:31, 203.55s/epoch, accuracy=0.696, loss=0.839, lr=2e-5, val_accuracy=0.701, val_loss=0.829, val_lr=2e-5]
