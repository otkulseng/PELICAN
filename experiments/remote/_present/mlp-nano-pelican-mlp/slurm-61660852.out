2024-06-08 17:25:03.209000: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:25:03.364803: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:25:04.008320: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 17:25:06.923535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 17:25:24.374076: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/mlp-nano-pelican-mlp/conf-pelican-0/config.yml


Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32, 2) │          6 │ inner_product[0]… │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 2) │          8 │ diag_bias_dense[… │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 22)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense_1   │ (None, 32, 32, 2) │         48 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 2) │          0 │ diag_bias_dense_… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 2) │          8 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 4)         │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         25 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 95 (380.00 B)
 Trainable params: 87 (348.00 B)
 Non-trainable params: 8 (32.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [08:03<134:02:23, 483.03s/epoch, accuracy=0.403, loss=1.36, lr=0.002, val_accuracy=0.35, val_loss=1.84, val_lr=0.002]  0%|          | 2/1000 [16:04<133:42:16, 482.30s/epoch, accuracy=0.571, loss=1.12, lr=0.002, val_accuracy=0.376, val_loss=5.69, val_lr=0.002]  0%|          | 3/1000 [24:06<133:30:02, 482.05s/epoch, accuracy=0.569, loss=1.11, lr=0.002, val_accuracy=0.635, val_loss=1.06, val_lr=0.002]  0%|          | 4/1000 [32:10<133:35:54, 482.89s/epoch, accuracy=0.592, loss=1.08, lr=0.002, val_accuracy=0.3, val_loss=2.55, val_lr=0.002]    0%|          | 5/1000 [40:13<133:25:10, 482.72s/epoch, accuracy=0.632, loss=1.03, lr=0.002, val_accuracy=0.199, val_loss=4.9, val_lr=0.002]  1%|          | 6/1000 [48:13<133:05:33, 482.03s/epoch, accuracy=0.612, loss=1.05, lr=0.002, val_accuracy=0.559, val_loss=1.11, val_lr=0.002]  1%|          | 7/1000 [56:13<132:45:31, 481.30s/epoch, accuracy=0.631, loss=1.01, lr=0.002, val_accuracy=0.465, val_loss=1.32, val_lr=0.002]  1%|          | 8/1000 [1:04:13<132:31:44, 480.95s/epoch, accuracy=0.653, loss=0.984, lr=0.002, val_accuracy=0.557, val_loss=1.16, val_lr=0.002]  1%|          | 9/1000 [1:12:15<132:25:14, 481.04s/epoch, accuracy=0.65, loss=0.985, lr=0.002, val_accuracy=0.473, val_loss=1.42, val_lr=0.002]   1%|          | 10/1000 [1:20:17<132:23:51, 481.45s/epoch, accuracy=0.645, loss=0.99, lr=0.002, val_accuracy=0.315, val_loss=2.92, val_lr=0.002]  1%|          | 11/1000 [1:28:18<132:15:29, 481.43s/epoch, accuracy=0.645, loss=0.984, lr=0.002, val_accuracy=0.324, val_loss=2.71, val_lr=0.002]  1%|          | 12/1000 [1:36:22<132:18:21, 482.09s/epoch, accuracy=0.648, loss=0.976, lr=0.002, val_accuracy=0.433, val_loss=1.63, val_lr=0.002]  1%|▏         | 13/1000 [1:44:28<132:30:42, 483.33s/epoch, accuracy=0.657, loss=0.96, lr=0.002, val_accuracy=0.502, val_loss=1.42, val_lr=0.002]   1%|▏         | 14/1000 [1:52:33<132:30:03, 483.78s/epoch, accuracy=0.66, loss=0.953, lr=0.0002, val_accuracy=0.658, val_loss=0.952, val_lr=0.0002]  2%|▏         | 15/1000 [2:00:38<132:26:40, 484.06s/epoch, accuracy=0.664, loss=0.946, lr=0.0002, val_accuracy=0.602, val_loss=1.05, val_lr=0.0002]  2%|▏         | 16/1000 [2:08:38<131:58:10, 482.82s/epoch, accuracy=0.664, loss=0.946, lr=0.0002, val_accuracy=0.429, val_loss=1.51, val_lr=0.0002]  2%|▏         | 17/1000 [2:16:37<131:33:24, 481.79s/epoch, accuracy=0.663, loss=0.948, lr=0.0002, val_accuracy=0.64, val_loss=0.983, val_lr=0.0002]  2%|▏         | 18/1000 [2:24:37<131:15:29, 481.19s/epoch, accuracy=0.664, loss=0.947, lr=0.0002, val_accuracy=0.609, val_loss=1.03, val_lr=0.0002]  2%|▏         | 19/1000 [2:32:36<130:58:47, 480.66s/epoch, accuracy=0.667, loss=0.941, lr=0.0002, val_accuracy=0.641, val_loss=0.981, val_lr=0.0002]  2%|▏         | 20/1000 [2:40:34<130:35:43, 479.74s/epoch, accuracy=0.669, loss=0.937, lr=0.0002, val_accuracy=0.557, val_loss=1.2, val_lr=0.0002]    2%|▏         | 21/1000 [2:48:27<129:57:32, 477.89s/epoch, accuracy=0.668, loss=0.938, lr=0.0002, val_accuracy=0.56, val_loss=1.1, val_lr=0.0002]   2%|▏         | 22/1000 [2:56:23<129:36:37, 477.09s/epoch, accuracy=0.669, loss=0.936, lr=0.0002, val_accuracy=0.67, val_loss=0.938, val_lr=0.0002]  2%|▏         | 23/1000 [3:04:16<129:12:05, 476.08s/epoch, accuracy=0.669, loss=0.935, lr=0.0002, val_accuracy=0.671, val_loss=0.935, val_lr=0.0002]  2%|▏         | 24/1000 [3:11:51<127:19:33, 469.64s/epoch, accuracy=0.67, loss=0.935, lr=0.0002, val_accuracy=0.672, val_loss=0.928, val_lr=0.0002]   2%|▎         | 25/1000 [3:19:28<126:12:07, 465.98s/epoch, accuracy=0.67, loss=0.934, lr=0.0002, val_accuracy=0.654, val_loss=0.958, val_lr=0.0002]  3%|▎         | 26/1000 [3:27:05<125:18:10, 463.13s/epoch, accuracy=0.669, loss=0.934, lr=0.0002, val_accuracy=0.657, val_loss=0.957, val_lr=0.0002]  3%|▎         | 27/1000 [3:34:42<124:40:39, 461.29s/epoch, accuracy=0.671, loss=0.931, lr=0.0002, val_accuracy=0.479, val_loss=1.34, val_lr=0.0002]   3%|▎         | 28/1000 [3:42:18<124:08:31, 459.79s/epoch, accuracy=0.671, loss=0.93, lr=0.0002, val_accuracy=0.676, val_loss=0.924, val_lr=0.0002]  3%|▎         | 29/1000 [3:49:55<123:44:50, 458.80s/epoch, accuracy=0.673, loss=0.927, lr=0.0002, val_accuracy=0.678, val_loss=0.921, val_lr=0.0002]  3%|▎         | 30/1000 [3:57:30<123:21:10, 457.81s/epoch, accuracy=0.673, loss=0.926, lr=0.0002, val_accuracy=0.554, val_loss=1.12, val_lr=0.0002]   3%|▎         | 31/1000 [4:05:05<123:00:00, 456.97s/epoch, accuracy=0.673, loss=0.925, lr=0.0002, val_accuracy=0.617, val_loss=1.02, val_lr=0.0002]  3%|▎         | 32/1000 [4:12:41<122:46:38, 456.61s/epoch, accuracy=0.672, loss=0.926, lr=0.0002, val_accuracy=0.654, val_loss=0.965, val_lr=0.0002]  3%|▎         | 33/1000 [4:20:17<122:35:24, 456.39s/epoch, accuracy=0.673, loss=0.925, lr=0.0002, val_accuracy=0.672, val_loss=0.928, val_lr=0.0002]  3%|▎         | 34/1000 [4:27:53<122:27:10, 456.35s/epoch, accuracy=0.666, loss=0.941, lr=0.0002, val_accuracy=0.503, val_loss=1.27, val_lr=0.0002]   4%|▎         | 35/1000 [4:35:28<122:14:51, 456.05s/epoch, accuracy=0.671, loss=0.928, lr=0.0002, val_accuracy=0.503, val_loss=1.35, val_lr=0.0002]  4%|▎         | 36/1000 [4:43:02<121:57:53, 455.47s/epoch, accuracy=0.672, loss=0.926, lr=0.0002, val_accuracy=0.479, val_loss=1.4, val_lr=0.0002]   4%|▎         | 37/1000 [4:50:38<121:49:30, 455.42s/epoch, accuracy=0.672, loss=0.925, lr=0.0002, val_accuracy=0.668, val_loss=0.937, val_lr=0.0002]  4%|▍         | 38/1000 [4:58:13<121:41:47, 455.41s/epoch, accuracy=0.673, loss=0.923, lr=0.0002, val_accuracy=0.642, val_loss=0.979, val_lr=0.0002]  4%|▍         | 39/1000 [5:05:49<121:33:47, 455.39s/epoch, accuracy=0.673, loss=0.923, lr=0.0002, val_accuracy=0.678, val_loss=0.916, val_lr=0.0002]  4%|▍         | 40/1000 [5:13:24<121:28:01, 455.50s/epoch, accuracy=0.674, loss=0.921, lr=2e-5, val_accuracy=0.669, val_loss=0.928, val_lr=2e-5]      4%|▍         | 41/1000 [5:21:00<121:23:06, 455.67s/epoch, accuracy=0.674, loss=0.921, lr=2e-5, val_accuracy=0.665, val_loss=0.936, val_lr=2e-5]  4%|▍         | 42/1000 [5:28:36<121:15:38, 455.68s/epoch, accuracy=0.674, loss=0.921, lr=2e-5, val_accuracy=0.675, val_loss=0.919, val_lr=2e-5]  4%|▍         | 43/1000 [5:36:10<121:00:15, 455.19s/epoch, accuracy=0.674, loss=0.921, lr=2e-5, val_accuracy=0.678, val_loss=0.914, val_lr=2e-5]  4%|▍         | 44/1000 [5:43:42<120:38:14, 454.28s/epoch, accuracy=0.674, loss=0.921, lr=2e-5, val_accuracy=0.658, val_loss=0.948, val_lr=2e-5]  4%|▍         | 45/1000 [5:51:14<120:17:24, 453.45s/epoch, accuracy=0.674, loss=0.921, lr=2e-5, val_accuracy=0.679, val_loss=0.915, val_lr=2e-5]  5%|▍         | 46/1000 [5:58:49<120:17:11, 453.91s/epoch, accuracy=0.674, loss=0.921, lr=2e-5, val_accuracy=0.676, val_loss=0.92, val_lr=2e-5] slurmstepd: error: *** JOB 61660852 ON eu-g5-043-4 CANCELLED AT 2024-06-08T23:25:00 DUE TO TIME LIMIT ***
