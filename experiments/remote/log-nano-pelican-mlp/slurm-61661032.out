2024-06-08 17:32:06.150171: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:32:06.153945: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:32:06.209553: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 17:32:08.207536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 17:32:16.249401: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/log-nano-pelican-mlp/conf-pelican-1/config.yml


Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer           │ (None, 32, 32, 1) │          1 │ inner_product[0]… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 1) │          4 │ log_layer[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32, 3) │         24 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 3) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 3) │         12 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 6)         │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         35 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 76 (304.00 B)
 Trainable params: 68 (272.00 B)
 Non-trainable params: 8 (32.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [04:12<70:06:10, 252.62s/epoch, accuracy=0.561, loss=1.17, lr=0.002, val_accuracy=0.656, val_loss=1.04, val_lr=0.002]  0%|          | 2/1000 [08:20<69:18:52, 250.03s/epoch, accuracy=0.65, loss=0.983, lr=0.002, val_accuracy=0.661, val_loss=0.945, val_lr=0.002]  0%|          | 3/1000 [12:29<69:00:59, 249.21s/epoch, accuracy=0.654, loss=0.949, lr=0.002, val_accuracy=0.661, val_loss=0.938, val_lr=0.002]  0%|          | 4/1000 [16:37<68:52:30, 248.95s/epoch, accuracy=0.654, loss=0.94, lr=0.002, val_accuracy=0.66, val_loss=0.929, val_lr=0.002]    0%|          | 5/1000 [20:45<68:43:17, 248.64s/epoch, accuracy=0.654, loss=0.935, lr=0.002, val_accuracy=0.664, val_loss=0.92, val_lr=0.002]  1%|          | 6/1000 [24:53<68:34:33, 248.36s/epoch, accuracy=0.655, loss=0.931, lr=0.002, val_accuracy=0.663, val_loss=0.918, val_lr=0.002]  1%|          | 7/1000 [29:00<68:24:49, 248.03s/epoch, accuracy=0.657, loss=0.929, lr=0.002, val_accuracy=0.664, val_loss=0.916, val_lr=0.002]  1%|          | 8/1000 [33:07<68:15:36, 247.72s/epoch, accuracy=0.657, loss=0.928, lr=0.002, val_accuracy=0.658, val_loss=0.925, val_lr=0.002]  1%|          | 9/1000 [37:15<68:11:08, 247.70s/epoch, accuracy=0.658, loss=0.927, lr=0.002, val_accuracy=0.666, val_loss=0.912, val_lr=0.002]  1%|          | 10/1000 [41:23<68:09:55, 247.87s/epoch, accuracy=0.658, loss=0.926, lr=0.002, val_accuracy=0.667, val_loss=0.912, val_lr=0.002]  1%|          | 11/1000 [45:32<68:07:55, 248.00s/epoch, accuracy=0.659, loss=0.926, lr=0.002, val_accuracy=0.654, val_loss=0.951, val_lr=0.002]  1%|          | 12/1000 [49:40<68:06:29, 248.17s/epoch, accuracy=0.659, loss=0.925, lr=0.002, val_accuracy=0.661, val_loss=0.924, val_lr=0.002]  1%|▏         | 13/1000 [53:48<68:01:37, 248.12s/epoch, accuracy=0.659, loss=0.925, lr=0.002, val_accuracy=0.666, val_loss=0.913, val_lr=0.002]  1%|▏         | 14/1000 [57:56<67:56:02, 248.03s/epoch, accuracy=0.66, loss=0.924, lr=0.002, val_accuracy=0.67, val_loss=0.91, val_lr=0.002]     2%|▏         | 15/1000 [1:02:05<67:55:32, 248.26s/epoch, accuracy=0.66, loss=0.924, lr=0.002, val_accuracy=0.664, val_loss=0.917, val_lr=0.002]  2%|▏         | 16/1000 [1:06:13<67:52:54, 248.35s/epoch, accuracy=0.661, loss=0.924, lr=0.002, val_accuracy=0.665, val_loss=0.917, val_lr=0.002]  2%|▏         | 17/1000 [1:10:23<67:55:26, 248.76s/epoch, accuracy=0.661, loss=0.924, lr=0.002, val_accuracy=0.666, val_loss=0.915, val_lr=0.002]  2%|▏         | 18/1000 [1:14:33<67:55:42, 249.02s/epoch, accuracy=0.662, loss=0.922, lr=0.002, val_accuracy=0.666, val_loss=0.914, val_lr=0.002]  2%|▏         | 19/1000 [1:18:42<67:51:00, 248.99s/epoch, accuracy=0.662, loss=0.922, lr=0.002, val_accuracy=0.669, val_loss=0.914, val_lr=0.002]  2%|▏         | 20/1000 [1:22:50<67:46:09, 248.95s/epoch, accuracy=0.662, loss=0.922, lr=0.002, val_accuracy=0.667, val_loss=0.912, val_lr=0.002]  2%|▏         | 21/1000 [1:26:59<67:41:49, 248.94s/epoch, accuracy=0.662, loss=0.922, lr=0.002, val_accuracy=0.654, val_loss=0.944, val_lr=0.002]  2%|▏         | 22/1000 [1:31:08<67:38:00, 248.96s/epoch, accuracy=0.663, loss=0.922, lr=0.002, val_accuracy=0.671, val_loss=0.908, val_lr=0.002]  2%|▏         | 23/1000 [1:35:16<67:25:50, 248.46s/epoch, accuracy=0.663, loss=0.921, lr=0.002, val_accuracy=0.662, val_loss=0.922, val_lr=0.002]  2%|▏         | 24/1000 [1:39:22<67:12:36, 247.91s/epoch, accuracy=0.663, loss=0.922, lr=0.002, val_accuracy=0.67, val_loss=0.912, val_lr=0.002]   2%|▎         | 25/1000 [1:43:30<67:09:26, 247.97s/epoch, accuracy=0.664, loss=0.921, lr=0.002, val_accuracy=0.668, val_loss=0.91, val_lr=0.002]  3%|▎         | 26/1000 [1:47:38<67:03:51, 247.88s/epoch, accuracy=0.663, loss=0.92, lr=0.002, val_accuracy=0.666, val_loss=0.917, val_lr=0.002]  3%|▎         | 27/1000 [1:51:46<66:58:23, 247.79s/epoch, accuracy=0.664, loss=0.92, lr=0.002, val_accuracy=0.673, val_loss=0.908, val_lr=0.002]  3%|▎         | 28/1000 [1:55:54<66:57:42, 248.01s/epoch, accuracy=0.664, loss=0.92, lr=0.002, val_accuracy=0.672, val_loss=0.906, val_lr=0.002]  3%|▎         | 29/1000 [2:00:02<66:54:37, 248.07s/epoch, accuracy=0.664, loss=0.92, lr=0.002, val_accuracy=0.658, val_loss=0.935, val_lr=0.002]  3%|▎         | 30/1000 [2:04:11<66:54:25, 248.31s/epoch, accuracy=0.664, loss=0.919, lr=0.002, val_accuracy=0.67, val_loss=0.911, val_lr=0.002]  3%|▎         | 31/1000 [2:08:21<66:57:22, 248.75s/epoch, accuracy=0.664, loss=0.919, lr=0.002, val_accuracy=0.662, val_loss=0.915, val_lr=0.002]  3%|▎         | 32/1000 [2:12:31<66:57:03, 248.99s/epoch, accuracy=0.664, loss=0.919, lr=0.002, val_accuracy=0.672, val_loss=0.913, val_lr=0.002]  3%|▎         | 33/1000 [2:16:41<66:59:32, 249.40s/epoch, accuracy=0.664, loss=0.919, lr=0.002, val_accuracy=0.663, val_loss=0.915, val_lr=0.002]  3%|▎         | 34/1000 [2:20:51<66:58:20, 249.59s/epoch, accuracy=0.665, loss=0.919, lr=0.002, val_accuracy=0.67, val_loss=0.913, val_lr=0.002]   4%|▎         | 35/1000 [2:25:01<66:56:54, 249.76s/epoch, accuracy=0.665, loss=0.919, lr=0.002, val_accuracy=0.673, val_loss=0.908, val_lr=0.002]  4%|▎         | 36/1000 [2:29:10<66:45:57, 249.33s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.66, val_loss=0.923, val_lr=0.002]   4%|▎         | 37/1000 [2:33:17<66:31:16, 248.68s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.67, val_loss=0.911, val_lr=0.002]  4%|▍         | 38/1000 [2:37:23<66:14:42, 247.90s/epoch, accuracy=0.665, loss=0.919, lr=0.002, val_accuracy=0.663, val_loss=0.921, val_lr=0.002]  4%|▍         | 39/1000 [2:41:28<65:59:14, 247.20s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.667, val_loss=0.916, val_lr=0.002]  4%|▍         | 40/1000 [2:45:31<65:32:05, 245.76s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.67, val_loss=0.906, val_lr=0.002]   4%|▍         | 41/1000 [2:49:30<64:57:04, 243.82s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.674, val_loss=0.904, val_lr=0.002]  4%|▍         | 42/1000 [2:53:32<64:46:09, 243.39s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.667, val_loss=0.912, val_lr=0.002]  4%|▍         | 43/1000 [2:57:35<64:37:50, 243.13s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.672, val_loss=0.907, val_lr=0.002]  4%|▍         | 44/1000 [3:01:38<64:32:27, 243.04s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.667, val_loss=0.917, val_lr=0.002]  4%|▍         | 45/1000 [3:05:40<64:26:29, 242.92s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.668, val_loss=0.905, val_lr=0.002]  5%|▍         | 46/1000 [3:09:43<64:23:01, 242.96s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.668, val_loss=0.908, val_lr=0.002]  5%|▍         | 47/1000 [3:13:46<64:18:04, 242.90s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.671, val_loss=0.913, val_lr=0.002]  5%|▍         | 48/1000 [3:17:48<64:08:39, 242.56s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.666, val_loss=0.916, val_lr=0.002]  5%|▍         | 49/1000 [3:21:49<63:59:00, 242.21s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.667, val_loss=0.911, val_lr=0.002]  5%|▌         | 50/1000 [3:25:47<63:35:23, 240.97s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.673, val_loss=0.904, val_lr=0.002]  5%|▌         | 51/1000 [3:29:46<63:20:41, 240.30s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.674, val_loss=0.906, val_lr=0.002]  5%|▌         | 52/1000 [3:33:44<63:04:39, 239.53s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.661, val_loss=0.924, val_lr=0.002]  5%|▌         | 53/1000 [3:37:40<62:44:03, 238.48s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.66, val_loss=0.922, val_lr=0.002]   5%|▌         | 54/1000 [3:41:36<62:29:25, 237.81s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.654, val_loss=0.929, val_lr=0.002]  6%|▌         | 55/1000 [3:45:31<62:13:40, 237.06s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.66, val_loss=0.919, val_lr=0.002]   6%|▌         | 56/1000 [3:49:27<62:02:23, 236.59s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.663, val_loss=0.924, val_lr=0.002]  6%|▌         | 57/1000 [3:53:23<61:56:18, 236.46s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.665, val_loss=0.914, val_lr=0.002]  6%|▌         | 58/1000 [3:57:17<61:40:11, 235.68s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.674, val_loss=0.903, val_lr=0.002]  6%|▌         | 59/1000 [4:01:07<61:09:24, 233.97s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.674, val_loss=0.904, val_lr=0.002]  6%|▌         | 60/1000 [4:04:55<60:35:44, 232.07s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.658, val_loss=0.927, val_lr=0.002]  6%|▌         | 61/1000 [4:08:42<60:10:50, 230.72s/epoch, accuracy=0.664, loss=0.917, lr=0.002, val_accuracy=0.675, val_loss=0.904, val_lr=0.002]  6%|▌         | 62/1000 [4:12:29<59:47:09, 229.46s/epoch, accuracy=0.664, loss=0.917, lr=0.002, val_accuracy=0.644, val_loss=0.945, val_lr=0.002]  6%|▋         | 63/1000 [4:16:16<59:33:33, 228.83s/epoch, accuracy=0.664, loss=0.917, lr=0.002, val_accuracy=0.663, val_loss=0.917, val_lr=0.002]  6%|▋         | 64/1000 [4:20:03<59:21:55, 228.33s/epoch, accuracy=0.665, loss=0.916, lr=0.002, val_accuracy=0.653, val_loss=0.936, val_lr=0.002]  6%|▋         | 65/1000 [4:23:50<59:09:24, 227.77s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.671, val_loss=0.906, val_lr=0.002]  7%|▋         | 66/1000 [4:27:34<58:51:37, 226.87s/epoch, accuracy=0.665, loss=0.916, lr=0.002, val_accuracy=0.669, val_loss=0.909, val_lr=0.002]  7%|▋         | 67/1000 [4:31:28<59:17:47, 228.80s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.66, val_loss=0.921, val_lr=0.002]   7%|▋         | 68/1000 [4:35:17<59:14:09, 228.81s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.661, val_loss=0.92, val_lr=0.002]  7%|▋         | 69/1000 [4:39:17<60:06:04, 232.40s/epoch, accuracy=0.665, loss=0.916, lr=0.002, val_accuracy=0.673, val_loss=0.903, val_lr=0.002]  7%|▋         | 70/1000 [4:43:25<61:14:51, 237.09s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.675, val_loss=0.908, val_lr=0.002]  7%|▋         | 71/1000 [4:47:30<61:46:07, 239.36s/epoch, accuracy=0.664, loss=0.916, lr=0.002, val_accuracy=0.669, val_loss=0.912, val_lr=0.002]  7%|▋         | 72/1000 [4:51:35<62:09:12, 241.11s/epoch, accuracy=0.666, loss=0.913, lr=0.0002, val_accuracy=0.674, val_loss=0.902, val_lr=0.0002]  7%|▋         | 73/1000 [4:55:41<62:26:33, 242.50s/epoch, accuracy=0.667, loss=0.913, lr=0.0002, val_accuracy=0.675, val_loss=0.902, val_lr=0.0002]  7%|▋         | 74/1000 [4:59:48<62:44:55, 243.95s/epoch, accuracy=0.667, loss=0.913, lr=0.0002, val_accuracy=0.673, val_loss=0.902, val_lr=0.0002]  8%|▊         | 75/1000 [5:03:56<63:00:25, 245.22s/epoch, accuracy=0.666, loss=0.913, lr=0.0002, val_accuracy=0.672, val_loss=0.902, val_lr=0.0002]  8%|▊         | 76/1000 [5:08:03<63:04:20, 245.74s/epoch, accuracy=0.667, loss=0.913, lr=0.0002, val_accuracy=0.673, val_loss=0.905, val_lr=0.0002]  8%|▊         | 77/1000 [5:12:13<63:18:01, 246.89s/epoch, accuracy=0.666, loss=0.913, lr=0.0002, val_accuracy=0.672, val_loss=0.902, val_lr=0.0002]  8%|▊         | 78/1000 [5:16:22<63:22:28, 247.45s/epoch, accuracy=0.667, loss=0.913, lr=0.0002, val_accuracy=0.672, val_loss=0.902, val_lr=0.0002]  8%|▊         | 79/1000 [5:20:33<63:37:13, 248.68s/epoch, accuracy=0.667, loss=0.913, lr=0.0002, val_accuracy=0.674, val_loss=0.902, val_lr=0.0002]  8%|▊         | 80/1000 [5:24:46<63:52:05, 249.92s/epoch, accuracy=0.666, loss=0.913, lr=0.0002, val_accuracy=0.675, val_loss=0.901, val_lr=0.0002]  8%|▊         | 81/1000 [5:29:04<64:24:26, 252.30s/epoch, accuracy=0.667, loss=0.913, lr=0.0002, val_accuracy=0.673, val_loss=0.902, val_lr=0.0002]  8%|▊         | 81/1000 [5:29:04<62:13:34, 243.76s/epoch, accuracy=0.667, loss=0.913, lr=0.0002, val_accuracy=0.673, val_loss=0.902, val_lr=0.0002]


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/log-nano-pelican-mlp/conf-pelican-1/config.yml


Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer_1       │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product_1     │ [(None, 32, 32,   │          0 │ input_layer_1[0]… │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer_1         │ (None, 32, 32, 1) │          1 │ inner_product_1[… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 1) │          4 │ log_layer_1[0][0] │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2_1          │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
│ (Lineq2v2)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense_1   │ (None, 32, 32, 3) │         24 │ lineq2v2_1[0][0]  │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply_1          │ (None, 32, 32, 3) │          0 │ diag_bias_dense_… │
│ (Multiply)          │                   │            │ inner_product_1[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 3) │         12 │ multiply_1[0][0]  │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0_1          │ (None, 6)         │          0 │ batch_normalizat… │
│ (Lineq2v0)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 5)         │         35 │ lineq2v0_1[0][0]  │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 76 (304.00 B)
 Trainable params: 68 (272.00 B)
 Non-trainable params: 8 (32.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]  0%|          | 1/1000 [04:19<72:01:19, 259.54s/epoch, accuracy=0.561, loss=1.17, lr=0.002, val_accuracy=0.656, val_loss=1.04, val_lr=0.002]  0%|          | 2/1000 [08:34<71:15:37, 257.05s/epoch, accuracy=0.65, loss=0.983, lr=0.002, val_accuracy=0.661, val_loss=0.945, val_lr=0.002]  0%|          | 3/1000 [12:38<69:28:04, 250.84s/epoch, accuracy=0.654, loss=0.949, lr=0.002, val_accuracy=0.661, val_loss=0.938, val_lr=0.002]  0%|          | 4/1000 [16:39<68:22:15, 247.12s/epoch, accuracy=0.654, loss=0.94, lr=0.002, val_accuracy=0.66, val_loss=0.929, val_lr=0.002]    0%|          | 5/1000 [20:43<67:58:07, 245.92s/epoch, accuracy=0.654, loss=0.935, lr=0.002, val_accuracy=0.664, val_loss=0.92, val_lr=0.002]  1%|          | 6/1000 [24:58<68:45:53, 249.05s/epoch, accuracy=0.655, loss=0.931, lr=0.002, val_accuracy=0.663, val_loss=0.918, val_lr=0.002]  1%|          | 7/1000 [29:14<69:16:27, 251.15s/epoch, accuracy=0.657, loss=0.929, lr=0.002, val_accuracy=0.664, val_loss=0.916, val_lr=0.002]  1%|          | 8/1000 [33:29<69:32:45, 252.38s/epoch, accuracy=0.657, loss=0.928, lr=0.002, val_accuracy=0.658, val_loss=0.925, val_lr=0.002]  1%|          | 9/1000 [37:44<69:44:15, 253.34s/epoch, accuracy=0.658, loss=0.927, lr=0.002, val_accuracy=0.666, val_loss=0.912, val_lr=0.002]  1%|          | 10/1000 [42:02<70:01:55, 254.66s/epoch, accuracy=0.658, loss=0.926, lr=0.002, val_accuracy=0.667, val_loss=0.912, val_lr=0.002]  1%|          | 11/1000 [46:18<70:05:58, 255.17s/epoch, accuracy=0.659, loss=0.926, lr=0.002, val_accuracy=0.654, val_loss=0.951, val_lr=0.002]  1%|          | 12/1000 [50:35<70:09:37, 255.65s/epoch, accuracy=0.659, loss=0.925, lr=0.002, val_accuracy=0.661, val_loss=0.924, val_lr=0.002]  1%|▏         | 13/1000 [54:53<70:19:16, 256.49s/epoch, accuracy=0.659, loss=0.925, lr=0.002, val_accuracy=0.666, val_loss=0.913, val_lr=0.002]  1%|▏         | 14/1000 [59:10<70:16:42, 256.60s/epoch, accuracy=0.66, loss=0.924, lr=0.002, val_accuracy=0.67, val_loss=0.91, val_lr=0.002]     2%|▏         | 15/1000 [1:03:28<70:21:24, 257.14s/epoch, accuracy=0.66, loss=0.924, lr=0.002, val_accuracy=0.664, val_loss=0.917, val_lr=0.002]  2%|▏         | 16/1000 [1:07:44<70:09:35, 256.68s/epoch, accuracy=0.661, loss=0.924, lr=0.002, val_accuracy=0.665, val_loss=0.917, val_lr=0.002]  2%|▏         | 17/1000 [1:12:00<70:02:30, 256.51s/epoch, accuracy=0.661, loss=0.924, lr=0.002, val_accuracy=0.666, val_loss=0.915, val_lr=0.002]  2%|▏         | 18/1000 [1:16:16<69:55:54, 256.37s/epoch, accuracy=0.662, loss=0.922, lr=0.002, val_accuracy=0.666, val_loss=0.914, val_lr=0.002]  2%|▏         | 19/1000 [1:20:33<69:51:40, 256.37s/epoch, accuracy=0.662, loss=0.922, lr=0.002, val_accuracy=0.669, val_loss=0.914, val_lr=0.002]  2%|▏         | 20/1000 [1:24:43<69:18:52, 254.62s/epoch, accuracy=0.662, loss=0.922, lr=0.002, val_accuracy=0.667, val_loss=0.912, val_lr=0.002]  2%|▏         | 21/1000 [1:28:48<68:26:30, 251.68s/epoch, accuracy=0.662, loss=0.922, lr=0.002, val_accuracy=0.654, val_loss=0.944, val_lr=0.002]  2%|▏         | 22/1000 [1:32:53<67:51:58, 249.81s/epoch, accuracy=0.663, loss=0.922, lr=0.002, val_accuracy=0.671, val_loss=0.908, val_lr=0.002]  2%|▏         | 23/1000 [1:36:58<67:21:57, 248.23s/epoch, accuracy=0.663, loss=0.921, lr=0.002, val_accuracy=0.662, val_loss=0.922, val_lr=0.002]  2%|▏         | 24/1000 [1:41:02<66:55:30, 246.85s/epoch, accuracy=0.663, loss=0.922, lr=0.002, val_accuracy=0.67, val_loss=0.912, val_lr=0.002]   2%|▎         | 25/1000 [1:45:05<66:35:11, 245.86s/epoch, accuracy=0.664, loss=0.921, lr=0.002, val_accuracy=0.668, val_loss=0.91, val_lr=0.002]  3%|▎         | 26/1000 [1:49:08<66:18:21, 245.07s/epoch, accuracy=0.663, loss=0.92, lr=0.002, val_accuracy=0.666, val_loss=0.917, val_lr=0.002]  3%|▎         | 27/1000 [1:53:12<66:06:56, 244.62s/epoch, accuracy=0.664, loss=0.92, lr=0.002, val_accuracy=0.673, val_loss=0.908, val_lr=0.002]  3%|▎         | 28/1000 [1:57:16<66:00:42, 244.49s/epoch, accuracy=0.664, loss=0.92, lr=0.002, val_accuracy=0.672, val_loss=0.906, val_lr=0.002]  3%|▎         | 29/1000 [2:01:20<65:56:01, 244.45s/epoch, accuracy=0.664, loss=0.92, lr=0.002, val_accuracy=0.658, val_loss=0.935, val_lr=0.002]  3%|▎         | 30/1000 [2:05:24<65:47:37, 244.18s/epoch, accuracy=0.664, loss=0.919, lr=0.002, val_accuracy=0.67, val_loss=0.911, val_lr=0.002]  3%|▎         | 31/1000 [2:09:28<65:41:36, 244.06s/epoch, accuracy=0.664, loss=0.919, lr=0.002, val_accuracy=0.662, val_loss=0.915, val_lr=0.002]  3%|▎         | 32/1000 [2:13:32<65:36:27, 244.00s/epoch, accuracy=0.664, loss=0.919, lr=0.002, val_accuracy=0.672, val_loss=0.913, val_lr=0.002]  3%|▎         | 33/1000 [2:17:35<65:31:46, 243.96s/epoch, accuracy=0.664, loss=0.919, lr=0.002, val_accuracy=0.663, val_loss=0.915, val_lr=0.002]  3%|▎         | 34/1000 [2:21:39<65:27:35, 243.95s/epoch, accuracy=0.665, loss=0.919, lr=0.002, val_accuracy=0.67, val_loss=0.913, val_lr=0.002]   4%|▎         | 35/1000 [2:25:43<65:23:52, 243.97s/epoch, accuracy=0.665, loss=0.919, lr=0.002, val_accuracy=0.673, val_loss=0.908, val_lr=0.002]  4%|▎         | 36/1000 [2:29:47<65:16:57, 243.79s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.66, val_loss=0.923, val_lr=0.002]   4%|▎         | 37/1000 [2:33:50<65:11:47, 243.72s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.67, val_loss=0.911, val_lr=0.002]  4%|▍         | 38/1000 [2:37:54<65:05:26, 243.58s/epoch, accuracy=0.665, loss=0.919, lr=0.002, val_accuracy=0.663, val_loss=0.921, val_lr=0.002]  4%|▍         | 39/1000 [2:41:57<65:01:46, 243.61s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.667, val_loss=0.916, val_lr=0.002]  4%|▍         | 40/1000 [2:46:02<65:02:37, 243.91s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.67, val_loss=0.906, val_lr=0.002]   4%|▍         | 41/1000 [2:50:07<65:05:36, 244.36s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.674, val_loss=0.904, val_lr=0.002]  4%|▍         | 42/1000 [2:54:12<65:02:20, 244.41s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.667, val_loss=0.912, val_lr=0.002]  4%|▍         | 43/1000 [2:58:16<64:56:28, 244.29s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.672, val_loss=0.907, val_lr=0.002]  4%|▍         | 44/1000 [3:02:20<64:53:20, 244.35s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.667, val_loss=0.917, val_lr=0.002]  4%|▍         | 45/1000 [3:06:45<66:27:57, 250.55s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.668, val_loss=0.905, val_lr=0.002]  5%|▍         | 46/1000 [3:11:19<68:15:31, 257.58s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.668, val_loss=0.908, val_lr=0.002]  5%|▍         | 47/1000 [3:15:42<68:36:05, 259.15s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.671, val_loss=0.913, val_lr=0.002]  5%|▍         | 48/1000 [3:19:39<66:43:52, 252.34s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.666, val_loss=0.916, val_lr=0.002]  5%|▍         | 49/1000 [3:23:32<65:09:04, 246.63s/epoch, accuracy=0.665, loss=0.918, lr=0.002, val_accuracy=0.667, val_loss=0.911, val_lr=0.002]  5%|▌         | 50/1000 [3:27:22<63:45:36, 241.62s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.673, val_loss=0.904, val_lr=0.002]  5%|▌         | 51/1000 [3:31:12<62:46:36, 238.14s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.674, val_loss=0.906, val_lr=0.002]  5%|▌         | 52/1000 [3:34:58<61:46:46, 234.61s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.661, val_loss=0.924, val_lr=0.002]  5%|▌         | 53/1000 [3:38:44<60:58:48, 231.81s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.66, val_loss=0.922, val_lr=0.002]   5%|▌         | 54/1000 [3:42:29<60:22:42, 229.77s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.654, val_loss=0.929, val_lr=0.002]  6%|▌         | 55/1000 [3:46:13<59:54:57, 228.25s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.66, val_loss=0.919, val_lr=0.002]   6%|▌         | 56/1000 [3:49:57<59:30:44, 226.95s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.663, val_loss=0.924, val_lr=0.002]  6%|▌         | 57/1000 [3:53:41<59:14:23, 226.15s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.665, val_loss=0.914, val_lr=0.002]  6%|▌         | 58/1000 [3:57:26<59:00:40, 225.52s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.674, val_loss=0.903, val_lr=0.002]  6%|▌         | 59/1000 [4:01:11<58:55:29, 225.43s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.674, val_loss=0.904, val_lr=0.002]  6%|▌         | 60/1000 [4:04:56<58:52:29, 225.48s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.658, val_loss=0.927, val_lr=0.002]  6%|▌         | 61/1000 [4:08:51<59:30:39, 228.16s/epoch, accuracy=0.664, loss=0.917, lr=0.002, val_accuracy=0.675, val_loss=0.904, val_lr=0.002]  6%|▌         | 62/1000 [4:12:55<60:44:29, 233.12s/epoch, accuracy=0.664, loss=0.917, lr=0.002, val_accuracy=0.644, val_loss=0.945, val_lr=0.002]  6%|▋         | 63/1000 [4:17:01<61:39:58, 236.92s/epoch, accuracy=0.664, loss=0.917, lr=0.002, val_accuracy=0.663, val_loss=0.917, val_lr=0.002]  6%|▋         | 64/1000 [4:21:07<62:18:36, 239.65s/epoch, accuracy=0.665, loss=0.916, lr=0.002, val_accuracy=0.653, val_loss=0.936, val_lr=0.002]  6%|▋         | 65/1000 [4:25:16<62:55:35, 242.28s/epoch, accuracy=0.665, loss=0.917, lr=0.002, val_accuracy=0.671, val_loss=0.906, val_lr=0.002]  7%|▋         | 66/1000 [4:29:27<63:32:30, 244.91s/epoch, accuracy=0.665, loss=0.916, lr=0.002, val_accuracy=0.669, val_loss=0.909, val_lr=0.002]slurmstepd: error: *** JOB 61661032 ON eu-g5-032-2 CANCELLED AT 2024-06-09T03:32:15 DUE TO TIME LIMIT ***
