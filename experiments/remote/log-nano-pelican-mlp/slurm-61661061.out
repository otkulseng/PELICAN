2024-06-08 17:33:36.973897: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:33:36.977877: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 17:33:37.034614: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 17:33:39.188598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 17:33:48.206669: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/log-nano-pelican-mlp/conf-pelican-2/config.yml


Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer           │ (None, 32, 32, 1) │          1 │ inner_product[0]… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 1) │          4 │ log_layer[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32, 5) │         40 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 5) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 5) │         20 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 10)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 5)         │         55 │ lineq2v0[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 120 (480.00 B)
 Trainable params: 108 (432.00 B)
 Non-trainable params: 12 (48.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [05:17<88:02:04, 317.24s/epoch, accuracy=0.591, loss=1.11, lr=0.002, val_accuracy=0.652, val_loss=1, val_lr=0.002]  0%|          | 2/1000 [10:25<86:31:35, 312.12s/epoch, accuracy=0.656, loss=0.983, lr=0.002, val_accuracy=0.655, val_loss=0.982, val_lr=0.002]  0%|          | 3/1000 [15:34<86:01:43, 310.64s/epoch, accuracy=0.66, loss=0.967, lr=0.002, val_accuracy=0.662, val_loss=0.962, val_lr=0.002]   0%|          | 4/1000 [20:43<85:48:02, 310.12s/epoch, accuracy=0.661, loss=0.958, lr=0.002, val_accuracy=0.667, val_loss=0.95, val_lr=0.002]  0%|          | 5/1000 [25:41<84:29:25, 305.69s/epoch, accuracy=0.662, loss=0.951, lr=0.002, val_accuracy=0.651, val_loss=0.965, val_lr=0.002]  1%|          | 6/1000 [30:38<83:31:44, 302.52s/epoch, accuracy=0.664, loss=0.946, lr=0.002, val_accuracy=0.665, val_loss=0.943, val_lr=0.002]  1%|          | 7/1000 [35:34<82:50:48, 300.35s/epoch, accuracy=0.664, loss=0.943, lr=0.002, val_accuracy=0.67, val_loss=0.934, val_lr=0.002]   1%|          | 8/1000 [40:30<82:26:32, 299.19s/epoch, accuracy=0.664, loss=0.939, lr=0.002, val_accuracy=0.66, val_loss=0.947, val_lr=0.002]  1%|          | 9/1000 [45:29<82:17:32, 298.94s/epoch, accuracy=0.664, loss=0.936, lr=0.002, val_accuracy=0.672, val_loss=0.928, val_lr=0.002]  1%|          | 10/1000 [50:28<82:13:38, 299.01s/epoch, accuracy=0.665, loss=0.932, lr=0.002, val_accuracy=0.672, val_loss=0.922, val_lr=0.002]  1%|          | 11/1000 [55:26<82:04:18, 298.75s/epoch, accuracy=0.666, loss=0.927, lr=0.002, val_accuracy=0.675, val_loss=0.917, val_lr=0.002]  1%|          | 12/1000 [1:00:24<81:58:05, 298.67s/epoch, accuracy=0.668, loss=0.922, lr=0.002, val_accuracy=0.654, val_loss=0.926, val_lr=0.002]  1%|▏         | 13/1000 [1:05:23<81:53:16, 298.68s/epoch, accuracy=0.668, loss=0.921, lr=0.002, val_accuracy=0.672, val_loss=0.93, val_lr=0.002]   1%|▏         | 14/1000 [1:10:23<81:52:57, 298.96s/epoch, accuracy=0.669, loss=0.919, lr=0.002, val_accuracy=0.651, val_loss=0.93, val_lr=0.002]  2%|▏         | 15/1000 [1:15:23<81:54:54, 299.39s/epoch, accuracy=0.67, loss=0.919, lr=0.002, val_accuracy=0.671, val_loss=0.919, val_lr=0.002]  2%|▏         | 16/1000 [1:20:22<81:48:04, 299.27s/epoch, accuracy=0.671, loss=0.917, lr=0.002, val_accuracy=0.672, val_loss=0.914, val_lr=0.002]  2%|▏         | 17/1000 [1:25:21<81:41:58, 299.21s/epoch, accuracy=0.671, loss=0.917, lr=0.002, val_accuracy=0.679, val_loss=0.907, val_lr=0.002]  2%|▏         | 18/1000 [1:30:20<81:33:32, 298.99s/epoch, accuracy=0.671, loss=0.916, lr=0.002, val_accuracy=0.683, val_loss=0.902, val_lr=0.002]  2%|▏         | 19/1000 [1:35:16<81:15:59, 298.23s/epoch, accuracy=0.672, loss=0.915, lr=0.002, val_accuracy=0.672, val_loss=0.916, val_lr=0.002]  2%|▏         | 20/1000 [1:40:13<81:03:49, 297.79s/epoch, accuracy=0.672, loss=0.915, lr=0.002, val_accuracy=0.67, val_loss=0.922, val_lr=0.002]   2%|▏         | 21/1000 [1:45:10<80:57:46, 297.72s/epoch, accuracy=0.673, loss=0.914, lr=0.002, val_accuracy=0.677, val_loss=0.907, val_lr=0.002]  2%|▏         | 22/1000 [1:50:06<80:44:11, 297.19s/epoch, accuracy=0.673, loss=0.913, lr=0.002, val_accuracy=0.666, val_loss=0.934, val_lr=0.002]  2%|▏         | 23/1000 [1:55:04<80:39:39, 297.22s/epoch, accuracy=0.672, loss=0.914, lr=0.002, val_accuracy=0.681, val_loss=0.902, val_lr=0.002]  2%|▏         | 24/1000 [2:00:01<80:35:45, 297.28s/epoch, accuracy=0.672, loss=0.913, lr=0.002, val_accuracy=0.681, val_loss=0.901, val_lr=0.002]  2%|▎         | 25/1000 [2:05:00<80:39:38, 297.82s/epoch, accuracy=0.673, loss=0.913, lr=0.002, val_accuracy=0.669, val_loss=0.908, val_lr=0.002]  3%|▎         | 26/1000 [2:09:59<80:39:38, 298.13s/epoch, accuracy=0.673, loss=0.912, lr=0.002, val_accuracy=0.679, val_loss=0.907, val_lr=0.002]  3%|▎         | 27/1000 [2:14:58<80:40:56, 298.52s/epoch, accuracy=0.673, loss=0.912, lr=0.002, val_accuracy=0.687, val_loss=0.9, val_lr=0.002]    3%|▎         | 28/1000 [2:19:57<80:38:11, 298.65s/epoch, accuracy=0.674, loss=0.912, lr=0.002, val_accuracy=0.677, val_loss=0.908, val_lr=0.002]  3%|▎         | 29/1000 [2:24:57<80:36:06, 298.83s/epoch, accuracy=0.674, loss=0.911, lr=0.002, val_accuracy=0.668, val_loss=0.926, val_lr=0.002]  3%|▎         | 30/1000 [2:29:53<80:20:28, 298.17s/epoch, accuracy=0.674, loss=0.911, lr=0.002, val_accuracy=0.682, val_loss=0.9, val_lr=0.002]    3%|▎         | 31/1000 [2:34:49<80:03:40, 297.44s/epoch, accuracy=0.674, loss=0.911, lr=0.002, val_accuracy=0.676, val_loss=0.915, val_lr=0.002]  3%|▎         | 32/1000 [2:39:44<79:46:00, 296.65s/epoch, accuracy=0.674, loss=0.911, lr=0.002, val_accuracy=0.675, val_loss=0.914, val_lr=0.002]  3%|▎         | 33/1000 [2:44:34<79:07:59, 294.60s/epoch, accuracy=0.675, loss=0.91, lr=0.002, val_accuracy=0.681, val_loss=0.908, val_lr=0.002]   3%|▎         | 34/1000 [2:49:21<78:27:51, 292.41s/epoch, accuracy=0.675, loss=0.909, lr=0.002, val_accuracy=0.685, val_loss=0.899, val_lr=0.002]  4%|▎         | 35/1000 [2:54:14<78:23:39, 292.46s/epoch, accuracy=0.674, loss=0.91, lr=0.002, val_accuracy=0.683, val_loss=0.896, val_lr=0.002]   4%|▎         | 36/1000 [2:59:05<78:14:27, 292.19s/epoch, accuracy=0.675, loss=0.909, lr=0.002, val_accuracy=0.669, val_loss=0.925, val_lr=0.002]  4%|▎         | 37/1000 [3:03:56<78:03:40, 291.82s/epoch, accuracy=0.675, loss=0.909, lr=0.002, val_accuracy=0.684, val_loss=0.899, val_lr=0.002]  4%|▍         | 38/1000 [3:08:48<77:57:00, 291.71s/epoch, accuracy=0.678, loss=0.905, lr=0.0002, val_accuracy=0.688, val_loss=0.892, val_lr=0.0002]  4%|▍         | 39/1000 [3:13:39<77:49:45, 291.56s/epoch, accuracy=0.678, loss=0.905, lr=0.0002, val_accuracy=0.685, val_loss=0.893, val_lr=0.0002]  4%|▍         | 40/1000 [3:18:29<77:36:31, 291.03s/epoch, accuracy=0.678, loss=0.905, lr=0.0002, val_accuracy=0.686, val_loss=0.892, val_lr=0.0002]  4%|▍         | 41/1000 [3:23:16<77:14:26, 289.95s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.686, val_loss=0.892, val_lr=0.0002]  4%|▍         | 42/1000 [3:28:02<76:52:49, 288.90s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.687, val_loss=0.891, val_lr=0.0002]  4%|▍         | 43/1000 [3:32:49<76:37:52, 288.27s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.685, val_loss=0.894, val_lr=0.0002]  4%|▍         | 44/1000 [3:37:35<76:21:26, 287.54s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.686, val_loss=0.891, val_lr=0.0002]  4%|▍         | 45/1000 [3:42:21<76:07:04, 286.94s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.683, val_loss=0.893, val_lr=0.0002]  5%|▍         | 46/1000 [3:47:06<75:57:11, 286.62s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.688, val_loss=0.891, val_lr=0.0002]  5%|▍         | 47/1000 [3:51:52<75:47:24, 286.30s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.685, val_loss=0.892, val_lr=0.0002]  5%|▍         | 48/1000 [3:56:34<75:20:41, 284.92s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.687, val_loss=0.891, val_lr=0.0002]  5%|▍         | 49/1000 [4:01:10<74:33:08, 282.22s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.686, val_loss=0.891, val_lr=0.0002]  5%|▌         | 50/1000 [4:05:44<73:52:22, 279.94s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.685, val_loss=0.893, val_lr=0.0002]  5%|▌         | 51/1000 [4:10:16<73:07:16, 277.38s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.688, val_loss=0.892, val_lr=0.0002]  5%|▌         | 52/1000 [4:14:46<72:30:44, 275.36s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.689, val_loss=0.891, val_lr=0.0002]  5%|▌         | 53/1000 [4:19:17<72:04:17, 273.98s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.688, val_loss=0.891, val_lr=0.0002]  5%|▌         | 54/1000 [4:23:48<71:44:24, 273.01s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.684, val_loss=0.894, val_lr=0.0002]  6%|▌         | 55/1000 [4:28:23<71:50:24, 273.68s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.685, val_loss=0.892, val_lr=0.0002]  6%|▌         | 56/1000 [4:33:00<72:00:34, 274.61s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.688, val_loss=0.89, val_lr=0.0002]   6%|▌         | 57/1000 [4:37:41<72:28:33, 276.68s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.687, val_loss=0.891, val_lr=0.0002]  6%|▌         | 58/1000 [4:42:31<73:23:59, 280.51s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.688, val_loss=0.89, val_lr=0.0002]   6%|▌         | 59/1000 [4:47:19<73:57:25, 282.94s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.688, val_loss=0.891, val_lr=0.0002]  6%|▌         | 60/1000 [4:52:09<74:25:37, 285.04s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.688, val_loss=0.89, val_lr=0.0002]   6%|▌         | 61/1000 [4:56:58<74:38:29, 286.17s/epoch, accuracy=0.679, loss=0.903, lr=0.0002, val_accuracy=0.688, val_loss=0.89, val_lr=0.0002]  6%|▌         | 62/1000 [5:01:50<75:00:37, 287.89s/epoch, accuracy=0.679, loss=0.903, lr=0.0002, val_accuracy=0.687, val_loss=0.891, val_lr=0.0002]  6%|▋         | 63/1000 [5:06:40<75:05:44, 288.52s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.688, val_loss=0.89, val_lr=2e-5]       6%|▋         | 64/1000 [5:11:31<75:14:36, 289.40s/epoch, accuracy=0.68, loss=0.903, lr=2e-5, val_accuracy=0.687, val_loss=0.89, val_lr=2e-5]   6%|▋         | 65/1000 [5:16:23<75:21:45, 290.17s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.688, val_loss=0.89, val_lr=2e-5]  7%|▋         | 66/1000 [5:21:17<75:33:32, 291.23s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.688, val_loss=0.89, val_lr=2e-5]  7%|▋         | 67/1000 [5:26:16<76:02:10, 293.39s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.688, val_loss=0.89, val_lr=2e-5]  7%|▋         | 68/1000 [5:31:15<76:27:15, 295.32s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.688, val_loss=0.89, val_lr=2e-5]  7%|▋         | 69/1000 [5:36:15<76:41:45, 296.57s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.688, val_loss=0.89, val_lr=2e-5]  7%|▋         | 70/1000 [5:41:07<76:16:09, 295.24s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.688, val_loss=0.89, val_lr=2e-5]  7%|▋         | 71/1000 [5:45:59<75:54:13, 294.14s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.688, val_loss=0.89, val_lr=2e-5]  7%|▋         | 72/1000 [5:50:51<75:41:46, 293.65s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.687, val_loss=0.89, val_lr=2e-5]  7%|▋         | 72/1000 [5:50:51<75:22:11, 292.38s/epoch, accuracy=0.679, loss=0.903, lr=2e-5, val_accuracy=0.687, val_loss=0.89, val_lr=2e-5]


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/log-nano-pelican-mlp/conf-pelican-2/config.yml


Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer_1       │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product_1     │ [(None, 32, 32,   │          0 │ input_layer_1[0]… │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer_1         │ (None, 32, 32, 1) │          1 │ inner_product_1[… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 1) │          4 │ log_layer_1[0][0] │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2_1          │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
│ (Lineq2v2)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense_1   │ (None, 32, 32, 5) │         40 │ lineq2v2_1[0][0]  │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply_1          │ (None, 32, 32, 5) │          0 │ diag_bias_dense_… │
│ (Multiply)          │                   │            │ inner_product_1[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 5) │         20 │ multiply_1[0][0]  │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0_1          │ (None, 10)        │          0 │ batch_normalizat… │
│ (Lineq2v0)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 5)         │         55 │ lineq2v0_1[0][0]  │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 120 (480.00 B)
 Trainable params: 108 (432.00 B)
 Non-trainable params: 12 (48.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]  0%|          | 1/1000 [05:00<83:16:04, 300.06s/epoch, accuracy=0.591, loss=1.11, lr=0.002, val_accuracy=0.652, val_loss=1, val_lr=0.002]  0%|          | 2/1000 [09:58<82:51:34, 298.89s/epoch, accuracy=0.656, loss=0.983, lr=0.002, val_accuracy=0.655, val_loss=0.982, val_lr=0.002]  0%|          | 3/1000 [14:56<82:42:26, 298.64s/epoch, accuracy=0.66, loss=0.967, lr=0.002, val_accuracy=0.662, val_loss=0.962, val_lr=0.002]   0%|          | 4/1000 [19:55<82:37:14, 298.63s/epoch, accuracy=0.661, loss=0.958, lr=0.002, val_accuracy=0.667, val_loss=0.95, val_lr=0.002]  0%|          | 5/1000 [24:53<82:33:41, 298.72s/epoch, accuracy=0.662, loss=0.951, lr=0.002, val_accuracy=0.651, val_loss=0.965, val_lr=0.002]  1%|          | 6/1000 [29:53<82:35:19, 299.11s/epoch, accuracy=0.664, loss=0.946, lr=0.002, val_accuracy=0.665, val_loss=0.943, val_lr=0.002]  1%|          | 7/1000 [34:51<82:23:02, 298.67s/epoch, accuracy=0.664, loss=0.943, lr=0.002, val_accuracy=0.67, val_loss=0.934, val_lr=0.002]   1%|          | 8/1000 [39:49<82:14:43, 298.47s/epoch, accuracy=0.664, loss=0.939, lr=0.002, val_accuracy=0.66, val_loss=0.947, val_lr=0.002]  1%|          | 9/1000 [44:46<82:03:20, 298.08s/epoch, accuracy=0.664, loss=0.936, lr=0.002, val_accuracy=0.672, val_loss=0.928, val_lr=0.002]  1%|          | 10/1000 [49:45<81:59:29, 298.15s/epoch, accuracy=0.665, loss=0.932, lr=0.002, val_accuracy=0.672, val_loss=0.922, val_lr=0.002]  1%|          | 11/1000 [54:45<82:04:38, 298.76s/epoch, accuracy=0.666, loss=0.927, lr=0.002, val_accuracy=0.675, val_loss=0.917, val_lr=0.002]  1%|          | 12/1000 [59:45<82:05:04, 299.09s/epoch, accuracy=0.668, loss=0.922, lr=0.002, val_accuracy=0.654, val_loss=0.926, val_lr=0.002]  1%|▏         | 13/1000 [1:04:40<81:41:58, 297.99s/epoch, accuracy=0.668, loss=0.921, lr=0.002, val_accuracy=0.672, val_loss=0.93, val_lr=0.002]  1%|▏         | 14/1000 [1:09:36<81:26:40, 297.36s/epoch, accuracy=0.669, loss=0.919, lr=0.002, val_accuracy=0.651, val_loss=0.93, val_lr=0.002]  2%|▏         | 15/1000 [1:14:30<81:07:14, 296.48s/epoch, accuracy=0.67, loss=0.919, lr=0.002, val_accuracy=0.671, val_loss=0.919, val_lr=0.002]  2%|▏         | 16/1000 [1:19:25<80:51:09, 295.80s/epoch, accuracy=0.671, loss=0.917, lr=0.002, val_accuracy=0.672, val_loss=0.914, val_lr=0.002]  2%|▏         | 17/1000 [1:24:19<80:37:46, 295.29s/epoch, accuracy=0.671, loss=0.917, lr=0.002, val_accuracy=0.679, val_loss=0.907, val_lr=0.002]  2%|▏         | 18/1000 [1:29:13<80:26:53, 294.92s/epoch, accuracy=0.671, loss=0.916, lr=0.002, val_accuracy=0.683, val_loss=0.902, val_lr=0.002]  2%|▏         | 19/1000 [1:34:07<80:17:58, 294.68s/epoch, accuracy=0.672, loss=0.915, lr=0.002, val_accuracy=0.672, val_loss=0.916, val_lr=0.002]  2%|▏         | 20/1000 [1:39:01<80:11:47, 294.60s/epoch, accuracy=0.672, loss=0.915, lr=0.002, val_accuracy=0.67, val_loss=0.922, val_lr=0.002]   2%|▏         | 21/1000 [1:43:56<80:07:33, 294.64s/epoch, accuracy=0.673, loss=0.914, lr=0.002, val_accuracy=0.677, val_loss=0.907, val_lr=0.002]  2%|▏         | 22/1000 [1:48:50<80:01:05, 294.55s/epoch, accuracy=0.673, loss=0.913, lr=0.002, val_accuracy=0.666, val_loss=0.934, val_lr=0.002]  2%|▏         | 23/1000 [1:53:44<79:53:36, 294.39s/epoch, accuracy=0.672, loss=0.914, lr=0.002, val_accuracy=0.681, val_loss=0.902, val_lr=0.002]  2%|▏         | 24/1000 [1:58:38<79:46:40, 294.26s/epoch, accuracy=0.672, loss=0.913, lr=0.002, val_accuracy=0.681, val_loss=0.901, val_lr=0.002]  2%|▎         | 25/1000 [2:03:32<79:39:21, 294.11s/epoch, accuracy=0.673, loss=0.913, lr=0.002, val_accuracy=0.669, val_loss=0.908, val_lr=0.002]  3%|▎         | 26/1000 [2:08:26<79:33:03, 294.03s/epoch, accuracy=0.673, loss=0.912, lr=0.002, val_accuracy=0.679, val_loss=0.907, val_lr=0.002]  3%|▎         | 27/1000 [2:13:20<79:26:34, 293.93s/epoch, accuracy=0.673, loss=0.912, lr=0.002, val_accuracy=0.687, val_loss=0.9, val_lr=0.002]    3%|▎         | 28/1000 [2:18:14<79:21:47, 293.94s/epoch, accuracy=0.674, loss=0.912, lr=0.002, val_accuracy=0.677, val_loss=0.908, val_lr=0.002]  3%|▎         | 29/1000 [2:23:08<79:19:33, 294.10s/epoch, accuracy=0.674, loss=0.911, lr=0.002, val_accuracy=0.668, val_loss=0.926, val_lr=0.002]  3%|▎         | 30/1000 [2:28:04<79:22:14, 294.57s/epoch, accuracy=0.674, loss=0.911, lr=0.002, val_accuracy=0.682, val_loss=0.9, val_lr=0.002]    3%|▎         | 31/1000 [2:32:59<79:21:09, 294.81s/epoch, accuracy=0.674, loss=0.911, lr=0.002, val_accuracy=0.676, val_loss=0.915, val_lr=0.002]  3%|▎         | 32/1000 [2:37:54<79:16:36, 294.83s/epoch, accuracy=0.674, loss=0.911, lr=0.002, val_accuracy=0.675, val_loss=0.914, val_lr=0.002]  3%|▎         | 33/1000 [2:43:16<81:20:53, 302.85s/epoch, accuracy=0.675, loss=0.91, lr=0.002, val_accuracy=0.681, val_loss=0.908, val_lr=0.002]   3%|▎         | 34/1000 [2:48:54<84:09:39, 313.64s/epoch, accuracy=0.675, loss=0.909, lr=0.002, val_accuracy=0.685, val_loss=0.899, val_lr=0.002]  4%|▎         | 35/1000 [2:54:02<83:32:40, 311.67s/epoch, accuracy=0.674, loss=0.91, lr=0.002, val_accuracy=0.683, val_loss=0.896, val_lr=0.002]   4%|▎         | 36/1000 [2:58:45<81:11:44, 303.22s/epoch, accuracy=0.675, loss=0.909, lr=0.002, val_accuracy=0.669, val_loss=0.925, val_lr=0.002]  4%|▎         | 37/1000 [3:03:21<78:56:23, 295.10s/epoch, accuracy=0.675, loss=0.909, lr=0.002, val_accuracy=0.684, val_loss=0.899, val_lr=0.002]  4%|▍         | 38/1000 [3:07:57<77:16:25, 289.17s/epoch, accuracy=0.678, loss=0.905, lr=0.0002, val_accuracy=0.688, val_loss=0.892, val_lr=0.0002]  4%|▍         | 39/1000 [3:12:27<75:43:26, 283.67s/epoch, accuracy=0.678, loss=0.905, lr=0.0002, val_accuracy=0.685, val_loss=0.893, val_lr=0.0002]  4%|▍         | 40/1000 [3:16:58<74:34:21, 279.65s/epoch, accuracy=0.678, loss=0.905, lr=0.0002, val_accuracy=0.686, val_loss=0.892, val_lr=0.0002]  4%|▍         | 41/1000 [3:21:27<73:40:09, 276.55s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.686, val_loss=0.892, val_lr=0.0002]  4%|▍         | 42/1000 [3:25:56<72:59:11, 274.27s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.687, val_loss=0.891, val_lr=0.0002]  4%|▍         | 43/1000 [3:30:24<72:25:29, 272.44s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.685, val_loss=0.894, val_lr=0.0002]  4%|▍         | 44/1000 [3:34:52<71:59:03, 271.07s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.686, val_loss=0.891, val_lr=0.0002]  4%|▍         | 45/1000 [3:39:45<73:41:13, 277.77s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.683, val_loss=0.893, val_lr=0.0002]  5%|▍         | 46/1000 [3:44:42<75:07:41, 283.50s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.688, val_loss=0.891, val_lr=0.0002]  5%|▍         | 47/1000 [3:49:43<76:26:27, 288.76s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.685, val_loss=0.892, val_lr=0.0002]  5%|▍         | 48/1000 [3:54:56<78:14:38, 295.88s/epoch, accuracy=0.678, loss=0.904, lr=0.0002, val_accuracy=0.687, val_loss=0.891, val_lr=0.0002]  5%|▍         | 49/1000 [4:00:15<79:59:20, 302.80s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.686, val_loss=0.891, val_lr=0.0002]  5%|▌         | 50/1000 [4:05:38<81:31:18, 308.92s/epoch, accuracy=0.679, loss=0.904, lr=0.0002, val_accuracy=0.685, val_loss=0.893, val_lr=0.0002]slurmstepd: error: *** JOB 61661061 ON eu-g5-032-2 CANCELLED AT 2024-06-09T03:33:48 DUE TO TIME LIMIT ***
