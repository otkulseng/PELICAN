2024-06-08 21:25:53.507021: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 21:25:53.510892: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-06-08 21:25:53.566798: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-08 21:25:55.636708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-06-08 21:26:10.232899: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected


Running train for /cluster/home/okulseng/PELICAN/experiments/_present/log-nano-pelican-mlp/conf-pelican-7/config.yml


Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 4)     │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ inner_product       │ [(None, 32, 32,   │          0 │ input_layer[0][0] │
│ (InnerProduct)      │ 1), (None, 32,    │            │                   │
│                     │ 32, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ log_layer           │ (None, 32, 32, 1) │          1 │ inner_product[0]… │
│ (LogLayer)          │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32, 1) │          4 │ log_layer[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v2 (Lineq2v2) │ (None, 32, 32, 6) │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ diag_bias_dense     │ (None, 32, 32, 8) │         64 │ lineq2v2[0][0]    │
│ (DiagBiasDense)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 32, 32, 8) │          0 │ diag_bias_dense[… │
│                     │                   │            │ inner_product[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32, 8) │         32 │ multiply[0][0]    │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ lineq2v0 (Lineq2v0) │ (None, 16)        │          0 │ batch_normalizat… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 64)        │      1,088 │ lineq2v0[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 32)        │      2,080 │ dense[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 5)         │        165 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 3,434 (13.41 KB)
 Trainable params: 3,416 (13.34 KB)
 Non-trainable params: 18 (72.00 B)
'LogLayer' object has no attribute 'calc_flops'
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [07:12<119:59:12, 432.39s/epoch, accuracy=0.64, loss=0.959, lr=0.002, val_accuracy=0.668, val_loss=0.905, val_lr=0.002]  0%|          | 2/1000 [14:19<119:05:14, 429.57s/epoch, accuracy=0.688, loss=0.863, lr=0.002, val_accuracy=0.697, val_loss=0.843, val_lr=0.002]  0%|          | 3/1000 [21:27<118:44:37, 428.76s/epoch, accuracy=0.696, loss=0.842, lr=0.002, val_accuracy=0.705, val_loss=0.829, val_lr=0.002]  0%|          | 4/1000 [28:34<118:27:03, 428.14s/epoch, accuracy=0.7, loss=0.831, lr=0.002, val_accuracy=0.705, val_loss=0.824, val_lr=0.002]    0%|          | 5/1000 [35:39<117:57:17, 426.77s/epoch, accuracy=0.703, loss=0.826, lr=0.002, val_accuracy=0.702, val_loss=0.823, val_lr=0.002]  1%|          | 6/1000 [42:45<117:49:12, 426.71s/epoch, accuracy=0.704, loss=0.823, lr=0.002, val_accuracy=0.704, val_loss=0.825, val_lr=0.002]  1%|          | 7/1000 [49:54<117:52:49, 427.36s/epoch, accuracy=0.706, loss=0.818, lr=0.002, val_accuracy=0.709, val_loss=0.815, val_lr=0.002]  1%|          | 8/1000 [56:52<116:54:13, 424.25s/epoch, accuracy=0.707, loss=0.816, lr=0.002, val_accuracy=0.71, val_loss=0.809, val_lr=0.002]   1%|          | 9/1000 [1:03:45<115:48:53, 420.72s/epoch, accuracy=0.708, loss=0.814, lr=0.002, val_accuracy=0.713, val_loss=0.807, val_lr=0.002]  1%|          | 10/1000 [1:10:38<115:02:31, 418.34s/epoch, accuracy=0.709, loss=0.812, lr=0.002, val_accuracy=0.713, val_loss=0.802, val_lr=0.002]  1%|          | 11/1000 [1:17:31<114:30:26, 416.81s/epoch, accuracy=0.709, loss=0.811, lr=0.002, val_accuracy=0.713, val_loss=0.801, val_lr=0.002]  1%|          | 12/1000 [1:24:24<114:06:34, 415.78s/epoch, accuracy=0.71, loss=0.809, lr=0.002, val_accuracy=0.715, val_loss=0.798, val_lr=0.002]   1%|▏         | 13/1000 [1:31:16<113:38:28, 414.50s/epoch, accuracy=0.71, loss=0.807, lr=0.002, val_accuracy=0.716, val_loss=0.798, val_lr=0.002]  1%|▏         | 14/1000 [1:38:05<113:04:08, 412.83s/epoch, accuracy=0.711, loss=0.805, lr=0.002, val_accuracy=0.718, val_loss=0.792, val_lr=0.002]  2%|▏         | 15/1000 [1:44:51<112:23:16, 410.76s/epoch, accuracy=0.712, loss=0.802, lr=0.002, val_accuracy=0.715, val_loss=0.797, val_lr=0.002]  2%|▏         | 16/1000 [1:51:37<111:52:03, 409.27s/epoch, accuracy=0.713, loss=0.803, lr=0.002, val_accuracy=0.717, val_loss=0.793, val_lr=0.002]  2%|▏         | 17/1000 [1:58:27<111:52:11, 409.70s/epoch, accuracy=0.713, loss=0.8, lr=0.002, val_accuracy=0.715, val_loss=0.795, val_lr=0.002]    2%|▏         | 18/1000 [2:05:17<111:46:38, 409.77s/epoch, accuracy=0.714, loss=0.799, lr=0.002, val_accuracy=0.703, val_loss=0.813, val_lr=0.002]  2%|▏         | 19/1000 [2:12:09<111:49:26, 410.36s/epoch, accuracy=0.715, loss=0.798, lr=0.002, val_accuracy=0.71, val_loss=0.81, val_lr=0.002]    2%|▏         | 20/1000 [2:19:01<111:50:18, 410.84s/epoch, accuracy=0.715, loss=0.797, lr=0.002, val_accuracy=0.722, val_loss=0.784, val_lr=0.002]  2%|▏         | 21/1000 [2:25:53<111:47:35, 411.09s/epoch, accuracy=0.715, loss=0.796, lr=0.002, val_accuracy=0.707, val_loss=0.819, val_lr=0.002]  2%|▏         | 22/1000 [2:32:45<111:48:24, 411.56s/epoch, accuracy=0.714, loss=0.798, lr=0.002, val_accuracy=0.718, val_loss=0.79, val_lr=0.002]   2%|▏         | 23/1000 [2:39:38<111:47:15, 411.91s/epoch, accuracy=0.716, loss=0.795, lr=0.002, val_accuracy=0.718, val_loss=0.792, val_lr=0.002]  2%|▏         | 24/1000 [2:46:30<111:39:33, 411.86s/epoch, accuracy=0.716, loss=0.794, lr=0.002, val_accuracy=0.723, val_loss=0.782, val_lr=0.002]  2%|▎         | 25/1000 [2:53:22<111:34:48, 411.99s/epoch, accuracy=0.716, loss=0.793, lr=0.002, val_accuracy=0.715, val_loss=0.793, val_lr=0.002]  3%|▎         | 26/1000 [3:00:16<111:39:29, 412.70s/epoch, accuracy=0.716, loss=0.794, lr=0.002, val_accuracy=0.722, val_loss=0.783, val_lr=0.002]  3%|▎         | 27/1000 [3:07:10<111:38:41, 413.07s/epoch, accuracy=0.717, loss=0.793, lr=0.002, val_accuracy=0.721, val_loss=0.787, val_lr=0.002]  3%|▎         | 28/1000 [3:14:01<111:20:39, 412.39s/epoch, accuracy=0.717, loss=0.792, lr=0.002, val_accuracy=0.723, val_loss=0.783, val_lr=0.002]  3%|▎         | 29/1000 [3:20:49<110:50:03, 410.92s/epoch, accuracy=0.717, loss=0.791, lr=0.002, val_accuracy=0.716, val_loss=0.794, val_lr=0.002]  3%|▎         | 30/1000 [3:27:38<110:33:50, 410.34s/epoch, accuracy=0.718, loss=0.79, lr=0.002, val_accuracy=0.723, val_loss=0.781, val_lr=0.002]   3%|▎         | 31/1000 [3:34:26<110:17:08, 409.73s/epoch, accuracy=0.718, loss=0.79, lr=0.002, val_accuracy=0.721, val_loss=0.784, val_lr=0.002]  3%|▎         | 32/1000 [3:41:10<109:43:53, 408.09s/epoch, accuracy=0.718, loss=0.789, lr=0.002, val_accuracy=0.713, val_loss=0.803, val_lr=0.002]  3%|▎         | 33/1000 [3:47:53<109:12:09, 406.55s/epoch, accuracy=0.718, loss=0.789, lr=0.002, val_accuracy=0.724, val_loss=0.779, val_lr=0.002]  3%|▎         | 34/1000 [3:54:35<108:41:58, 405.09s/epoch, accuracy=0.718, loss=0.788, lr=0.002, val_accuracy=0.721, val_loss=0.787, val_lr=0.002]  4%|▎         | 35/1000 [4:01:12<107:58:53, 402.83s/epoch, accuracy=0.718, loss=0.789, lr=0.002, val_accuracy=0.723, val_loss=0.781, val_lr=0.002]  4%|▎         | 36/1000 [4:07:50<107:26:33, 401.24s/epoch, accuracy=0.719, loss=0.787, lr=0.002, val_accuracy=0.72, val_loss=0.784, val_lr=0.002]   4%|▎         | 37/1000 [4:14:25<106:49:53, 399.37s/epoch, accuracy=0.719, loss=0.787, lr=0.002, val_accuracy=0.715, val_loss=0.796, val_lr=0.002]  4%|▍         | 38/1000 [4:21:13<107:27:00, 402.10s/epoch, accuracy=0.719, loss=0.787, lr=0.002, val_accuracy=0.726, val_loss=0.776, val_lr=0.002]  4%|▍         | 39/1000 [4:28:09<108:24:53, 406.13s/epoch, accuracy=0.719, loss=0.786, lr=0.002, val_accuracy=0.725, val_loss=0.778, val_lr=0.002]  4%|▍         | 40/1000 [4:34:53<108:08:46, 405.55s/epoch, accuracy=0.72, loss=0.785, lr=0.002, val_accuracy=0.722, val_loss=0.787, val_lr=0.002]   4%|▍         | 41/1000 [4:41:48<108:47:43, 408.41s/epoch, accuracy=0.72, loss=0.785, lr=0.002, val_accuracy=0.725, val_loss=0.776, val_lr=0.002]  4%|▍         | 42/1000 [4:48:19<107:15:05, 403.03s/epoch, accuracy=0.72, loss=0.785, lr=0.002, val_accuracy=0.725, val_loss=0.778, val_lr=0.002]  4%|▍         | 43/1000 [4:54:46<105:52:18, 398.26s/epoch, accuracy=0.72, loss=0.784, lr=0.002, val_accuracy=0.725, val_loss=0.777, val_lr=0.002]  4%|▍         | 44/1000 [5:01:09<104:31:15, 393.59s/epoch, accuracy=0.72, loss=0.784, lr=0.002, val_accuracy=0.726, val_loss=0.777, val_lr=0.002]  4%|▍         | 45/1000 [5:07:32<103:35:02, 390.47s/epoch, accuracy=0.721, loss=0.783, lr=0.002, val_accuracy=0.728, val_loss=0.771, val_lr=0.002]  5%|▍         | 46/1000 [5:13:56<102:56:47, 388.48s/epoch, accuracy=0.721, loss=0.783, lr=0.002, val_accuracy=0.724, val_loss=0.78, val_lr=0.002]   5%|▍         | 47/1000 [5:20:19<102:24:24, 386.85s/epoch, accuracy=0.721, loss=0.783, lr=0.002, val_accuracy=0.727, val_loss=0.772, val_lr=0.002]  5%|▍         | 48/1000 [5:26:39<101:45:58, 384.83s/epoch, accuracy=0.721, loss=0.782, lr=0.002, val_accuracy=0.727, val_loss=0.772, val_lr=0.002]  5%|▍         | 49/1000 [5:32:58<101:14:36, 383.26s/epoch, accuracy=0.722, loss=0.782, lr=0.002, val_accuracy=0.725, val_loss=0.778, val_lr=0.002]  5%|▌         | 50/1000 [5:39:20<100:58:32, 382.64s/epoch, accuracy=0.721, loss=0.782, lr=0.002, val_accuracy=0.723, val_loss=0.779, val_lr=0.002]  5%|▌         | 51/1000 [5:45:41<100:45:48, 382.24s/epoch, accuracy=0.722, loss=0.78, lr=0.002, val_accuracy=0.725, val_loss=0.778, val_lr=0.002]   5%|▌         | 52/1000 [5:52:02<100:34:23, 381.92s/epoch, accuracy=0.722, loss=0.781, lr=0.002, val_accuracy=0.727, val_loss=0.776, val_lr=0.002]  5%|▌         | 53/1000 [5:58:22<100:20:50, 381.47s/epoch, accuracy=0.722, loss=0.781, lr=0.002, val_accuracy=0.728, val_loss=0.772, val_lr=0.002]  5%|▌         | 54/1000 [6:04:50<100:41:11, 383.16s/epoch, accuracy=0.722, loss=0.78, lr=0.002, val_accuracy=0.727, val_loss=0.773, val_lr=0.002]   6%|▌         | 55/1000 [6:11:20<101:06:40, 385.19s/epoch, accuracy=0.722, loss=0.78, lr=0.002, val_accuracy=0.726, val_loss=0.776, val_lr=0.002]  6%|▌         | 56/1000 [6:17:48<101:17:56, 386.31s/epoch, accuracy=0.723, loss=0.779, lr=0.002, val_accuracy=0.726, val_loss=0.775, val_lr=0.002]  6%|▌         | 57/1000 [6:24:19<101:31:22, 387.57s/epoch, accuracy=0.722, loss=0.78, lr=0.002, val_accuracy=0.73, val_loss=0.767, val_lr=0.002]    6%|▌         | 58/1000 [6:30:50<101:43:34, 388.76s/epoch, accuracy=0.723, loss=0.779, lr=0.002, val_accuracy=0.726, val_loss=0.774, val_lr=0.002]  6%|▌         | 59/1000 [6:37:24<101:57:40, 390.07s/epoch, accuracy=0.723, loss=0.779, lr=0.002, val_accuracy=0.721, val_loss=0.789, val_lr=0.002]  6%|▌         | 60/1000 [6:43:56<102:02:11, 390.78s/epoch, accuracy=0.723, loss=0.779, lr=0.002, val_accuracy=0.725, val_loss=0.779, val_lr=0.002]  6%|▌         | 61/1000 [6:50:30<102:12:08, 391.83s/epoch, accuracy=0.723, loss=0.779, lr=0.002, val_accuracy=0.729, val_loss=0.769, val_lr=0.002]  6%|▌         | 62/1000 [6:57:08<102:34:15, 393.66s/epoch, accuracy=0.723, loss=0.778, lr=0.002, val_accuracy=0.724, val_loss=0.778, val_lr=0.002]  6%|▋         | 63/1000 [7:03:40<102:19:42, 393.15s/epoch, accuracy=0.722, loss=0.778, lr=0.002, val_accuracy=0.726, val_loss=0.777, val_lr=0.002]  6%|▋         | 64/1000 [7:10:13<102:09:35, 392.92s/epoch, accuracy=0.723, loss=0.778, lr=0.002, val_accuracy=0.727, val_loss=0.776, val_lr=0.002]  6%|▋         | 65/1000 [7:16:47<102:10:18, 393.39s/epoch, accuracy=0.723, loss=0.779, lr=0.002, val_accuracy=0.721, val_loss=0.786, val_lr=0.002]  7%|▋         | 66/1000 [7:23:21<102:05:51, 393.52s/epoch, accuracy=0.723, loss=0.778, lr=0.002, val_accuracy=0.727, val_loss=0.774, val_lr=0.002]  7%|▋         | 67/1000 [7:29:54<101:58:07, 393.45s/epoch, accuracy=0.723, loss=0.778, lr=0.002, val_accuracy=0.727, val_loss=0.775, val_lr=0.002]  7%|▋         | 68/1000 [7:36:29<101:59:08, 393.94s/epoch, accuracy=0.726, loss=0.77, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  7%|▋         | 69/1000 [7:43:03<101:53:19, 393.98s/epoch, accuracy=0.727, loss=0.769, lr=0.0002, val_accuracy=0.731, val_loss=0.763, val_lr=0.0002]  7%|▋         | 70/1000 [7:49:35<101:34:29, 393.19s/epoch, accuracy=0.727, loss=0.769, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  7%|▋         | 71/1000 [7:56:08<101:29:42, 393.31s/epoch, accuracy=0.727, loss=0.769, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  7%|▋         | 72/1000 [8:02:41<101:19:16, 393.06s/epoch, accuracy=0.727, loss=0.769, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  7%|▋         | 73/1000 [8:09:11<100:59:03, 392.17s/epoch, accuracy=0.727, loss=0.769, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  7%|▋         | 74/1000 [8:15:41<100:42:15, 391.51s/epoch, accuracy=0.727, loss=0.769, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  8%|▊         | 75/1000 [8:22:11<100:28:18, 391.03s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  8%|▊         | 76/1000 [8:28:41<100:19:04, 390.85s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  8%|▊         | 77/1000 [8:35:12<100:12:59, 390.88s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  8%|▊         | 78/1000 [8:41:45<100:17:08, 391.57s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  8%|▊         | 79/1000 [8:48:20<100:24:41, 392.49s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  8%|▊         | 80/1000 [8:54:54<100:23:11, 392.82s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  8%|▊         | 81/1000 [9:01:26<100:16:53, 392.83s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.731, val_loss=0.762, val_lr=0.0002]  8%|▊         | 82/1000 [9:08:01<100:20:24, 393.49s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  8%|▊         | 83/1000 [9:14:34<100:10:14, 393.25s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  8%|▊         | 84/1000 [9:21:13<100:29:37, 394.95s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.763, val_lr=0.0002]  8%|▊         | 85/1000 [9:27:51<100:38:15, 395.95s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  9%|▊         | 86/1000 [9:34:30<100:45:20, 396.85s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  9%|▊         | 87/1000 [9:41:10<100:52:47, 397.77s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]  9%|▉         | 88/1000 [9:47:48<100:44:36, 397.67s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.762, val_lr=0.0002]  9%|▉         | 89/1000 [9:54:25<100:38:25, 397.70s/epoch, accuracy=0.727, loss=0.768, lr=0.0002, val_accuracy=0.732, val_loss=0.761, val_lr=0.0002]slurmstepd: error: *** JOB 61661202 ON eu-g5-043-4 CANCELLED AT 2024-06-09T07:26:08 DUE TO TIME LIMIT ***
