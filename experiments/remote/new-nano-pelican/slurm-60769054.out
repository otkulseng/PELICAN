2024-05-29 22:49:39.831934: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-29 22:49:39.892583: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-29 22:49:40.172461: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-29 22:49:42.993482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-05-29 22:49:54.500403: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 32, 4)          │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ inner_product (InnerProduct)    │ (None, 32, 32, 1)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lineq2v2 (Lineq2v2)             │ (None, 32, 32, 7)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 32, 32, 4)      │            32 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lineq2v0 (Lineq2v0)             │ (None, 8)              │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 64)             │           576 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 64)             │         4,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 32)             │         2,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_4 (Dense)                 │ (None, 5)              │           165 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 7,013 (27.39 KB)
 Trainable params: 7,013 (27.39 KB)
 Non-trainable params: 0 (0.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [02:08<35:39:57, 128.53s/epoch, accuracy=0.678, loss=0.89, lr=0.01, val_accuracy=0.695, val_loss=0.846, val_lr=0.01]  0%|          | 2/1000 [04:26<37:06:08, 133.84s/epoch, accuracy=0.698, loss=0.837, lr=0.01, val_accuracy=0.701, val_loss=0.829, val_lr=0.01]  0%|          | 3/1000 [07:09<40:44:51, 147.13s/epoch, accuracy=0.702, loss=0.827, lr=0.01, val_accuracy=0.702, val_loss=0.824, val_lr=0.01]  0%|          | 4/1000 [10:05<43:54:47, 158.72s/epoch, accuracy=0.705, loss=0.819, lr=0.01, val_accuracy=0.707, val_loss=0.81, val_lr=0.01]   0%|          | 5/1000 [13:07<46:10:35, 167.07s/epoch, accuracy=0.706, loss=0.815, lr=0.01, val_accuracy=0.706, val_loss=0.812, val_lr=0.01]  1%|          | 6/1000 [16:06<47:16:41, 171.23s/epoch, accuracy=0.707, loss=0.814, lr=0.01, val_accuracy=0.711, val_loss=0.808, val_lr=0.01]  1%|          | 7/1000 [19:04<47:49:34, 173.39s/epoch, accuracy=0.708, loss=0.811, lr=0.01, val_accuracy=0.709, val_loss=0.807, val_lr=0.01]  1%|          | 8/1000 [22:04<48:19:05, 175.35s/epoch, accuracy=0.708, loss=0.811, lr=0.01, val_accuracy=0.706, val_loss=0.812, val_lr=0.01]  1%|          | 9/1000 [25:17<49:50:30, 181.06s/epoch, accuracy=0.709, loss=0.808, lr=0.01, val_accuracy=0.709, val_loss=0.806, val_lr=0.01]  1%|          | 10/1000 [28:44<51:58:29, 189.00s/epoch, accuracy=0.709, loss=0.808, lr=0.01, val_accuracy=0.709, val_loss=0.81, val_lr=0.01]  1%|          | 11/1000 [31:36<50:27:36, 183.68s/epoch, accuracy=0.71, loss=0.807, lr=0.01, val_accuracy=0.704, val_loss=0.809, val_lr=0.01]  1%|          | 12/1000 [33:50<46:15:34, 168.56s/epoch, accuracy=0.709, loss=0.807, lr=0.01, val_accuracy=0.708, val_loss=0.81, val_lr=0.01]  1%|▏         | 13/1000 [36:02<43:12:34, 157.60s/epoch, accuracy=0.71, loss=0.806, lr=0.01, val_accuracy=0.711, val_loss=0.799, val_lr=0.01]  1%|▏         | 14/1000 [38:16<41:12:24, 150.45s/epoch, accuracy=0.714, loss=0.792, lr=0.001, val_accuracy=0.713, val_loss=0.795, val_lr=0.001]  2%|▏         | 15/1000 [40:29<39:46:23, 145.36s/epoch, accuracy=0.715, loss=0.791, lr=0.001, val_accuracy=0.712, val_loss=0.792, val_lr=0.001]  2%|▏         | 16/1000 [42:43<38:45:02, 141.77s/epoch, accuracy=0.715, loss=0.79, lr=0.001, val_accuracy=0.713, val_loss=0.792, val_lr=0.001]   2%|▏         | 17/1000 [44:56<38:00:48, 139.22s/epoch, accuracy=0.715, loss=0.79, lr=0.001, val_accuracy=0.712, val_loss=0.793, val_lr=0.001]  2%|▏         | 18/1000 [47:09<37:29:02, 137.42s/epoch, accuracy=0.715, loss=0.789, lr=0.001, val_accuracy=0.713, val_loss=0.793, val_lr=0.001]  2%|▏         | 19/1000 [49:23<37:07:14, 136.22s/epoch, accuracy=0.715, loss=0.789, lr=0.001, val_accuracy=0.713, val_loss=0.791, val_lr=0.001]  2%|▏         | 20/1000 [51:36<36:49:53, 135.30s/epoch, accuracy=0.715, loss=0.789, lr=0.001, val_accuracy=0.712, val_loss=0.793, val_lr=0.001]  2%|▏         | 21/1000 [53:49<36:36:32, 134.62s/epoch, accuracy=0.715, loss=0.789, lr=0.001, val_accuracy=0.714, val_loss=0.79, val_lr=0.001]   2%|▏         | 22/1000 [56:02<36:24:24, 134.01s/epoch, accuracy=0.716, loss=0.789, lr=0.001, val_accuracy=0.714, val_loss=0.791, val_lr=0.001]  2%|▏         | 23/1000 [58:14<36:15:54, 133.63s/epoch, accuracy=0.716, loss=0.788, lr=0.001, val_accuracy=0.714, val_loss=0.791, val_lr=0.001]  2%|▏         | 24/1000 [1:00:27<36:08:44, 133.32s/epoch, accuracy=0.715, loss=0.788, lr=0.001, val_accuracy=0.713, val_loss=0.791, val_lr=0.001]  2%|▎         | 25/1000 [1:02:40<36:03:56, 133.17s/epoch, accuracy=0.716, loss=0.788, lr=0.001, val_accuracy=0.714, val_loss=0.791, val_lr=0.001]  3%|▎         | 26/1000 [1:04:52<35:58:00, 132.94s/epoch, accuracy=0.716, loss=0.788, lr=0.001, val_accuracy=0.714, val_loss=0.791, val_lr=0.001]  3%|▎         | 27/1000 [1:07:05<35:54:21, 132.85s/epoch, accuracy=0.716, loss=0.788, lr=0.001, val_accuracy=0.714, val_loss=0.791, val_lr=0.001]  3%|▎         | 28/1000 [1:09:18<35:53:47, 132.95s/epoch, accuracy=0.716, loss=0.788, lr=0.001, val_accuracy=0.713, val_loss=0.79, val_lr=0.001]   3%|▎         | 29/1000 [1:11:31<35:51:32, 132.95s/epoch, accuracy=0.716, loss=0.788, lr=0.001, val_accuracy=0.714, val_loss=0.791, val_lr=0.001]  3%|▎         | 30/1000 [1:13:44<35:49:16, 132.95s/epoch, accuracy=0.716, loss=0.788, lr=0.001, val_accuracy=0.714, val_loss=0.791, val_lr=0.001]  3%|▎         | 31/1000 [1:15:56<35:43:58, 132.75s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.715, val_loss=0.79, val_lr=0.001]   3%|▎         | 32/1000 [1:18:09<35:42:39, 132.81s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.714, val_loss=0.79, val_lr=0.001]  3%|▎         | 33/1000 [1:20:22<35:38:39, 132.70s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.715, val_loss=0.79, val_lr=0.001]  3%|▎         | 34/1000 [1:22:34<35:37:18, 132.75s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.714, val_loss=0.79, val_lr=0.001]  4%|▎         | 35/1000 [1:24:47<35:35:26, 132.77s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.714, val_loss=0.789, val_lr=0.001]  4%|▎         | 36/1000 [1:27:00<35:32:34, 132.73s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.715, val_loss=0.79, val_lr=0.001]   4%|▎         | 37/1000 [1:29:12<35:29:27, 132.68s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.713, val_loss=0.79, val_lr=0.001]  4%|▍         | 38/1000 [1:31:25<35:28:08, 132.73s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.714, val_loss=0.789, val_lr=0.001]  4%|▍         | 39/1000 [1:33:38<35:26:29, 132.77s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.714, val_loss=0.79, val_lr=0.001]   4%|▍         | 40/1000 [1:35:51<35:24:14, 132.77s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.715, val_loss=0.789, val_lr=0.001]  4%|▍         | 41/1000 [1:38:04<35:22:29, 132.79s/epoch, accuracy=0.716, loss=0.786, lr=0.001, val_accuracy=0.714, val_loss=0.793, val_lr=0.001]  4%|▍         | 42/1000 [1:40:16<35:17:53, 132.64s/epoch, accuracy=0.716, loss=0.786, lr=0.001, val_accuracy=0.715, val_loss=0.79, val_lr=0.001]   4%|▍         | 43/1000 [1:42:29<35:15:58, 132.66s/epoch, accuracy=0.716, loss=0.787, lr=0.001, val_accuracy=0.714, val_loss=0.79, val_lr=0.001]  4%|▍         | 44/1000 [1:44:41<35:12:33, 132.59s/epoch, accuracy=0.716, loss=0.786, lr=0.001, val_accuracy=0.715, val_loss=0.79, val_lr=0.001]  4%|▍         | 45/1000 [1:46:54<35:10:03, 132.57s/epoch, accuracy=0.716, loss=0.786, lr=0.001, val_accuracy=0.714, val_loss=0.79, val_lr=0.001]  5%|▍         | 46/1000 [1:49:06<35:08:40, 132.62s/epoch, accuracy=0.716, loss=0.786, lr=0.001, val_accuracy=0.714, val_loss=0.79, val_lr=0.001]  5%|▍         | 47/1000 [1:51:19<35:07:24, 132.68s/epoch, accuracy=0.716, loss=0.786, lr=0.001, val_accuracy=0.715, val_loss=0.789, val_lr=0.001]  5%|▍         | 48/1000 [1:53:31<35:01:12, 132.43s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  5%|▍         | 49/1000 [1:55:44<34:59:59, 132.49s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  5%|▌         | 50/1000 [1:57:56<34:58:38, 132.55s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  5%|▌         | 51/1000 [2:00:09<34:56:41, 132.56s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  5%|▌         | 52/1000 [2:02:21<34:51:47, 132.39s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  5%|▌         | 53/1000 [2:04:33<34:45:57, 132.16s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  5%|▌         | 54/1000 [2:06:45<34:46:12, 132.32s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  6%|▌         | 55/1000 [2:08:58<34:45:13, 132.39s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  6%|▌         | 56/1000 [2:11:10<34:43:27, 132.42s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  6%|▌         | 57/1000 [2:13:23<34:40:11, 132.36s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  6%|▌         | 58/1000 [2:15:35<34:39:49, 132.47s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  6%|▌         | 59/1000 [2:17:48<34:38:48, 132.55s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  6%|▌         | 60/1000 [2:20:01<34:38:36, 132.68s/epoch, accuracy=0.717, loss=0.784, lr=0.0001, val_accuracy=0.715, val_loss=0.788, val_lr=0.0001]  6%|▌         | 61/1000 [2:22:14<34:36:07, 132.66s/epoch, accuracy=0.717, loss=0.783, lr=1e-5, val_accuracy=0.715, val_loss=0.788, val_lr=1e-5]      6%|▌         | 62/1000 [2:24:26<34:32:50, 132.59s/epoch, accuracy=0.718, loss=0.783, lr=1e-5, val_accuracy=0.715, val_loss=0.788, val_lr=1e-5]  6%|▋         | 63/1000 [2:26:38<34:26:10, 132.31s/epoch, accuracy=0.717, loss=0.783, lr=1e-5, val_accuracy=0.715, val_loss=0.788, val_lr=1e-5]  6%|▋         | 64/1000 [2:28:50<34:21:47, 132.17s/epoch, accuracy=0.717, loss=0.783, lr=1e-5, val_accuracy=0.715, val_loss=0.788, val_lr=1e-5]  6%|▋         | 65/1000 [2:31:01<34:15:10, 131.88s/epoch, accuracy=0.717, loss=0.783, lr=1e-5, val_accuracy=0.715, val_loss=0.788, val_lr=1e-5]  7%|▋         | 66/1000 [2:33:12<34:10:45, 131.74s/epoch, accuracy=0.717, loss=0.783, lr=1e-5, val_accuracy=0.715, val_loss=0.788, val_lr=1e-5]  7%|▋         | 67/1000 [2:35:24<34:07:41, 131.68s/epoch, accuracy=0.718, loss=0.783, lr=1e-5, val_accuracy=0.715, val_loss=0.788, val_lr=1e-5]  7%|▋         | 68/1000 [2:37:36<34:06:03, 131.72s/epoch, accuracy=0.717, loss=0.783, lr=1e-6, val_accuracy=0.715, val_loss=0.788, val_lr=1e-6]  7%|▋         | 69/1000 [2:39:47<34:03:25, 131.69s/epoch, accuracy=0.718, loss=0.783, lr=1e-6, val_accuracy=0.715, val_loss=0.788, val_lr=1e-6]  7%|▋         | 70/1000 [2:41:59<34:00:55, 131.67s/epoch, accuracy=0.717, loss=0.783, lr=1e-6, val_accuracy=0.715, val_loss=0.788, val_lr=1e-6]  7%|▋         | 71/1000 [2:44:11<33:58:53, 131.68s/epoch, accuracy=0.718, loss=0.783, lr=1e-6, val_accuracy=0.715, val_loss=0.788, val_lr=1e-6]  7%|▋         | 72/1000 [2:46:22<33:55:23, 131.60s/epoch, accuracy=0.718, loss=0.783, lr=1e-6, val_accuracy=0.715, val_loss=0.788, val_lr=1e-6]  7%|▋         | 73/1000 [2:48:33<33:52:09, 131.53s/epoch, accuracy=0.717, loss=0.783, lr=1e-6, val_accuracy=0.715, val_loss=0.788, val_lr=1e-6]  7%|▋         | 74/1000 [2:50:45<33:51:13, 131.61s/epoch, accuracy=0.718, loss=0.783, lr=1e-6, val_accuracy=0.715, val_loss=0.788, val_lr=1e-6]  8%|▊         | 75/1000 [2:52:57<33:48:33, 131.58s/epoch, accuracy=0.718, loss=0.783, lr=1e-7, val_accuracy=0.715, val_loss=0.788, val_lr=1e-7]  8%|▊         | 75/1000 [2:52:57<35:33:04, 138.36s/epoch, accuracy=0.718, loss=0.783, lr=1e-7, val_accuracy=0.715, val_loss=0.788, val_lr=1e-7]
