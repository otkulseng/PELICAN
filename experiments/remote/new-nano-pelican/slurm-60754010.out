2024-05-29 20:12:41.985900: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-29 20:12:41.987379: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-29 20:12:42.039092: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-29 20:12:42.251773: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-29 20:12:44.138503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-05-29 20:12:52.341240: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
Running train
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 32, 4)          │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ inner_product (InnerProduct)    │ (None, 32, 32, 1)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lineq2v2 (Lineq2v2)             │ (None, 32, 32, 7)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 32, 32, 3)      │            24 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lineq2v0 (Lineq2v0)             │ (None, 6)              │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 64)             │           448 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 32)             │         2,080 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 5)              │           165 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 2,717 (10.61 KB)
 Trainable params: 2,717 (10.61 KB)
 Non-trainable params: 0 (0.00 B)
0epoch [00:00, ?epoch/s]  0%|          | 0/1000 [00:00<?, ?epoch/s]/cluster/home/okulseng/.local/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
  0%|          | 1/1000 [01:08<18:57:25, 68.31s/epoch, accuracy=0.682, loss=0.884, lr=0.01, val_accuracy=0.694, val_loss=0.852, val_lr=0.01]  0%|          | 2/1000 [02:13<18:24:22, 66.40s/epoch, accuracy=0.701, loss=0.838, lr=0.01, val_accuracy=0.7, val_loss=0.838, val_lr=0.01]    0%|          | 3/1000 [03:19<18:22:07, 66.33s/epoch, accuracy=0.703, loss=0.832, lr=0.01, val_accuracy=0.703, val_loss=0.834, val_lr=0.01]  0%|          | 4/1000 [04:25<18:20:14, 66.28s/epoch, accuracy=0.704, loss=0.825, lr=0.01, val_accuracy=0.701, val_loss=0.83, val_lr=0.01]   0%|          | 5/1000 [05:33<18:25:47, 66.68s/epoch, accuracy=0.704, loss=0.82, lr=0.01, val_accuracy=0.702, val_loss=0.823, val_lr=0.01]  1%|          | 6/1000 [06:39<18:24:14, 66.65s/epoch, accuracy=0.706, loss=0.815, lr=0.01, val_accuracy=0.706, val_loss=0.812, val_lr=0.01]  1%|          | 7/1000 [07:46<18:21:41, 66.57s/epoch, accuracy=0.706, loss=0.813, lr=0.01, val_accuracy=0.705, val_loss=0.825, val_lr=0.01]  1%|          | 8/1000 [08:53<18:22:44, 66.70s/epoch, accuracy=0.707, loss=0.811, lr=0.01, val_accuracy=0.707, val_loss=0.807, val_lr=0.01]  1%|          | 9/1000 [10:00<18:23:24, 66.81s/epoch, accuracy=0.707, loss=0.81, lr=0.01, val_accuracy=0.707, val_loss=0.809, val_lr=0.01]   1%|          | 10/1000 [11:06<18:18:56, 66.60s/epoch, accuracy=0.707, loss=0.809, lr=0.01, val_accuracy=0.704, val_loss=0.818, val_lr=0.01]  1%|          | 11/1000 [12:12<18:17:57, 66.61s/epoch, accuracy=0.708, loss=0.809, lr=0.01, val_accuracy=0.705, val_loss=0.812, val_lr=0.01]  1%|          | 12/1000 [13:20<18:19:13, 66.75s/epoch, accuracy=0.708, loss=0.807, lr=0.01, val_accuracy=0.708, val_loss=0.807, val_lr=0.01]  1%|▏         | 13/1000 [14:26<18:16:24, 66.65s/epoch, accuracy=0.709, loss=0.806, lr=0.01, val_accuracy=0.708, val_loss=0.807, val_lr=0.01]  1%|▏         | 14/1000 [15:32<18:12:41, 66.49s/epoch, accuracy=0.708, loss=0.806, lr=0.01, val_accuracy=0.708, val_loss=0.806, val_lr=0.01]  2%|▏         | 15/1000 [16:38<18:09:13, 66.35s/epoch, accuracy=0.709, loss=0.806, lr=0.01, val_accuracy=0.709, val_loss=0.804, val_lr=0.01]  2%|▏         | 16/1000 [17:45<18:12:54, 66.64s/epoch, accuracy=0.709, loss=0.806, lr=0.01, val_accuracy=0.708, val_loss=0.808, val_lr=0.01]  2%|▏         | 17/1000 [18:52<18:12:37, 66.69s/epoch, accuracy=0.709, loss=0.806, lr=0.01, val_accuracy=0.708, val_loss=0.803, val_lr=0.01]  2%|▏         | 18/1000 [19:59<18:12:36, 66.76s/epoch, accuracy=0.709, loss=0.805, lr=0.01, val_accuracy=0.704, val_loss=0.815, val_lr=0.01]  2%|▏         | 19/1000 [21:05<18:08:58, 66.60s/epoch, accuracy=0.71, loss=0.804, lr=0.01, val_accuracy=0.708, val_loss=0.807, val_lr=0.01]   2%|▏         | 20/1000 [22:11<18:04:03, 66.37s/epoch, accuracy=0.71, loss=0.804, lr=0.01, val_accuracy=0.707, val_loss=0.807, val_lr=0.01]  2%|▏         | 21/1000 [23:16<17:53:10, 65.77s/epoch, accuracy=0.71, loss=0.804, lr=0.01, val_accuracy=0.707, val_loss=0.805, val_lr=0.01]  2%|▏         | 22/1000 [24:22<17:55:21, 65.97s/epoch, accuracy=0.71, loss=0.804, lr=0.01, val_accuracy=0.706, val_loss=0.809, val_lr=0.01]  2%|▏         | 23/1000 [25:29<17:59:07, 66.27s/epoch, accuracy=0.713, loss=0.795, lr=0.001, val_accuracy=0.71, val_loss=0.798, val_lr=0.001]  2%|▏         | 24/1000 [26:35<17:57:37, 66.25s/epoch, accuracy=0.713, loss=0.794, lr=0.001, val_accuracy=0.711, val_loss=0.797, val_lr=0.001]  2%|▎         | 25/1000 [27:42<18:00:04, 66.47s/epoch, accuracy=0.713, loss=0.794, lr=0.001, val_accuracy=0.711, val_loss=0.797, val_lr=0.001]  3%|▎         | 26/1000 [28:48<17:54:42, 66.20s/epoch, accuracy=0.713, loss=0.794, lr=0.001, val_accuracy=0.71, val_loss=0.797, val_lr=0.001]   3%|▎         | 27/1000 [29:55<17:58:07, 66.48s/epoch, accuracy=0.713, loss=0.793, lr=0.001, val_accuracy=0.711, val_loss=0.796, val_lr=0.001]  3%|▎         | 28/1000 [31:01<17:53:41, 66.28s/epoch, accuracy=0.713, loss=0.793, lr=0.001, val_accuracy=0.711, val_loss=0.796, val_lr=0.001]  3%|▎         | 29/1000 [32:08<17:56:33, 66.52s/epoch, accuracy=0.713, loss=0.793, lr=0.001, val_accuracy=0.711, val_loss=0.797, val_lr=0.001]  3%|▎         | 30/1000 [33:15<17:57:33, 66.65s/epoch, accuracy=0.713, loss=0.793, lr=0.001, val_accuracy=0.711, val_loss=0.796, val_lr=0.001]  3%|▎         | 31/1000 [34:21<17:53:10, 66.45s/epoch, accuracy=0.713, loss=0.793, lr=0.001, val_accuracy=0.711, val_loss=0.796, val_lr=0.001]  3%|▎         | 32/1000 [35:28<17:53:50, 66.56s/epoch, accuracy=0.713, loss=0.793, lr=0.001, val_accuracy=0.711, val_loss=0.797, val_lr=0.001]  3%|▎         | 33/1000 [36:34<17:51:56, 66.51s/epoch, accuracy=0.713, loss=0.793, lr=0.001, val_accuracy=0.711, val_loss=0.797, val_lr=0.001]  3%|▎         | 34/1000 [37:40<17:50:02, 66.46s/epoch, accuracy=0.714, loss=0.793, lr=0.001, val_accuracy=0.711, val_loss=0.796, val_lr=0.001]  4%|▎         | 35/1000 [38:47<17:50:04, 66.53s/epoch, accuracy=0.714, loss=0.792, lr=0.0001, val_accuracy=0.711, val_loss=0.795, val_lr=0.0001]  4%|▎         | 36/1000 [39:54<17:52:11, 66.73s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.711, val_loss=0.795, val_lr=0.0001]  4%|▎         | 37/1000 [41:01<17:49:18, 66.62s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.712, val_loss=0.795, val_lr=0.0001]  4%|▍         | 38/1000 [42:06<17:44:45, 66.41s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.711, val_loss=0.795, val_lr=0.0001]  4%|▍         | 39/1000 [43:13<17:44:18, 66.45s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.712, val_loss=0.795, val_lr=0.0001]  4%|▍         | 40/1000 [44:20<17:44:02, 66.50s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.712, val_loss=0.795, val_lr=0.0001]  4%|▍         | 41/1000 [45:26<17:41:17, 66.40s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.711, val_loss=0.795, val_lr=0.0001]  4%|▍         | 42/1000 [46:32<17:41:26, 66.48s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.712, val_loss=0.795, val_lr=0.0001]  4%|▍         | 43/1000 [47:39<17:42:37, 66.62s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.711, val_loss=0.795, val_lr=0.0001]  4%|▍         | 44/1000 [48:45<17:37:42, 66.38s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.711, val_loss=0.795, val_lr=0.0001]  4%|▍         | 45/1000 [49:51<17:34:17, 66.24s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.712, val_loss=0.795, val_lr=0.0001]  5%|▍         | 46/1000 [50:58<17:37:58, 66.54s/epoch, accuracy=0.714, loss=0.791, lr=0.0001, val_accuracy=0.711, val_loss=0.795, val_lr=0.0001]  5%|▍         | 47/1000 [52:05<17:39:24, 66.70s/epoch, accuracy=0.714, loss=0.791, lr=1e-5, val_accuracy=0.712, val_loss=0.795, val_lr=1e-5]      5%|▍         | 48/1000 [53:12<17:36:48, 66.61s/epoch, accuracy=0.714, loss=0.791, lr=1e-5, val_accuracy=0.711, val_loss=0.795, val_lr=1e-5]  5%|▍         | 49/1000 [54:18<17:33:51, 66.49s/epoch, accuracy=0.714, loss=0.791, lr=1e-5, val_accuracy=0.711, val_loss=0.795, val_lr=1e-5]  5%|▌         | 50/1000 [55:25<17:34:38, 66.61s/epoch, accuracy=0.714, loss=0.791, lr=1e-5, val_accuracy=0.712, val_loss=0.795, val_lr=1e-5]  5%|▌         | 51/1000 [56:32<17:33:38, 66.62s/epoch, accuracy=0.714, loss=0.791, lr=1e-5, val_accuracy=0.712, val_loss=0.795, val_lr=1e-5]  5%|▌         | 52/1000 [57:39<17:36:30, 66.87s/epoch, accuracy=0.714, loss=0.791, lr=1e-5, val_accuracy=0.712, val_loss=0.795, val_lr=1e-5]  5%|▌         | 53/1000 [58:46<17:37:05, 66.98s/epoch, accuracy=0.714, loss=0.791, lr=1e-5, val_accuracy=0.712, val_loss=0.795, val_lr=1e-5]  5%|▌         | 54/1000 [59:54<17:37:21, 67.06s/epoch, accuracy=0.714, loss=0.791, lr=1e-6, val_accuracy=0.712, val_loss=0.795, val_lr=1e-6]  6%|▌         | 55/1000 [1:01:01<17:35:58, 67.05s/epoch, accuracy=0.714, loss=0.791, lr=1e-6, val_accuracy=0.712, val_loss=0.795, val_lr=1e-6]  6%|▌         | 56/1000 [1:02:07<17:33:18, 66.95s/epoch, accuracy=0.714, loss=0.791, lr=1e-6, val_accuracy=0.712, val_loss=0.795, val_lr=1e-6]  6%|▌         | 57/1000 [1:03:14<17:30:16, 66.83s/epoch, accuracy=0.714, loss=0.791, lr=1e-6, val_accuracy=0.712, val_loss=0.795, val_lr=1e-6]  6%|▌         | 58/1000 [1:04:19<17:22:34, 66.41s/epoch, accuracy=0.714, loss=0.791, lr=1e-6, val_accuracy=0.712, val_loss=0.795, val_lr=1e-6]  6%|▌         | 59/1000 [1:05:26<17:21:29, 66.41s/epoch, accuracy=0.714, loss=0.791, lr=1e-6, val_accuracy=0.712, val_loss=0.795, val_lr=1e-6]  6%|▌         | 60/1000 [1:06:32<17:17:56, 66.25s/epoch, accuracy=0.714, loss=0.791, lr=1e-6, val_accuracy=0.712, val_loss=0.795, val_lr=1e-6]  6%|▌         | 60/1000 [1:06:32<17:22:22, 66.53s/epoch, accuracy=0.714, loss=0.791, lr=1e-6, val_accuracy=0.712, val_loss=0.795, val_lr=1e-6]
